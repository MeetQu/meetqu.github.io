<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Anthony's Blog</title><link>https://sudrizzz.github.io/</link><description>Recent content on Anthony's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 24 Nov 2020 10:00:00 +0800</lastBuildDate><atom:link href="https://sudrizzz.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>并行计算课程实践</title><link>https://sudrizzz.github.io/posts/parallel-computing/</link><pubDate>Tue, 24 Nov 2020 10:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/parallel-computing/</guid><description>本文的代码均存放在 Github，地址 https://github.com/sudrizzz/ParallelComputing
本例中所设计到的输入矩阵有两个：a 矩阵与 b 矩阵，其值相同，如下：
a、b 矩阵：
118.04 8.47 16.82 17.15 19.58 4.24 7.20 16.50 5.97 11.90 210.25 13.50 7.83 11.03 20.45 19.68 13.65 15.40 3.04 13.03 30.35 5.22 2.95 17.27 3.36 8.61 2.79 2.34 21.45 4.69 411.02 18.02 13.16 6.36 13.69 11.26 10.60 20.89 6.28 16.56 511.31 16.53 8.59 19.15 6.08 7.57 17.35 19.74 1.50 20.39 611.30 1.85 4.13 14.24 19.12 7.49 1.38 0.43 9.83 1.35 75.12 20.</description></item><item><title>FastDFS 搭建分布式文件管理系统</title><link>https://sudrizzz.github.io/posts/getting-to-know-fastdfs/</link><pubDate>Wed, 04 Nov 2020 17:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-fastdfs/</guid><description>FastDFS 简介 FastDFS 是一个开源的高性能分布式文件系统（Distributed File System）。它的主要功能包括：文件存储、文件同步和文件访问以及高容量和负载平衡。主要解决了海量数据存储问题，特别适合以中小文件（建议范围：4KB &amp;lt; file_size &amp;lt; 500MB）为载体的在线服务。
FastDFS 开源地址：https://github.com/happyfish100/fastdfs
由于网络上已有很多详细的关于 FastDFS 的介绍，故此处不再赘述。请查看参考文章中的第 1、2 条。
FastDFS 架构图 FastDFS 上传流程 FastDFS 下载流程 安装 FastDFS 配置防火墙 本篇文章是基于 CentOS v8.2.2004 版本，以下操作均为单机环境，单机 IP 地址为 192.168.61.128。在安装 FastDFS 之前，需要先进行防火墙的设置。防火墙的相关命令如下：
1# 暂时关闭防火墙 2systemctl stop firewalld 3 4# 永久关闭防火墙 5systemctl disable firewalld 6 7# 启用防火墙 8systemctl enable firewalld 下载安装 libfastcommon libfastcommon 是从 FastDFS 抽取出来的公共 c 函数库。
1# 下载 2wget https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz 3 4# 解压 5tar -zxvf V1.0.43.tar.gz 6cd libfastcommon-1.</description></item><item><title>Spark 分布式内存计算框架</title><link>https://sudrizzz.github.io/posts/spark-distributed-programming/</link><pubDate>Fri, 23 Oct 2020 20:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/spark-distributed-programming/</guid><description>Spark 简介 Spark 是一种基于内存的、用以实现高效集群计算的平台。准确地讲，Spark 是一个大数据并行计算框架，是对广泛使用的 MapReduce 计算模型的扩展。Spark 有着自己的生态系统，但同时兼容 HDFS、Hive 等分布式存储系统，可以完美融入 Hadoop 的生态圈中，代替 MapReduce 去执行更为高效的分布式计算。两者的区别在于：基于 MapReduce 的计算引擎通常会将中间结果输出到磁盘上进行存储和容错；而 Spark 则是将中间结果尽量保存在内存中以减少底层存储系统的 I/O，以提高计算速度。
Spark 编程模型 核心数据结构 RDD Spark 将数据抽象成弹性分布式数据集（Resilient Distributed Dataset, RDD），RDD 实际是分布在集群多个节点上数据的集合，通过操作 RDD 对象来并行化操作集群上的分布式数据。
RDD 有两种创建方式:
并行化驱动程序中已有的原生集合; 引用 HDFS、HBase 等外部存储系统上的数据集。 RDD 可以缓存在内存中，每次对 RDD 操作的结果都可以放到内存中，下一次操作时可直接从内存中读取，相对于 MapReduce,它省去了大量的磁盘 I/O 操作。另外，持久化的 RDD 能够在错误中自动恢复，如果某部分 RDD 丢失，Spark 会自动重算丢失的部分。
RDD 上的操作 从相关数据源获取初始数据形成初始 RDD 后，需要根据应用的需求对得到的初始 RDD 进行必要的处理，来获取满足需求的数据内容，从而对中间数据进行计算加工，得到最终的数据。
RDD 支持两种操作，一种是转换（Transformation）操作，另一种是行动（Action）操作。
转换（Transformation）操作 转换操作即将一个 RDD 转换为一个新的 RDD。值得注意的是，转换操作是惰性的，这就意味着对 RDD 调用某种转换操作时，操作并不会立即执行，而是 Spark 在内部记录下所要求执行的操作的相关信息，当在行动操作中需要用到这些转换出来的 RDD 时才会被计算，下表所示为基本的转换操作。通过转换操作，可以从已有的 RDD 生成出新的 RDD, Spark 使用谱系（Lineage）记录新旧 RDD 之间的依赖关系，一旦持久化的 RDD 丢失部分数据时，Spark 能通过谱系图重新计算丢失的数据。</description></item><item><title>MapReduce 分布式编程</title><link>https://sudrizzz.github.io/posts/mapreduce-distributed-programming/</link><pubDate>Sat, 17 Oct 2020 20:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/mapreduce-distributed-programming/</guid><description>词频统计程序示例 假设将一个英文文本大文件作为输入，统计文件中单词出现的频数。最基本的操作是把输入文件的每一行传递给 map 函数完成对单词的拆分并输出中间结果，中间结果为 &amp;lt;word, 1&amp;gt; 的形式， 表示程序对一个单词，都对应一个计数 1。使用 reduce 函数收集 map 函数的结果作为输入值，并生成最终 &amp;lt;word, count&amp;gt; 形式的结果，完成对每个单词的词频统计。它们对应 MapReduce 处理数据流程如上图所示。
MapReduce 程序的运行过程 如图所示，MapReduce 运行阶段数据传递经过输入文件、Map 阶段、中间文件、 Reduce 阶段、输出文件五个阶段，用户程序只与 Map 阶段和 Reduce 阶段的 Worker 直接相关，其他事情由 Hadoop 平台根据设置自行完成。
从用户程序 User Program 开始，用户程序 User Program 链接了 MapReduce 库，实现了最基本的 map 函数和 reduce 函数。
MapReduce 库先把 User Program 的输入文件划分为 M 份，如上图左方所示，将数据分成了分片 0~4，每一份通常为 16MB~64MB；然后使用 fork 将用户进程复制到集群内其他机器上。 User Program 的副本中有一个 Master 副本和多个 Worker 副本。Master 是负责调度的，为空闲 Worker 分配 Map 作业或者 Reduce 作业。 被分配了 Map 作业的 Worker，开始读取对应分片的输入数据, Map 作业数量与输入文件划分数 M 相同，并与分片一一对应; Map 作业将输入数据转化为键值对表示形式并传递给 map 函数，map 函数产生的中间键值对被缓存在内存中。 缓存的中间键值对会被定期写入本地磁盘，而且被分为 R 个区（R 的大小是由用户定义的），每个区会对应一个 Reduce 作业；这些中间键值对的位置会被通报给 Master, Master 负责将信息转发给 Reduce Worker。 Master 通知分配了 Reduce 作业的 Worker 负责数据分区，Reduce Worker 读取键值对数据并依据键排序，使相同键的键值对聚集在一起。同一个分区可能存在多个键的键值对，而 reduce 函数的一次调用的键值是唯一的， 所以必须进行排序处理。 Reduce Worker 遍历排序后的中间键值对，对于每个唯一的键，都将键与关联的值传递给 reduce 函数，reduce 函数产生的输出会写回到数据分区的输出文件中。 当所有的 Map 和 Reduce 作业都完成了，Master 唤醒 User Program，MapReduce 函数调用返回 User Program。 执行完毕后，MapReduce 的输出放在 R 个分区的输出文件中，即每个 Reduce 作业分别对应一个输出文件。用户可将这 R 个文件作为输入交给另一个 MapReduce 程序处理，而不需要主动合并这 R 个文件。在 MapReduce 计算过程中，输入数据来自分布式文件系统，中间数据放在本地文件系统，最终输出数据写入分布式文件系统。</description></item><item><title>HDFS 文件管理</title><link>https://sudrizzz.github.io/posts/hdfs-file-system/</link><pubDate>Mon, 12 Oct 2020 15:20:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/hdfs-file-system/</guid><description>本文所有代码均可在 https://github.com/sudrizzz/HDFSOperations 查看。
通过命令行访问 HDFS 命令行是最简单、最直接操作文件的方式。这里介绍通过诸如读取文件、新建目录、移动文件、删除数据、列出目录等命令来进一步认识 HDFS。也可以输入 hadoop fs -help 命令获取每个命令的详细帮助。若熟悉 Linux 命令，Hadoop 命令看起来非常直观且易于使用。
对文件和目录的操作 通过命令行对 HDFS 文件和目录的操作主要包括：创建、浏览、删除文件和目录，以及从本地文件系统与 HDFS 文件系统互相拷贝等。常用命令格式如下。
1hadoop fs -ls &amp;lt;path&amp;gt; # 列出 path 目录下的所有内容（文件和目录） 2hadoop fs -lsr &amp;lt;path&amp;gt; # 递归列出 path 下的所有内容（文件或目录） 3hadoop fs -df &amp;lt;path&amp;gt; # 查看目录的使用情况 4hadoop fs -du &amp;lt;path&amp;gt; # 显示目录中所有文件及目录大小 5hadoop fs -touchz &amp;lt;path&amp;gt; # 创建一个路径为为 path 的 0 字节的 HDFS 空文件 6hadoop fs -mkdir &amp;lt;path&amp;gt; # 查看目录的使用情况 7hadoop fs -rm [-skipTrash] &amp;lt;path&amp;gt; # 将 HDFS 上路径为 &amp;lt;path&amp;gt; 的文件移动到回收站，加上 -skipTrash，则直接删除 8hadoop fs -rmr [-skipTrash] &amp;lt;path&amp;gt; # 将 HDFS 上路径为 &amp;lt;path&amp;gt; 的目录以及目录下的文件移动到回收站。如果加上 -skipTrash，则直接删除 9hadoop fs -moveFromLocal &amp;lt;localsrc&amp;gt;.</description></item><item><title>初识 Hadoop</title><link>https://sudrizzz.github.io/posts/getting-to-know-hadoop/</link><pubDate>Thu, 24 Sep 2020 09:20:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-hadoop/</guid><description>前言 本系列文章是基于《大数据技术基础》与 10 小时入门大数据 课程，如果有兴趣可以先阅读该书并观看视频教程。本系列文章中所用到的软件版本及其下载地址如下：
名称 版本 下载地址 CentOS 8.2.2004 https://mirrors.tuna.tsinghua.edu.cn/centos/8.2.2004/isos/x86_64/CentOS-8.2.2004-x86_64-minimal.iso JDK 14.0.2 https://www.oracle.com/java/technologies/javase/jdk14-archive-downloads.html Hadoop 2.10.1 https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.10.1/hadoop-2.10.1-src.tar.gz 环境准备 配置网络 此篇文章所使用的 CentOS 环境均是使用 VMware 15 虚拟的，具体安装教程请查看 使用 VMware 15 安装虚拟机和使用 CentOS 8，此处不再赘述。安装好一个节点之后，我们可以采用“虚拟机克隆”的方式，直接完成另外两个节点系统的安装。
虚拟机的网络配置采用 DHCP 自动分配模式，每台机器的 IP 地址可以通过命令 ip address 或 ifconfig 查看，其中 ifconfig 输出如下，第一组配置中 ens33 即为本机网络配置，inet 项对应的即为本机 ip（192.168.61.128）。
1ens33: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 2 inet 192.168.61.128 netmask 255.255.255.0 broadcast 192.</description></item><item><title>CMU 15-213 存储器层次结构</title><link>https://sudrizzz.github.io/posts/cmu-15-213-lesson3/</link><pubDate>Sun, 20 Sep 2020 15:20:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/cmu-15-213-lesson3/</guid><description>前言 本课的第三、四章分别是程序的机器级表示和处理器体系结构，由于过于硬核，此处略过。第五章是优化程序性能，讲解了如何最大限度地提高程序执行效能，此处也略过。本文基于第六章存储器层级结构。
存储技术 在本节中主要介绍 SRAM 存储器、DRAM 存储器、ROM 存储器以及机械和固态硬盘。
随机访问存储器 随机访问存储器（Random Access Memory, RAM）分为两类：静态的和动态的。静态随机访问存储器（Static Random Access Memory, SRAM）比动态随机访问存储器（Dynamic Random Access Memory, DRAM）更快，但也贵得多。目前 CPU 中的三级缓存都是 SRAM。
易失性存储器 需要注意的是，虽然 SRAM 是静态随机访问存储器，但是其“静态”是相对于动态随机访问存储器的，仍然属于“易失性存储器”，而非真正意义上的静态，同时 DRAM 也属于“易失性存储器”。通俗的说，就是断电之后保存的信息就会丢失。
SRAM SRAM 将每个位存储在一个双稳态的存储器单元中，每个单元是用一个六晶体管来实现的，在通电的情况下，它可以无限期地保持在两个不同的电压配置或状态之一，其他任何状态都是不稳定的。当从不稳定状态开始，电路会迅速转换到两个稳定状态中的一个。这样的存储器单元类似于下图倒转的钟摆模型。
由于上述的特性（SRAM 的双稳态特性），只要有电，它就会永远保持它的值。即使有干扰（例如电子噪音）来扰乱电压，当干扰消除后，电路就会恢复到稳定值。这样体现了上述表格中的持续性和不敏感性。
DRAM DRAM 将每个位存储位对一个电容的充电，每个单元由一个电容和一个访问晶体管组成。但是与 SRAM 不同，DRAM 存储单元对抗干扰非常敏感。当电容的电压被扰乱之后，它就永远不会恢复了。
小结 下表总结了 SRAM 和 DRAM 存储器的特性。只要有供电，SRAM 就会保持不变。与 DRAM 不同，它不需要刷新。SRAM 的存取比 DRAM 快。SRAM 对诸如光和电噪声这样的干扰不敏感。代价是 SRAM 单元比 DRAM 单元使用更多的晶体管，因而密集度低，而且更贵，功耗更大。
每位晶体管数 相对访问时间 持续的？ 敏感的？ 相对花费 应用 SRAM 6 1X 是 否 1000x 高速缓存存储器 DRAM 1 10X 否 是 1X 主存，帧缓冲区 非易失性存储器 显然，非易失性存储器指即使断电也不会丢失数据的存储器，非易失性存储器包括以下几种：</description></item><item><title>CMU 15-213 浮点数</title><link>https://sudrizzz.github.io/posts/cmu-15-213-lesson2/</link><pubDate>Mon, 14 Sep 2020 18:57:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/cmu-15-213-lesson2/</guid><description>前言 在 上一篇文章 中，我们了解了二进制有符号数、无符号数以及其相关的运算方法，在本篇中，我们将进一步了解浮点数在计算机中的相关知识。
二进制小数 表示方法 二进制小数表达方式：在“二进制小数点”左侧的位表示 2 的 n 次幂，而在“二进制小数点”右侧的位则表示 2 的 -n 次幂。如下图：
用公式表达如下：
$$ a = \sum_{k=-j}^{i}b_{k} \times 2^{k} $$
示例 例如，将十进制小数转换为二进制小数，有以下例子：
十进制小数 二进制小数 $ 5\frac{3}{4} $ 101.11 $ 2\frac{7}{8} $ 10.111 $ 1\frac{7}{16} $ 1.0111 以第一个为例，我们可以注意到二进制小数按位进行求和的结果是：
$$ 5\frac{3}{4} = 2^{2}+2^{0}+2^{-1}+2^{-2} $$
通过上面三个例子，我们可以注意到，当二进制小数整体右移一位，即相当于将十进制小数除以 2（仅针对无符号数）。相应的，当二进制小数整体左移一位，即相当于将十进制小数乘以 2。
同时我们应特别注意到，形如 $ 0.11111&amp;hellip;_{2} $ 的二进制小数，表示略比 1 小的十进制数。用公式表示如下：
$$ 1/2 + 1/4 + 1/8 + \dots + 1/2^{i} + \dots \to 1.</description></item><item><title>初识 Nginx（二）</title><link>https://sudrizzz.github.io/posts/getting-to-know-nginx-2/</link><pubDate>Fri, 11 Sep 2020 19:51:07 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-nginx-2/</guid><description>应用示例 本篇文章中所使用的 Nginx 是通过下载软件包手动编译安装的，详见 上一篇文章 离线安装部分。
在上一篇文章中，我们初步接触了 Nginx 的安装以及使用方法。在本篇文章中我们将以具体的静态网页作为例子，来详细介绍 Nginx 的部分细节。
文件准备 我们以 C++ 文档 dlib 为例做介绍，官网 http://dlib.net，点击左下角的 Download 按钮并将下载好的文件解压。将文件夹中的 docs 目录内容复制到 Nginx 安装目录中的 dlib 目录中。相关的目录结构如下。
1drwxr-xr-x. 9 root root 258 9月 11 16:54 blog 2drwx------. 2 nobody root 6 9月 6 15:26 client_body_temp 3drwxr-xr-x. 2 root root 4096 9月 11 19:48 conf 4drwxrwxrwx. 10 root root 8192 8月 9 03:30 dlib 5drwx------. 2 nobody root 6 9月 6 15:26 fastcgi_temp 6drwxr-xr-x.</description></item><item><title>初识 Nginx</title><link>https://sudrizzz.github.io/posts/getting-to-know-nginx/</link><pubDate>Mon, 07 Sep 2020 15:47:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-nginx/</guid><description>Nginx 简介 简介内容来自 Nginx 官网 http://nginx.org/en
nginx [engine x] is an HTTP and reverse proxy server, a mail proxy server, and a generic TCP/UDP proxy server, originally written by Igor Sysoev. For a long time, it has been running on many heavily loaded Russian sites including Yandex, Mail.Ru, VK, and Rambler. According to Netcraft, nginx served or proxied 25.75% busiest sites in August 2020. Here are some of the success stories: Dropbox, Netflix, Wordpress.</description></item><item><title>CMU 15-213 位、字节与整数</title><link>https://sudrizzz.github.io/posts/cmu-15-213-lesson1/</link><pubDate>Fri, 04 Sep 2020 19:02:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/cmu-15-213-lesson1/</guid><description>简介 CSAPP 课程全程 Computer Systems: A Programmer’s Perspective，中文翻译为“从程序员的视角，看计算机系统！”或“深入理解计算机系统”。此课程是卡耐基梅隆大学开设的一门课程，官方网站 https://www.cs.cmu.edu/~213/index.html。
内容简介节选自豆瓣
https://book.douban.com/subject/1230413
从程序员的视角，看计算机系统！
本书适用于那些想要写出更快、更可靠程序的程序员。通过掌握程序是如何映射到系统上，以及程序是如何执行的，读者能够更好的理解程序的行为为什么是这样的，以及效率低下是如何造成的。粗略来看，计算机系统包括处理器和存储器硬件、编译器、操作系统和网络互连环境。而通过程序员的视角，读者可以清晰地明白学习计算机系统的内部工作原理会对他们今后作为计算机科学研究者和工程师的工作有进一步的帮助。它还有助于为进一步学习计算机体系结构、操作系统、编译器和网络互连做好准备。
一切皆位 十进制 在计算机发展历史上，实际上只有宾夕法尼亚大学建立的第一台计算机 ENIAC 使用了十进制进行了算术运算，他们使用 10 个电子管来表示每个数字。所以他们通过控制电子管的开关来表示 10 个数字中的其中一个。
二进制 随着计算机的发展，十进制逐渐演化为二进制。在计算机中，我们使用电学层面上的电压高低来存储位数据，如图所示，高电压（0.9v-1.1v）记作逻辑 1，而低电压（0.0v-0.2v）记作逻辑 0。
之所以这么做，是因为通过区分高低电压，可以有效地过滤噪声和杂讯。
十六进制 二进制的成功运用也带来了一个问题，由于每一个位只能存储两种信号（即 0 和 1），对于人来说基本属于不可读的，所以我们将每四个二进制在位合并为一个十六进制位，这样大大缩减了数据的展示长度。例如
具体数据类型实际所占空间 此处以 C 语言数据类型为例，因为在 32 位与 64 位机器上所占空间不尽相同，故列下表。
C Data Type Typical 32-bit Typical 64-bit x86-64 char 1 1 1 short 2 2 2 int 4 4 4 long 4 8 8 float 4 4 4 double 8 8 8 pointer 4 8 8 位操作 与、或、非、异或 通俗的解释如下：</description></item><item><title>初识 Docker</title><link>https://sudrizzz.github.io/posts/getting-to-know-docker/</link><pubDate>Wed, 02 Sep 2020 18:37:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-docker/</guid><description>Docker 简介 简介来自于 Docker 入门教程 - 阮一峰的网络日志
Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。
Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。
总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。
安装 Docker 在此部分，作者使用的是 Centos 8.2 进行的操作，下述的安装命令仅保证在该环境下运行。
设置 Docker 仓库 根据官方教程，执行以下两条命令：
1sudo yum install -y yum-utils 2 3sudo yum-config-manager \ 4 --add-repo \ 5 http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 由于国内直接连接 Docker 官方镜像源十分缓慢，所以在第二个命令中将官方镜像源替换为阿里云镜像源。
安装 Docker 引擎 1sudo yum install docker-ce docker-ce-cli containerd.io 在执行这条命令时，极有可能会报错。比如作者遇到的报错如下：
1Error: 2 Problem: package docker-ce-3:19.03.8-3.el7.x86_64 requires containerd.io &amp;gt;= 1.2.2-3, but none of the providers can be installed 3 - cannot install the best candidate for the job 4 - package containerd.</description></item><item><title>Github 自动部署与图床</title><link>https://sudrizzz.github.io/posts/integrating-with-github-action/</link><pubDate>Sun, 09 Aug 2020 15:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/integrating-with-github-action/</guid><description>前情提要 在前文中我们实现了在 Github 中部署博客，此文将简化发文操作步骤，并实现文章图片管理。
创建仓库 注意：
由于 username 不方便叙述，故下文中均以 sudrizzz 为例替代 username，
请根据实际情况进行更改。
在上文中我们已经创建了一个名为 &amp;lt;username&amp;gt;.github.io 的仓库，现在还需要创建另一个仓库来存放文章管理文件。仓库名任意，公有与私有均可。
文章管理仓库：sudrizzz/blog_workflow 文章编译输出仓库：sudrizzz/sudrizzz.github.io 拆分文件 上文中我们只是将 /public 文件夹提交到了 sudrizzz.github.io 仓库，现在我们还需要将除了 /public 以外的文件全部提交到 blog_workflow，实现这一步可以再本地建立两个对应的文件夹，分别进行提交，操作步骤不再赘述，拆分后的目录结构如下。
1blog_workflow 仓库 2 3├─archetypes 4├─content 5│ └─cn 6│ └─posts 7├─layouts 8├─resources 9│ └─_gen 10└─themes 11 └─yinyang 12 ├─... 13 14 15sudrizzz.github.io 仓库 16 17├─categories 18│ └─test 19├─css 20│ └─highlight 21├─fonts 22├─images 23├─js 24├─posts 25│ └─test 26└─tags 配置公私密钥 生成密钥 打开 Git Bash，执行如下命令</description></item><item><title>从零搭建 Github Pages</title><link>https://sudrizzz.github.io/posts/build-blog-from-scratch/</link><pubDate>Sun, 09 Aug 2020 12:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/build-blog-from-scratch/</guid><description>创建仓库 首先需要在 Github 中创建一个名为 &amp;lt;username&amp;gt;.github.io 的仓库，其中 &amp;lt;username&amp;gt; 为你的 Github 用户名。
注意：
由于 username 不方便叙述，故下文中均以 sudrizzz 为例替代 username，
请根据实际情况进行更改。
例如我的 Github 用户名是 sudrizzz，于是创建的仓库名就是 sudrizzz.github.io。
初始化 Hugo 安装 Hugo 应用 https://github.com/gohugoio/hugo/releases
配置环境变量 将安装 Hugo 的目录路径配置到用户环境变量 PATH 中，如图 检验配置 在命令行窗口中输入以下内容
1hugo version 如果得到类似以下的结果则说明配置正确。
1Hugo Static Site Generator v0.74.3-DA0437B4 windows/amd64 BuildDate: 2020-07-23T16:23:30Z 创建博客 在命令行中输入以下命令
1hugo new site &amp;lt;blog_name&amp;gt; 上述命令将会创建一个名为 blog_name 的文件夹，请按照个人喜好取名。按照我的博客为例，取名为 sudrizzz.github.io，这样也方便后续进行代码提交
添加主题 以 yinyang 主题为例，按照文档中的安装步骤，执行以下命令
1cd sudrizzz.github.io 2git clone git@github.com:joway/hugo-theme-yinyang.git themes/yinyang 进入 sudrizzz.</description></item><item><title>The meaning of life</title><link>https://sudrizzz.github.io/posts/the-meaning-of-life/</link><pubDate>Fri, 21 Jun 2019 00:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/the-meaning-of-life/</guid><description>……我细读来书，终觉得你不免作茧自缚。你自己去寻出一个本不成问题的问题，“人生有何意义？”其实这个问题是容易解答的。人生的意义全是各人自己寻出来、造出来的：高尚、卑劣、清贵、污浊、有用、无用，……全靠自己的作为。
 生命本身不过是一件生物学的事实，有什么意义可说？一个人与一只猎，一只狗，有什么分别？人生的意义不在于何以有生，而在自己怎样生活。你若情愿把这六尺之躯葬送在白昼作梦之上二那就是你这一生的意义。你若发愤振作起来，决心去寻求生命的意义，去创造自己的生命的意义，那么，你活一日便有一日的意义，作一事便添一事的意义，生命无穷，生命的意义也无穷了。
 总之，生命本没有意义，你要能给他什么意义，他就有什么意义。与其终日冥想人生有何意义，不如试用此生作点有意义的事……
 节选自《答某君书》—— 胡适</description></item></channel></rss>