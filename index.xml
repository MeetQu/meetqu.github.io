<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Anthony's blog</title><link>https://sudrizzz.github.io/</link><description>Recent content on Anthony's blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 16 Feb 2021 08:00:00 +0800</lastBuildDate><atom:link href="https://sudrizzz.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>《机器学习》笔记（第五章）</title><link>https://sudrizzz.github.io/posts/machine-learning-note-4/</link><pubDate>Tue, 16 Feb 2021 08:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/machine-learning-note-4/</guid><description>&lt;h1 id="5-神经网络">5 神经网络&lt;/h1>
&lt;h2 id="51-神经元模型">5.1 神经元模型&lt;/h2>
&lt;p>神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。我们在机器学习中谈论神经网络时指的是“神经网络学习”。&lt;/p>
&lt;p>神经网络中最基本的成分是神经元（neuron）模型，即上述定义中的“简单单元”。在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个“阈值”（threshold），那么它就会被激活。即“兴奋”起来，向其他神经元发送化学物质。&lt;/p>
&lt;p>1943 年，[McCulloch and Pitts,1943] 将上述情形抽象为下图所示的简单模型，这就是一直沿用至今的“M-P 神经元模型”。在这个模型中，神经元接收到来自 n 个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接（connection）进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过“激活函数”（activation function）处理以产生神经元的输出。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210218140107.png" alt="20210218140107" />&lt;/p>
&lt;p>激活函数是将输入值映射为输出值“0”或“1”的一类函数，“0”代表神经元抑制，“1”代表神经元兴奋。常见的激活函数主要包括三种：阶跃函数，Sigmoid 函数和 ReLU 函数。&lt;/p>
&lt;ol>
&lt;li>阶跃函数&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210218142053.png" alt="20210218142053" />&lt;/p>
&lt;p>$$
f(x) = \begin{cases}
0, &amp;amp;x&amp;lt;0; \\ 1, &amp;amp;x=0;
\end{cases}
$$&lt;/p>
&lt;ol start="2">
&lt;li>Sigmoid 函数&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210218142227.png" alt="20210218142227" />&lt;/p>
&lt;p>$$ f(x) = \frac{1}{1+e^{-x}} $$&lt;/p>
&lt;ol start="3">
&lt;li>ReLU 函数&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210218142335.png" alt="20210218142335" />&lt;/p>
&lt;p>$$
f(x) = \begin{cases}
0, &amp;amp;x&amp;lt;0; \\ x, &amp;amp;x&amp;gt;0;
\end{cases}
$$&lt;/p>
&lt;h2 id="52-感知机与多层网络">5.2 感知机与多层网络&lt;/h2>
&lt;p>感知机（Perceptron）由两层神经元组成，如下图所示，输入层接收外界输入信号后传递给输出层，输出层是 M-P 神经元，亦称“阈值逻辑单元”（threshold logic unit）。感知机能容易地实现逻辑与、或、非运算。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210218143036.png" alt="20210218143036" />&lt;/p>
&lt;p>需注意的是,感知机只有输出层神经元进行激活函数处理,即只拥有一层功能神经元（functional neuron），其学习能力非常有限。&lt;/p>
&lt;p>一般的，常见的神经网络是形如下图所示的层级结构，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。这样的神经网络结构通常称为“多层前馈神经网络”（multi-layer feedforward neural networks），其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行加工，最终结果由输出层神经元输出；换言之，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元。因此，下图通常被称为“两层网络”或“单隐层网络”。只需包含隐层，即可称为多层网络。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210218145023.png" alt="20210218145023" />&lt;/p>
&lt;p>&lt;strong>神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权”（connection weight）以及每个功能神经元的阈值；换言之，神经网络“学”到的东西，蕴涵在连接权与阈值中。&lt;/strong>&lt;/p>
&lt;h2 id="53-误差逆传播算法">5.3 误差逆传播算法&lt;/h2>
&lt;p>多层网络的学习能力比单层感知机强得多．欲训练多层网络，需要更强大的学习算法。误差逆传播（errorBackPropagation，简称 BP）算法就是其中最杰出的代表，它是迄今最成功的神经网络学习算法。现实任务中使用神经网络时，大多是在使用 BP 算法进行训练。值得指出的是，BP 算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络。但通常说“BP 网络”时，一般是指用 BP 算法训练的多层前馈神经网络。&lt;/p>
&lt;p>对每个训练样例, BP 算法执行以下操作：&lt;/p>
&lt;ol>
&lt;li>先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果&lt;/li>
&lt;li>然后计算输出层的误差，再将误差逆向传播至隐层神经元&lt;/li>
&lt;li>最后根据隐层神经元的误差来对连接权和阈值进行调整&lt;/li>
&lt;/ol>
&lt;p>该迭代过程循环进行，直到达到某些停止条件为止，例如训练误差已达到一个很小的值。&lt;/p>
&lt;p>需要注意的是，BP 算法的目标是要最小化训练集 $D$ 上的累计误差&lt;/p>
&lt;p>$$ E = \frac{1}{m} \sum_{k=1}^{m}{E_k} $$&lt;/p>
&lt;p>[Hornik et al., 1989]证明，只需一个包含足够多神经元的隐层，多层前馈网络就能以任意精度逼近任意复杂度的连续函数。然而，如何设置隐层神经元的个数仍是个未决问题，实际应用中通常靠“试错法”（trial-by-error）调整。&lt;/p>
&lt;p>正是由于其强大的表示能力，BP 神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。有两种策略常用来缓解 BP 网络的过拟合：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>早停&lt;/strong>（early stopping）：将数据分成训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值&lt;/li>
&lt;li>&lt;strong>正则化&lt;/strong>（regularization），其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分。&lt;/li>
&lt;/ol>
&lt;h2 id="54-全局最小与局部极小">5.4 全局最小与局部极小&lt;/h2>
&lt;p>参数空间内梯度为零的点，只要其误差函数值小于邻点的误差函数值，就是局部极小点；可能存在多个局部极小值，但却只会有一个全局最小值。也就是说，“全局最小”一定是“局部极小”，反之则不成立。&lt;/p>
&lt;p>基于梯度的搜索是使用最为广泛的参数寻优方法。在此类方法中，我们从某些初始解出发，迭代寻找最优参数值。每次迭代中,我们先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向。例如，由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索最优解。若误差函数在当前点的梯度为零，则已达到局部极小，更新量将为零，这意味着参数的迭代更新将在此停止。显然，如果误差函数仅有一个局部极小，那么此时找到的局部极小就是全局最小；然而，如果误差函数具有多个局部极小，则不能保证找到的解是全局最小。对后一种情形，我们称参数寻优陷入了局部极小，这显然不是我们所希望的。&lt;/p>
&lt;p>在现实任务中，人们常采用以下策略来试图“跳出”局部极小，从而进一步接近全局最小：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数&lt;/strong>。这相当于从多个不同的初始点开始搜索。这样就可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。&lt;/li>
&lt;li>使用&lt;strong>模拟退火&lt;/strong>（simulated annealing）技术。模拟退火在每一步都以一定的概率接受比当前解更差的结果，从而有助于“跳出”局部极小。在每步迭代过程中，接受“次优解”的概率要随着时间的推移而逐渐降低，从而保证算法稳定。&lt;/li>
&lt;li>使用&lt;strong>随机梯度下降&lt;/strong>。与标准梯度下降法精确计算梯度不同，随机梯度下降法在计算梯度时加入了随机因素。于是，即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小继续搜索。&lt;/li>
&lt;/ul>
&lt;p>此外，遗传算法（genetic algorithms）也常用来训练神经网络以更好地逼近全局最小。&lt;/p>
&lt;h2 id="56-深度学习">5.6 深度学习&lt;/h2>
&lt;p>典型的深度学习模型就是很深层的神经网络。显然，对神经网络模型，提高容量的一个简单办法是增加隐层的数目。隐层多了，相应的神经元连接权、阈值等参数就会更多。模型复杂度也可通过单纯增加隐层神经元的数目来实现，前面我们谈到过，单隐层的多层前馈网络已具有很强大的学习能力；但从增加模型复杂度的角度来看，增加隐层的数目显然比增加隐层神经元的数目更有效，因为增加隐层数不仅增加了拥有激活函数的神经元数目，还增加了激活函数嵌套的层数。然而，多隐层神经网络难以直接用经典算法（例如标准 BP 算法）进行训练，因为误差在多隐层内逆传播时，往往会“发散”（diverge）而不能收敛到稳定状态。&lt;/p>
&lt;p>无监督逐层训练（unsupervised layer-wise training）是多隐层网络训练的有效手段，其基本思想是每次训练一层隐结点，训练时将上一层隐结点的输出作为输入，而本层隐结点的输出作为下一层隐结点的输入，这称为“预训练”（pre-training）；在预训练全部完成后，再对整个网络进行“微调”（fine-tuning）训练。&lt;/p>
&lt;p>事实上，“预训练+微调”的做法可视为将大量参数分组，对每组先找到局部看来比较好的设置，然后再基于这些局部较优的结果联合起来进行全局寻优。这样就在利用了模型大量参数所提供的自由度的同时，有效地节省了训练开销。&lt;/p>
&lt;p>另一种节省训练开销的策略是“权共享”（weight sharing），即让一组神经元使用相同的连接权。&lt;/p></description></item><item><title>《机器学习》笔记（第四章）</title><link>https://sudrizzz.github.io/posts/machine-learning-note-3/</link><pubDate>Tue, 02 Feb 2021 08:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/machine-learning-note-3/</guid><description>&lt;h1 id="4-决策树">4 决策树&lt;/h1>
&lt;h2 id="41-基本流程">4.1 基本流程&lt;/h2>
&lt;p>一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点；叶结点对应于决策结果，其他每个结点则对应于一个属性测试；每个结点包含的样本集合根据属性测试的结果被划分到子结点中；根结点包含样本全集。从根结点到每个叶结点的路径对应了一个判定测试序列。决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的“分而治之”（divide-and-conquer）策略。&lt;/p>
&lt;h2 id="42-划分选择">4.2 划分选择&lt;/h2>
&lt;p>一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度（purity）越来越高。&lt;/p>
&lt;h3 id="421-信息增益">4.2.1 信息增益&lt;/h3>
&lt;p>信息熵定义为信息的期望值。如果待分类的事物可能划分在多个分类之中，则符号 $x_i$ 的&lt;strong>信息&lt;/strong>定义为&lt;/p>
&lt;p>$$ l(x_i) = -\log_{2} p(x_i) $$&lt;/p>
&lt;p>其中，$p(x_i)$ 是选择该分类的概率。&lt;/p>
&lt;p>则 $D$ 的&lt;strong>信息熵&lt;/strong>定义为&lt;/p>
&lt;p>$$ Ent(D) = -\sum_{i=1}^{n} p(x_i) \log_{2} p(x_i) $$&lt;/p>
&lt;p>其中，$n$ 是分类的数目。$Ent(D)$ 的值越小，则 $D$ 的纯度越高。&lt;/p>
&lt;p>假定离散属性 $a$ 有 $V$ 个可能的取值 ${a^1, a^2,&amp;hellip;, a^V}$，若使用 $a$ 来对样本集 $D$ 进行划分，则会产生 $V$ 个分支结点，其中第 $v$ 个分支结点包含了 $D$ 中所有在属性 $a$ 上取值为 $a^V$ 的样本，记为 $D^V$。我们可根据上式计算出 $D^V$ 的信息熵，再考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重 $|D^v|/|D|$ ，即样本数越多的分支结点的影响越大，于是可计算出用属性 $a$ 对样本集 $D$ 进行划分所获得的“信息增益”(information gain)&lt;/p>
&lt;p>$$ Gain(D, a) = Ent(D) - \sum_{v=1}^{V} \frac{|D^v|}{|D|}Ent(D^v) $$&lt;/p>
&lt;p>一般而言，信息增益越大，则意味着使用属性 $a$ 来进行划分所获得的“纯度提升”越大。因此，我们可用信息增益来进行决策树的划分属性选择。即选择属性：&lt;/p>
&lt;p>$$ a_* = \mathop{argmin}\limits_{a \in A} Gain(D, a) $$&lt;/p>
&lt;h3 id="422-增益率">4.2.2 增益率&lt;/h3>
&lt;p>实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，著名的 C4.5 决策树算法 [Quinlan,1993] 不直接使用信息增益，而是使用“增益率”（gain ratio）来选择最优划分属性。采用与上式相同的符号表示，增益率定义为：&lt;/p>
&lt;p>$$ Gain_ratio(D, a) = \frac{Gain(D, a)}{IV(a)} $$&lt;/p>
&lt;p>其中&lt;/p>
&lt;p>$$ IV(a) = - \sum_{v=1}^{V} \frac{|D^v|}{|D|} log_2 \frac{|D^v|}{|D|} $$&lt;/p>
&lt;p>称为属性 $a$ 的“固有值”。属性 $a$ 的可能取值数目越多（即 $V$ 越大），则 $IV(a)$ 的值通常会越大。&lt;/p>
&lt;p>需注意的是，增益率准则对可取值数目较少的属性有所偏好，因此，C4.5 算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。&lt;/p>
&lt;h3 id="423-基尼指数">4.2.3 基尼指数&lt;/h3>
&lt;p>CART 决策树 [Breiman et al., 1984] 使用“基尼指数”（Gini index）来选择划分属性。数据集 $D$ 的纯度可用基尼值来度量:&lt;/p>
&lt;p>$$ Gini(D) = \sum_{k=1}^{|y|}\sum_{k' \neq k}p_k p_{k'} = 1 - \sum_{k=1}^{|y|}p_k^2 $$&lt;/p>
&lt;p>直观来说，$Gini(D)$ 反映了从数据集 $D$ 中随机抽取两个样本，其类别标记不一致的概率。因此，$Gini(D)$越小，则数据集 $D$ 的纯度越高。属性 $a$ 的基尼指数定义为：&lt;/p>
&lt;p>$$ Gini\_index(D, a) = \sum_{v=1}^V\frac{|D^v|}{|D|}Gini(D^v) $$&lt;/p>
&lt;p>于是，我们在候选属性集合 $A$ 中，选择那个使得划分后基尼指数最小的属性作为最优划分属性，即：&lt;/p>
&lt;p>$$ a_* = \mathop{argmin}\limits_{a \in A} Gini\_index(D, a) $$&lt;/p>
&lt;h2 id="43-剪枝处理">4.3 剪枝处理&lt;/h2>
&lt;p>剪枝（pruning）是决策树学习算法对付“过拟合”的主要手段。&lt;/p>
&lt;p>决策树剪枝的基本策略有“预剪枝”（prepruning）和“后剪枝”（postpruning）。预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点；后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。&lt;/p>
&lt;h3 id="431-预剪枝">4.3.1 预剪枝&lt;/h3>
&lt;p>基于书上 80-82 页的例子可以看出，预剪枝使得决策树的很多分支都没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高；预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策树带来了欠拟合的风险。&lt;/p>
&lt;h3 id="432-后剪枝">4.3.2 后剪枝&lt;/h3>
&lt;p>基于书上 82 页的例子可以看出，后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情形下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。&lt;/p>
&lt;h2 id="44-连续与缺失值">4.4 连续与缺失值&lt;/h2>
&lt;h3 id="441-连续值处理">4.4.1 连续值处理&lt;/h3>
&lt;p>给定样本集 $D$ 和连续属性 $a$，假定 $a$ 在 $D$ 上出现了 $n$ 个不同的取值，将这些值从小到大进行排序，记为 ${a1, a2,&amp;hellip;, a^n}$。基于划分点 $t$ 可将 $D$ 分为子集 $D_t^-$ 和 $D_t^+$，其中 $D_t^-$ 包含那些在属性 $a$ 上取值不大于 $t$ 的样本，而 $D_t^+$ 则包含那些在属性 $a$ 上取值大于 $t$ 的样本。显然，对相邻的属性取值 $a^i$ 与 $a^{i+1}$ 来说，$t$ 在区间 $[a^i, a^{i+1})$ 中取任意值所产生的划分结果相同。因此，对连续属性 $a$，我们可考察包含 $n-1$ 个元素的候选划分点集合&lt;/p>
&lt;p>$$ T_a = {\frac{a^i + a^{i+1}}{2} | 1 \leq i \leq n-1} $$&lt;/p>
&lt;p>即把区间 $[a^i, a^{i+1})$ 的中位点 $\frac{a^i+a^{i+1}}{2}$ 作为候选划分点。然后，我们就可像离散属性值一样来考察这些划分点，选取最优的划分点进行样本集合的划分。&lt;/p>
&lt;p>$$ Gain(D, a) = \max_{t \in T_a} Gain(D, a, t) \\ = \max_{t \in T_a}Ent(D) - \sum_{\lambda \in {-, +}} \frac{|D_t^\lambda|}{D} Ent(D_t^\lambda) $$&lt;/p>
&lt;p>其中 $Gain(D, a, t)$ 是样本集 $D$ 基于划分点 $t$ 二分后的信息增益。于是，我们就可选择使 $Gain(D, a, t)$ 最大化的划分点。&lt;/p>
&lt;h3 id="442-缺失值处理">4.4.2 缺失值处理&lt;/h3>
&lt;p>书中对于属性缺失值的样本仅仅介绍了 C4.5 算法中的处理方法，具体如下：&lt;/p>
&lt;ol>
&lt;li>将属性无缺失值的样本挑选出来形成一个样例子集 $\tilde{D}$&lt;/li>
&lt;li>对 $\tilde{D}$ 做信息熵计算，计算各属性的信息增益&lt;/li>
&lt;li>将各个信息增益还原到全体样本，即 $Gain(D, 属性) = \rho \times Gain(\tilde{D}, 属性)$，其中 $\rho$ 指 $\tilde{D}$ 与 $D$ 的比例&lt;/li>
&lt;li>选择信息增益最大的属性进行划分，并重复上述步骤&lt;/li>
&lt;/ol>
&lt;p>另外，还有其他方法来处理属性缺失值这一情况。&lt;/p>
&lt;p>对于离散值属性，可以采用&lt;strong>众数填充&lt;/strong>或&lt;strong>相关性最高的列填充&lt;/strong>的方式，来填充缺失值。&lt;/p>
&lt;p>对于连续值属性，可以对使用&lt;strong>中位数填充&lt;/strong>，也可以对&lt;strong>相关性最高的列做线性回归进行估计&lt;/strong>。&lt;/p>
&lt;h2 id="45-多变量决策树">4.5 多变量决策树&lt;/h2>
&lt;p>简而言之，单变量决策树（上述决策树）非叶节点，只针对某个（单个）属性取值进行测试分类；而多变量决策树非叶节点，不仅仅局限于单个属性取值，而是对&lt;strong>多个属性取值的线性组合&lt;/strong>进行测试分类。&lt;/p></description></item><item><title>SAE 入门（二）——基于 tiny_dnn 的手写数字重建</title><link>https://sudrizzz.github.io/posts/sae-2/</link><pubDate>Thu, 28 Jan 2021 18:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/sae-2/</guid><description>&lt;h1 id="前言">前言&lt;/h1>
&lt;p>在&lt;a class="link" href="https://sudrizzz.github.io/posts/sae-1/" target="_blank" rel="noopener"
>上一篇文章&lt;/a>中，我们使用 Python 使用 SAE 网络实现了手写数字的重建。在本文中，我们将尝试使用 tiny_dnn 库实现手写数字重建。&lt;/p>
&lt;h1 id="tiny_dnn-简介">tiny_dnn 简介&lt;/h1>
&lt;p>tiny-dnn 项目地址：https://github.com/tiny-dnn/tiny-dnn，这是深度学习的一个 C ++ 14 实现。它适合在有限的计算资源，嵌入式系统和 IoT 设备上进行深度学习。整个项目仅由头文件构成，使用时无需编译，直接引用即可。&lt;/p>
&lt;h1 id="搭建环境">搭建环境&lt;/h1>
&lt;h2 id="版本要求">版本要求&lt;/h2>
&lt;p>需要一个 C++ 14 编译器，例如 gcc 4.9+，clang 3.6+ 或者 VS 2015+。本文中使用 &lt;strong>Visual Studio 2019&lt;/strong> 为例进行配置。&lt;/p>
&lt;h2 id="创建项目">创建项目&lt;/h2>
&lt;p>打开 VS，创建一个名为 testTinyDNN 的&lt;strong>控制台应用&lt;/strong>。将 tiny_dnn 下载解压之后，放置到如下图所示的位置，与 &lt;code>testTinyDNN.cpp&lt;/code> 属于同一层级。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210129112851.png" alt="20210129112851" />&lt;/p>
&lt;h2 id="编辑配置">编辑配置&lt;/h2>
&lt;ol>
&lt;li>编辑 &lt;code>config.h&lt;/code> 文件第 61 行，将其取消注释；这样我们才可以将栈式自编码器预测的图片保存到本地。涉及内容如下：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="ln">1&lt;/span>&lt;span class="cm">/**
&lt;/span>&lt;span class="ln">2&lt;/span>&lt;span class="cm"> * Enable Image API support.
&lt;/span>&lt;span class="ln">3&lt;/span>&lt;span class="cm"> * Currently we use stb by default.
&lt;/span>&lt;span class="ln">4&lt;/span>&lt;span class="cm"> **/&lt;/span>
&lt;span class="ln">5&lt;/span>&lt;span class="cp">#define DNN_USE_IMAGE_API
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>编辑 &lt;code>image.h&lt;/code> 文件第 378 行，将 &lt;code>border_width&lt;/code> 值设置为 0，这样保存的图片每个像素周围就不会存在白色边框。涉及内容如下：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="ln">1&lt;/span>&lt;span class="k">const&lt;/span> &lt;span class="n">size_t&lt;/span> &lt;span class="n">border_width&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="编写代码">编写代码&lt;/h2>
&lt;p>打开 &lt;code>testTinyDNN.cpp&lt;/code> 文件，将下列代码粘贴进去。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="ln"> 1&lt;/span>&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;iostream&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;span class="ln"> 2&lt;/span>&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;string&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;span class="ln"> 3&lt;/span>&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;#34;tiny_dnn/tiny_dnn.h&amp;#34;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;span class="ln"> 4&lt;/span>&lt;span class="cp">&lt;/span>&lt;span class="k">using&lt;/span> &lt;span class="k">namespace&lt;/span> &lt;span class="n">tiny_dnn&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="k">using&lt;/span> &lt;span class="k">namespace&lt;/span> &lt;span class="n">tiny_dnn&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">activation&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln"> 6&lt;/span>&lt;span class="k">using&lt;/span> &lt;span class="k">namespace&lt;/span> &lt;span class="n">tiny_dnn&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="k">using&lt;/span> &lt;span class="k">namespace&lt;/span> &lt;span class="n">std&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln"> 8&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="cp">#define EPOCHS 50
&lt;/span>&lt;span class="ln">10&lt;/span>&lt;span class="cp">#define BATCH_SIZE 256
&lt;/span>&lt;span class="ln">11&lt;/span>&lt;span class="cp">&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="nf">sae&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="c1">// define network, optimizer and engine
&lt;/span>&lt;span class="ln">14&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">network&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">sequential&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">net&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="n">adam&lt;/span> &lt;span class="n">optimizer&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="n">core&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">backend_t&lt;/span> &lt;span class="n">backend_type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">core&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">default_engine&lt;/span>&lt;span class="p">();&lt;/span>
&lt;span class="ln">17&lt;/span>
&lt;span class="ln">18&lt;/span> &lt;span class="c1">// construct network layers, include 3 encoder layers and 3 decoder layers
&lt;/span>&lt;span class="ln">19&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">net&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">fully_connected_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">784&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">true&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">backend_type&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">relu&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">20&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">fully_connected_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">true&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">backend_type&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">relu&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">21&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">fully_connected_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">true&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">backend_type&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">relu&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">22&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">fully_connected_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">true&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">backend_type&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">relu&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">23&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">fully_connected_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">true&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">backend_type&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">sigmoid&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">24&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">fully_connected_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">784&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">true&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">backend_type&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">25&lt;/span>
&lt;span class="ln">26&lt;/span> &lt;span class="c1">// load MNIST dataset
&lt;/span>&lt;span class="ln">27&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">vector&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">vec_t&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">train_images&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">test_images&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">28&lt;/span> &lt;span class="n">string&lt;/span> &lt;span class="n">data_dir_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;tiny_dnn/data&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">29&lt;/span> &lt;span class="n">parse_mnist_images&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_dir_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;/train-images.idx3-ubyte&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">30&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">train_images&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">31&lt;/span> &lt;span class="n">parse_mnist_images&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_dir_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;/t10k-images.idx3-ubyte&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">32&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">test_images&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">33&lt;/span>
&lt;span class="ln">34&lt;/span> &lt;span class="n">cout&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="s">&amp;#34;start training&amp;#34;&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">endl&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">35&lt;/span>
&lt;span class="ln">36&lt;/span> &lt;span class="c1">// define learning rate (0.05)
&lt;/span>&lt;span class="ln">37&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">optimizer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">alpha&lt;/span> &lt;span class="o">*=&lt;/span> &lt;span class="k">static_cast&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">tiny_dnn&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">float_t&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.05&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">38&lt;/span>
&lt;span class="ln">39&lt;/span> &lt;span class="c1">// display training progress bar, and show training duration
&lt;/span>&lt;span class="ln">40&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">progress_display&lt;/span> &lt;span class="n">disp&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">static_cast&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_images&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="p">()));&lt;/span>
&lt;span class="ln">41&lt;/span> &lt;span class="n">timer&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">42&lt;/span>
&lt;span class="ln">43&lt;/span> &lt;span class="c1">// create callback
&lt;/span>&lt;span class="ln">44&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">45&lt;/span> &lt;span class="k">auto&lt;/span> &lt;span class="n">on_enumerate_epoch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="p">]()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">46&lt;/span> &lt;span class="n">epoch&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">47&lt;/span> &lt;span class="n">cout&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="s">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">elapsed&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="s">&amp;#34;s elapsed.&amp;#34;&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">endl&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">48&lt;/span> &lt;span class="n">cout&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="s">&amp;#34;epoch=&amp;#34;&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="s">&amp;#34;/&amp;#34;&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">EPOCHS&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">endl&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">49&lt;/span> &lt;span class="n">disp&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">restart&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">static_cast&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_images&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="p">()));&lt;/span>
&lt;span class="ln">50&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">restart&lt;/span>&lt;span class="p">();&lt;/span>
&lt;span class="ln">51&lt;/span> &lt;span class="p">};&lt;/span>
&lt;span class="ln">52&lt;/span>
&lt;span class="ln">53&lt;/span> &lt;span class="k">auto&lt;/span> &lt;span class="n">on_enumerate_minibatch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="p">]()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">54&lt;/span> &lt;span class="n">disp&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">BATCH_SIZE&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">55&lt;/span> &lt;span class="p">};&lt;/span>
&lt;span class="ln">56&lt;/span>
&lt;span class="ln">57&lt;/span> &lt;span class="c1">// training
&lt;/span>&lt;span class="ln">58&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">net&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">fit&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">mse&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">optimizer&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train_images&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train_images&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">BATCH_SIZE&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">EPOCHS&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">59&lt;/span> &lt;span class="n">on_enumerate_minibatch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">on_enumerate_epoch&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">60&lt;/span>
&lt;span class="ln">61&lt;/span> &lt;span class="c1">// save model
&lt;/span>&lt;span class="ln">62&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">net&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;sae-net&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">63&lt;/span> &lt;span class="n">cout&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="s">&amp;#34;end training.&amp;#34;&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">endl&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">64&lt;/span>
&lt;span class="ln">65&lt;/span> &lt;span class="c1">// if the model already exists, you can read it directly
&lt;/span>&lt;span class="ln">66&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">//net.load(&amp;#34;sae-net&amp;#34;);
&lt;/span>&lt;span class="ln">67&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="ln">68&lt;/span> &lt;span class="c1">// save layers to image
&lt;/span>&lt;span class="ln">69&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">//for (size_t i = 0; i &amp;lt; net.depth(); i++) {
&lt;/span>&lt;span class="ln">70&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// auto out_img = net[i]-&amp;gt;output_to_image();
&lt;/span>&lt;span class="ln">71&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// auto filename = &amp;#34;layer_&amp;#34; + to_string(i) + &amp;#34;.bmp&amp;#34;;
&lt;/span>&lt;span class="ln">72&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// out_img.save(filename);
&lt;/span>&lt;span class="ln">73&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">//}
&lt;/span>&lt;span class="ln">74&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="ln">75&lt;/span> &lt;span class="c1">// test and show results
&lt;/span>&lt;span class="ln">76&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">77&lt;/span> &lt;span class="c1">// get predicted result image
&lt;/span>&lt;span class="ln">78&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">auto&lt;/span> &lt;span class="n">predict&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">net&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">test_images&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]);&lt;/span>
&lt;span class="ln">79&lt;/span>
&lt;span class="ln">80&lt;/span> &lt;span class="c1">// save predicted result image to file
&lt;/span>&lt;span class="ln">81&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">auto&lt;/span> &lt;span class="n">image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">vec2image&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">float&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">predict&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">82&lt;/span> &lt;span class="k">auto&lt;/span> &lt;span class="n">filename&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;image_predicted_&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">to_string&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;.bmp&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">83&lt;/span> &lt;span class="n">image&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">84&lt;/span>
&lt;span class="ln">85&lt;/span> &lt;span class="c1">// save the origin test image to file
&lt;/span>&lt;span class="ln">86&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">vec2image&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">float&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">test_images&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">87&lt;/span> &lt;span class="n">filename&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;image_test_&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">to_string&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;.bmp&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">88&lt;/span> &lt;span class="n">image&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="ln">89&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="ln">90&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="ln">91&lt;/span>
&lt;span class="ln">92&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">93&lt;/span> &lt;span class="n">sae&lt;/span>&lt;span class="p">();&lt;/span>
&lt;span class="ln">94&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在代码中，我们定义了每批次训练数据量为 256 条，总共训练 50 个批次。&lt;/p>
&lt;p>网络结构为 3 个编码层 + 3 个解码层。编码层将数据从 784（28 * 28） 维分别编码（降维）到 128、64、32 维，解码器再将 32 维的编码结果解码（升维）到 64、128、784 维，完成手写数字重建。各层之间的激活函数选用 &lt;code>relu()&lt;/code> 与 &lt;code>sigmoid()&lt;/code>。&lt;/p>
&lt;h1 id="结果展示">结果展示&lt;/h1>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210129163100.png" alt="20210129163100" />&lt;/p>
&lt;p>从上到下，第一行为测试图像，第二行为 keras 搭建的 SAE 网络重建图像，第三行为 tiny_dnn 搭建的 SAE 网络重建图像。下面展示数字 2 和 5 重建的详细效果，左侧为 Python 平台重建结果，右侧为 C++ 平台重建结果。&lt;/p>
&lt;p>数字 2&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210129182201.png" alt="20210129182201" />&lt;/p>
&lt;p>数字 5&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210129181931.png" alt="20210129181931" />&lt;/p>
&lt;h1 id="性能对比">性能对比&lt;/h1>
&lt;p>测试使用的 CPU 型号为 Intel i5-4200H，基准频率为 2.80GHz。&lt;/p>
&lt;p>基于 tiny_dnn 的 C++ 平台训练时长为 2624.95 秒，基于 keras 的 Python 平台训练时长为 135.70 秒。在 50 个 epoch 测试中，Python 平台比 C++ 平台快了大约 19 倍，Python 平台 loss 大约为 0.08。由重建图片结果不难看出，Python 平台效果明显优于 C++ 平台。&lt;/p>
&lt;h1 id="存在的不足">存在的不足&lt;/h1>
&lt;ol>
&lt;li>C++ 平台目前无法计算每个 epoch 的 loss；&lt;/li>
&lt;li>将在 C++ 平台测试更多的 epoch，观察图像重建效果是否会有改善。&lt;/li>
&lt;/ol>
&lt;h1 id="参考文献">参考文献&lt;/h1>
&lt;ol>
&lt;li>&lt;a class="link" href="https://mightynotes.wordpress.com/2017/10/11/a-simple-and-basic-tutorial-of-tiny-dnn/" target="_blank" rel="noopener"
>A simple and basic tutorial of tiny-dnn&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://tiny-dnn.readthedocs.io/en/latest/getting_started/Getting-started.html" target="_blank" rel="noopener"
>A quick introduction to tiny-dnn&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://tiny-dnn.readthedocs.io/en/latest/how_tos/How-Tos.html#construct-the-network-model" target="_blank" rel="noopener"
>Details about tiny-dnn’s API and short examples&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>SAE 入门（一）</title><link>https://sudrizzz.github.io/posts/sae-1/</link><pubDate>Wed, 20 Jan 2021 18:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/sae-1/</guid><description>&lt;h1 id="autoencoder-简介">Autoencoder 简介&lt;/h1>
&lt;p>自编码器（Autoencoder，AE），是一种利用反向传播（backpropagation，BP）算法&lt;strong>使得输出值等于输入值&lt;/strong>的神经网络，它先将输入压缩成潜在空间表征，然后通过这种表征来重构输出。其中，空间表征可以看作是输入数据的高级抽象，通常是将高维度的数据抽象为低维度的数据。&lt;/p>
&lt;p>自编码器由两部分组成：&lt;br>
编码器：这部分能将输入压缩成潜在空间表征，可以用编码函数 $h=f(x)$ 表示;&lt;br>
解码器：这部分能重构来自潜在空间表征的输入，可以用解码函数 $r=g(h)$ 表示。&lt;/p>
&lt;p>因此，整个自编码器可以用函数 $g(f(x)) = r$ 来描述，其中输出 $r$ 与原始输入 $x$ 相近。&lt;/p>
&lt;p>自动编码器的目标是最大程度地减少输入和输出之间的重构误差。这有助于自动编码器学习数据中存在的重要功能。当表征很好地重建其输入时，则表示这个表征很好地保留了输入中存在的许多信息。整个过程如下图。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210122142001.png" alt="20210122142001" />&lt;/p>
&lt;h1 id="stacked-autoencoder-简介">Stacked Autoencoder 简介&lt;/h1>
&lt;p>Stacked Autoencoder 简写作 SAE。SAE 与 AE 的主要区别在于编码器与解码器的层数，栈式自编码器包含多层隐藏层。具体网络结构如下图所示，图中有两层编码层，两层解码层。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210122154135.png" alt="20210122154135" />&lt;/p>
&lt;h1 id="代码实现">代码实现&lt;/h1>
&lt;blockquote>
&lt;p>代码环境配置，请参考 &lt;a class="link" href="https://sudrizzz.github.io/posts/gan-for-hand-written-digits/" target="_blank" rel="noopener"
>GAN 网络之手写数字生成&lt;/a> 第一小节——环境搭建。&lt;/p>
&lt;/blockquote>
&lt;p>自编码器只是一种思想，在具体实现中，编码器和解码器可以由多种深度学习模型构成，例如全连接层、卷积层和 LSTM 等，以下使用 Keras 来实现栈式自编码器。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln"> 1&lt;/span>&lt;span class="kn">from&lt;/span> &lt;span class="nn">keras.datasets&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">mnist&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kn">from&lt;/span> &lt;span class="nn">keras.layers&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Input&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Dense&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="kn">from&lt;/span> &lt;span class="nn">keras.models&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Model&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;span class="ln"> 6&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="n">EPOCHS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">50&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="n">BATCH_SIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">256&lt;/span>
&lt;span class="ln"> 9&lt;/span>
&lt;span class="ln">10&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">train&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_test&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="n">input_img&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Input&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">784&lt;/span>&lt;span class="p">,))&lt;/span>
&lt;span class="ln">13&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="c1"># 三个编码层，将数据从 784 维向量编码为 128、64、32 维向量&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="n">encoded&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">units&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;relu&amp;#39;&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">input_img&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="n">encoded&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">units&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;relu&amp;#39;&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">encoded&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">17&lt;/span> &lt;span class="n">encoded&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">units&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;relu&amp;#39;&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">encoded&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">18&lt;/span>
&lt;span class="ln">19&lt;/span> &lt;span class="c1"># 三个解码层，将数据从 32 维向量解码成 64、128、784 维向量&lt;/span>
&lt;span class="ln">20&lt;/span> &lt;span class="n">decoded&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">units&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;relu&amp;#39;&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">encoded&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">21&lt;/span> &lt;span class="n">decoded&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">units&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;relu&amp;#39;&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">decoded&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">22&lt;/span> &lt;span class="n">decoded&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">units&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">784&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;sigmoid&amp;#39;&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">decoded&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">23&lt;/span> &lt;span class="n">autoencoder&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">input_img&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">decoded&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">24&lt;/span> &lt;span class="n">encoder&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">input_img&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">encoded&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">25&lt;/span>
&lt;span class="ln">26&lt;/span> &lt;span class="n">autoencoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">summary&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">27&lt;/span> &lt;span class="n">encoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">summary&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">28&lt;/span>
&lt;span class="ln">29&lt;/span> &lt;span class="n">autoencoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">compile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">optimizer&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;adam&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;binary_crossentropy&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metrics&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;accuracy&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln">30&lt;/span> &lt;span class="n">autoencoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">31&lt;/span> &lt;span class="n">epochs&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">EPOCHS&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">32&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">BATCH_SIZE&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">33&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">34&lt;/span> &lt;span class="n">validation_data&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_test&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">35&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">encoder&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">autoencoder&lt;/span>
&lt;span class="ln">36&lt;/span>
&lt;span class="ln">37&lt;/span>
&lt;span class="ln">38&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">encoded_imgs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">decoded_imgs&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln">39&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">figure&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">figsize&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">40&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln">41&lt;/span> &lt;span class="c1"># 展示原始输入图像&lt;/span>
&lt;span class="ln">42&lt;/span> &lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">43&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">44&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">gray&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">45&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_xaxis&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_visible&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">46&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_yaxis&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_visible&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">47&lt;/span>
&lt;span class="ln">48&lt;/span> &lt;span class="c1"># 展示编码后的图像&lt;/span>
&lt;span class="ln">49&lt;/span> &lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">50&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">encoded_imgs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">51&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">gray&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">52&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_xaxis&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_visible&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">53&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_yaxis&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_visible&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">54&lt;/span>
&lt;span class="ln">55&lt;/span> &lt;span class="c1"># 展示解码后的输入图像&lt;/span>
&lt;span class="ln">56&lt;/span> &lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">20&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">57&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">decoded_imgs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">58&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">gray&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">59&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_xaxis&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_visible&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">60&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_yaxis&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_visible&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">61&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">62&lt;/span>
&lt;span class="ln">63&lt;/span>
&lt;span class="ln">64&lt;/span>&lt;span class="k">if&lt;/span> &lt;span class="vm">__name__&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s1">&amp;#39;__main__&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="ln">65&lt;/span> &lt;span class="c1"># 加载数据，训练数据 60000 条，测试数据 10000 条，数据灰度值 [0, 255]&lt;/span>
&lt;span class="ln">66&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mnist&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load_data&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">67&lt;/span>
&lt;span class="ln">68&lt;/span> &lt;span class="c1"># 正则化数据，将灰度值区间转换为 [0, 1]&lt;/span>
&lt;span class="ln">69&lt;/span> &lt;span class="n">x_train&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;float32&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">255&lt;/span>
&lt;span class="ln">70&lt;/span> &lt;span class="n">x_test&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x_test&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;float32&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">255&lt;/span>
&lt;span class="ln">71&lt;/span>
&lt;span class="ln">72&lt;/span> &lt;span class="c1"># 将数据集从二维 (28, 28) 矩阵转换为长度为维度是 784 的向量&lt;/span>
&lt;span class="ln">73&lt;/span> &lt;span class="n">x_train&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">prod&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">:]))&lt;/span>
&lt;span class="ln">74&lt;/span> &lt;span class="n">x_test&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x_test&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">prod&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">:]))&lt;/span>
&lt;span class="ln">75&lt;/span> &lt;span class="k">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">76&lt;/span> &lt;span class="k">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">77&lt;/span>
&lt;span class="ln">78&lt;/span> &lt;span class="c1"># 训练数据&lt;/span>
&lt;span class="ln">79&lt;/span> &lt;span class="n">encoder&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">autoencoder&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_test&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">80&lt;/span>
&lt;span class="ln">81&lt;/span> &lt;span class="c1"># 获取编码后和解码后的图像&lt;/span>
&lt;span class="ln">82&lt;/span> &lt;span class="n">encoded_imgs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">encoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">83&lt;/span> &lt;span class="n">decoded_imgs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">autoencoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">84&lt;/span>
&lt;span class="ln">85&lt;/span> &lt;span class="c1"># 绘制图像&lt;/span>
&lt;span class="ln">86&lt;/span> &lt;span class="n">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">encoded_imgs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">decoded_imgs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>运行上述代码，可以从输出内容中得到以下信息：&lt;/p>
&lt;ol>
&lt;li>输入数据是 60000 张手写数字的灰度图像，灰度取值范围是 [0, 255]，我们将其灰度值按行依次存储到一个 1 * 784 的数组中；&lt;/li>
&lt;li>输入数据形如 (0, 0, 0,&amp;hellip;, 84, 185, 159,&amp;hellip;, 170, 52,&amp;hellip;, 0, 0)，我们可以将每张图片（每个向量）理解为一个 784 维空间的中向量；&lt;/li>
&lt;li>通过正则化后，输入数据每个维度区间变为 [0, 1]；&lt;/li>
&lt;li>编码层将输入的 784 维向量抽象为 128、64、32 维向量（dense，dense_1，dense_2）；&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>Model: &amp;quot;functional_3&amp;quot;
_________________________________________________________________
Layer (type) Output Shape Param #
=================================================================
input_1 (InputLayer) [(None, 784)] 0
_________________________________________________________________
dense (Dense) (None, 128) 100480
_________________________________________________________________
dense_1 (Dense) (None, 64) 8256
_________________________________________________________________
dense_2 (Dense) (None, 32) 2080
=================================================================
Total params: 110,816
Trainable params: 110,816
Non-trainable params: 0
_________________________________________________________________
&lt;/code>&lt;/pre>&lt;ol start="4">
&lt;li>解码层将抽象后的 32 维向量还原维 64、128、784 维向量（dense_3，dense_4，dense_5）；&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>Model: &amp;quot;functional_1&amp;quot;
_________________________________________________________________
Layer (type) Output Shape Param #
=================================================================
input_1 (InputLayer) [(None, 784)] 0
_________________________________________________________________
dense (Dense) (None, 128) 100480
_________________________________________________________________
dense_1 (Dense) (None, 64) 8256
_________________________________________________________________
dense_2 (Dense) (None, 32) 2080
_________________________________________________________________
dense_3 (Dense) (None, 64) 2112
_________________________________________________________________
dense_4 (Dense) (None, 128) 8320
_________________________________________________________________
dense_5 (Dense) (None, 784) 101136
=================================================================
Total params: 222,384
Trainable params: 222,384
Non-trainable params: 0
_________________________________________________________________
&lt;/code>&lt;/pre>&lt;p>训练完成之后，可以在输出内容中看到详细的训练数据，在 50 次训练之后，loss 已经降低到了 0.08。得到的输出图像如下图所示。&lt;/p>
&lt;pre>&lt;code>......
Epoch 48/50
235/235 [==============================] - 3s 12ms/step - loss: 0.0848 - accuracy: 0.0130 - val_loss: 0.0844 - val_accuracy: 0.0147
Epoch 49/50
235/235 [==============================] - 3s 12ms/step - loss: 0.0846 - accuracy: 0.0130 - val_loss: 0.0845 - val_accuracy: 0.0115
Epoch 50/50
235/235 [==============================] - 3s 12ms/step - loss: 0.0845 - accuracy: 0.0139 - val_loss: 0.0840 - val_accuracy: 0.0165
&lt;/code>&lt;/pre>&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210122160643.png" alt="20210122160643" />&lt;/p>
&lt;h1 id="参考文献">参考文献&lt;/h1>
&lt;ol>
&lt;li>&lt;a class="link" href="https://medium.com/@venkatakrishna.jonnalagadda/sparse-stacked-and-variational-autoencoder-efe5bfe73b64" target="_blank" rel="noopener"
>Sparse, Stacked and Variational Autoencoder&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://medium.com/datadriveninvestor/deep-learning-autoencoders-db265359943e" target="_blank" rel="noopener"
>Deep Learning Autoencoders&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://medium.com/datadriveninvestor/deep-autoencoder-using-keras-b77cd3e8be95" target="_blank" rel="noopener"
>Deep Autoencoder using Keras&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://zhuanlan.zhihu.com/p/34238979" target="_blank" rel="noopener"
>自编码器是什么？有什么用？这里有一份入门指南（附代码）&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95" target="_blank" rel="noopener"
>反向传播算法 - 维基百科&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/Nana0606/autoencoder" target="_blank" rel="noopener"
>Autoencoder - Github&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>《机器学习》笔记（第三章）</title><link>https://sudrizzz.github.io/posts/machine-learning-note-2/</link><pubDate>Wed, 30 Dec 2020 17:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/machine-learning-note-2/</guid><description>&lt;h1 id="3-线性模型">3 线性模型&lt;/h1>
&lt;h2 id="31-基本形式">3.1 基本形式&lt;/h2>
&lt;p>给定由 $d$ 个属性描述的示例 $\boldsymbol{x}=\{x_1; x_2;\cdots;x_d\}$，其中 $x_i$ 是 $\boldsymbol{x}$ 在第 $i$ 个属性上的取值，线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数，即&lt;/p>
&lt;p>$$ f(\boldsymbol{x}) = w_1x_1 + w_2x_2 + \cdots + w_dx_d + b $$&lt;/p>
&lt;p>一般用向量形式写成&lt;/p>
&lt;p>$$ f(\boldsymbol{x}) = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $$&lt;/p>
&lt;p>其中 $\boldsymbol{w} = (w_1; w_2; \cdots; w_d)$，$\boldsymbol{w}$ 和 $b$ 学得之后，模型就得以确定。&lt;/p>
&lt;h2 id="32-线性回归">3.2 线性回归&lt;/h2>
&lt;p>给定数据集 $D=\{(x_1, y_1,), (x_2, y_2), \cdots, (x_m, y_m)\}$，其中 $\boldsymbol{x}_i = (x_{i1}; x_{i2}, \cdots, x_{id})$，$y_i \in \mathbb{R}$。“线性回归（linear regression）”试图学得一个线性模型以尽可能准确地预测实值输出标记。&lt;/p>
&lt;p>线性回归试图学得 $f(x_i) = wx_i + b$，使得 $f(x_i) \simeq y_i$。&lt;/p>
&lt;p>2.3 节中的均方误差是回归任务中最常用的性能度量，因此我们可试图让均方误差最小化，即&lt;/p>
&lt;p>$$
(w^*, b^*) = arg \min_{(w, b)} \sum_{i = 1}^{m} (f(x_i) - y_i)^2 \\ = arg \min_{(w, b)} \sum_{i = 1}^{m} (y_i - wx_i - y_i)^2
$$&lt;/p>
&lt;p>均方误差有非常好的几何意义，它对应了常用的欧几里得距离或简称“欧氏距离”（Euclidean distance）。基于均方误差最小化来进行模型求解的方法称为“最小二乘法”（least square method）。在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小。
求解 $w$ 和 $b$ 使 $E_{(w, b)} = \sum_{i = 1}^m(y_i - wx_i - b)^2$ 最小化的过程，称为线性回归模型的最小二乘“参数估计”（parameter estimation）。我们可将 $E_{(w, b)}$ 分别对 $w$ 和 $b$ 求导，得到&lt;/p>
&lt;p>$$
\frac{\partial E_{(w, b)}}{\partial w} =2\left(w \sum_{i=1}^{m} x_{i}^{2}-\sum_{i=1}^{m}\left(y_{i}-b\right) x_{i}\right) \\ \frac{\partial E_{(w, b)}}{\partial b} =2\left(m b-\sum_{i=1}^{m}\left(y_{i}-w x_{i}\right)\right)
$$&lt;/p>
&lt;p>然后令上述两式为零可得到 $w$ 和 $b$ 最优解的闭式（closed-form）解&lt;/p>
&lt;p>$$
w=\frac{\sum_{i=1}^{m} y_{i}\left(x_{i}-\bar{x}\right)}{\sum_{i=1}^{m} x_{i}^{2}-\frac{1}{m}\left(\sum_{i=1}^{m} x_{i}\right)^{2}}
$$&lt;/p>
&lt;p>$$ b=\frac{1}{m}\sum_{i=1}^m(y_i-wx_i) $$&lt;/p>
&lt;p>其中，$\bar{x}=\frac{1}{m}\sum_{i=1}^mx_i$ 为 $x$ 均值。&lt;/p>
&lt;p>线性模型虽简单，却有丰富的变化。例如对于样例 $(\boldsymbol{x}, y)$，$y\in \mathbb{R}$，当我们希望线性模型 $ f(\boldsymbol{x}) = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $ 的预测值逼近真实标记 $y$ 时，就得到了线性回归模型。为便于观察，我们把线性回归模型简写为&lt;/p>
&lt;p>$$ y = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $$&lt;/p>
&lt;p>可否令模型预测值逼近 $y$ 的衍生物呢？譬如说，假设我们认为示例所对应的输出标记是在指数尺度上变化，那就可将输出标记的对数作为线性模型逼近的目标，即&lt;/p>
&lt;p>$$ \ln y = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $$&lt;/p>
&lt;p>这就是“对数线性回归”（log-linear regression），它实际上是在试图让 $e^{\boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b}$ 逼近 $y$。上式在形式上仍是线性回归，但实质上已是在求取输入空间到输出空间的非线性函数映射，如下图所示，这里的对数函数起到了将线性回归模型的预测值与真实标记联系起来的作用。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201231150756.png" alt="20201231150756" />&lt;/p>
&lt;p>更一般地，考虑单调可微函数 $g(\cdot)$，令&lt;/p>
&lt;p>$$ y=g^{-1}(\boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b) $$&lt;/p>
&lt;p>这样得到的模型称为“广义线性模型”（generalized linear model），其中函数 $g(\cdot)$ 称为“联系函数”（link function）。显然，对数线性回归是广义线性模型在 $g(\cdot) = \ln (\cdot)$ 时的特例。&lt;/p>
&lt;h2 id="33-对数几率回归">3.3 对数几率回归&lt;/h2>
&lt;p>考虑二分类任务，其输出标记 $y\in\{0,1\}$，而线性回归模型产生的预测值 $z = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $ 是实值，于是我们需将实值 $z$ 转换为 0/1 值。最理想的是“单位阶跃函数”（unit-step function）&lt;/p>
&lt;p>$$
y = \begin{cases}
0, &amp;amp;z&amp;lt;0; \\ 0.5, &amp;amp;z=0; \\ 1, &amp;amp;z&amp;gt;0;
\end{cases}
$$&lt;/p>
&lt;p>即若预测值 $z$ 大于零就判为正例，小于零则判为反例，预测值为临界值零则可任意判别，如下图所示。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201231140318.png" alt="20201231140318" />&lt;/p>
&lt;p>如果我们希望找到在一定程度上近似单位阶跃函数的“替代函数”（surrogate function），并希望它单调可微。对数几率函数（logistic function）正是这样一个常用的替代函数。&lt;/p>
&lt;p>$$ y = \frac{1}{1+e^{-z}} $$&lt;/p>
&lt;p>从上图可看出，对数几率函数是一种“Sigmoid 函数”，它将 $z$ 值转化为一个接近 0 或 1 的 $y$ 值，并且其输出值在 $z=0$ 附近变化很陡。将对数几率函数作为 $g^{-1}(\cdot)$ 代入 $ y=g^{-1}(\boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b) $，得到&lt;/p>
&lt;p>$$ y = \frac{1}{1+e^{-(\boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b)}} $$&lt;/p>
&lt;p>对上式两边同时取对数，并进行适当变形可得&lt;/p>
&lt;p>$$ \ln \frac{y}{1-y} = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $$&lt;/p>
&lt;p>若将 $y$ 视为样本 $\boldsymbol{x}$ 作为正例的可能性，则 $1-y$ 是其反例可能性，两者的比值&lt;/p>
&lt;p>$$ \frac{y}{1-y} $$&lt;/p>
&lt;p>称为“几率”（odds），反映了 $\boldsymbol{x}$ 作为正例的相对可能性。对几率取对数则得到“对数几率”（log odds，亦称 logit）&lt;/p>
&lt;p>$$ \ln\frac{y}{1-y} $$&lt;/p>
&lt;p>由此可看出，式 $y = \frac{1}{1+e^{-(\boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b)}}$ 实际上是在用线性回归模型的预测结果去逼近真实标记的对数几率，因此，其对应的模型称为“对数几率回归”（logisticregression，亦称 logit regression）。&lt;/p>
&lt;p>&lt;strong>特别需注意到，虽然对数几率回归的名字是“回归”，但实际却是一种分类学习方法&lt;/strong>。这种方法有很多优点，例如它是直接对分类可能性进行建模，无需事先假设数据分布，这样就避免了假设分布不准确所带来的问题；它不是仅预测出“类别”，而是可得到近似概率预测，这对许多需利用概率辅助决策的任务很有用；此外，对率函数是任意阶可导的凸函数，有很好的数学性质，现有的许多数值优化算法都可直接用于求取最优解。&lt;/p>
&lt;h2 id="34-线性判别分析">3.4 线性判别分析&lt;/h2>
&lt;p>线性判别分析（Linear Discriminant Analysis，简称 LDA）是一种经典的线性学习方法，在二分类问题上因为最早由 [Fisher，1936] 提出，亦称“Fisher 判别分析”。&lt;/p>
&lt;p>LDA 的思想非常朴素：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。下图给出了一个二维示意图。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201231154207.png" alt="20201231154207" />&lt;/p>
&lt;p>图中 “+”、“-” 分别代表正例和反例，椭圆表示数据簇的外轮廓，虛线表示投影，红色实心圆和实心三角形分别表示两类样本投影后的中心点。&lt;/p>
&lt;h2 id="35-多分类学习">3.5 多分类学习&lt;/h2>
&lt;p>现实中常遇到多分类学习任务。有些二分类学习方法可直接推广到多分类，但在更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类问题。&lt;/p>
&lt;p>不失一般性，考虑 N 个类别 $C_1, C_2, \cdots, C_N$ 多分类学习的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解。具体来说，先对问题进行拆分，然后为拆出的每个二分类任务训练一个分类器；在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果。这里的关键是如何对多分类任务进行拆分，以及如何对多个分类器进行集成。&lt;/p>
&lt;p>最经典的拆分策略有三种；“一对一”（One vs. One，简称 OvO）、“一对其余”（One vs. Rest，简称 OvR）和“多对多”（Many vs. Many，简称 MvM）。&lt;/p>
&lt;p>给定数据集 $D=\{(\boldsymbol{x}_1, y_1,), (\boldsymbol{x}_2, y_2), \cdots, (\boldsymbol{x}_m, y_m)\}$，$y_i \in \{C_1, C_2, \cdots, C_N\}$。OvO 将这 $N$ 个类别两两配对，从而产生 $N(N-1)/2$ 个二分类任务，例如 OvO 将为区分类别 $C_i$ 和 $C_j$；训练一个分类器，该分类器把 $D$ 中的 $C_i$ 类样例作为正例, $C_j$ 类样例作为反例。在测试阶段，新样本将同时提交给所有分类器，于是我们将得到 $N(N-1)/2$ 个分类结果，最终结果可通过投票产生：即把被预测得最多的类别作为最终分类结果。下图是 OvO 与 OvR 的示意图。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201231161216.png" alt="20201231161216" />&lt;/p>
&lt;p>OvR 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练 N 个分类器。在测试时若仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果，如上图所示，若有多个分类器预测为正类，则通常考虑各
分类器的预测置信度，选择置信度最大的类别标记作为分类结果。&lt;/p>
&lt;p>容易看出，OvR 只需训练 $N$ 个分类器,而 OvO 需训练 $N(N-1)/2$ 个分类器，因此，OvO 的存储开销和测试时间开销通常比 OvR 更大。但在训练时，OvR 的每个分类器均使用全部训练样例，而 OvO 的每个分类器仅用到两个类的样例，因此，在类别很多时，OvO 的训练时间开销通常比 OvR 更小。至于预测性能，则取决于具体的数据分布，在多数情形下两者差不多。&lt;/p>
&lt;p>MvM 是每次将若干个类作为正类，若干个其他类作为反类。显然, OvO 和 OvR 是 MvM 的特例。MvM 的正、反类构造必须有特殊的设计，不能随意选取。这里我们介绍一种最常用的 MvM 技术：“纠错输出码”（Error Correcting Output Codes，简称 ECOC）。&lt;/p>
&lt;p>ECOC [Dietterich and Bakiri，1995] 是将编码的思想引入类别拆分，并尽可能在解码过程中具有容错性。ECOC 工作过程主要分为两步:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>编码：对 $N$ 个类别做 $M$ 次划分，每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集；这样一共产生 $M$ 个训练集，可训练出 $M$ 个分类器。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>解码：$M$ 个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>类别划分通过“编码矩阵”（coding matrix）指定。编码矩阵有多种形式，常见的主要有二元码 [Dietterich and Bakiri，1995] 和三元码 [Allwein et al，2000]。前者将每个类别分别指定为正类和反类，后者在正、反类之外，还可指定“停用类”。下图为二元码和三元码的示意图。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201231162236.png" alt="20201231162236" />&lt;/p>
&lt;p>上图中，“+1”、“-1”分别表示学习器 $f_i$ 将该类样本作为正、反例；三元码中“0”表示 $f_i$ 不使用该类样本。&lt;/p>
&lt;blockquote>
&lt;p>海明距离：两个等长编码序列中对应位置的不同字符的个数&lt;/p>
&lt;/blockquote>
&lt;p>对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠错能力越强，也即单个错误不会引起结果剧烈变化。&lt;/p>
&lt;h2 id="36-类别不平衡问题">3.6 类别不平衡问题&lt;/h2>
&lt;p>类别不平衡（class-imbalance）就是指分类任务中不同类别的训练样例数目差别很大的情况，例如又 998 个反例，但正例只有 2 个，那么学习方法只需返回一个永远将新样本预测为反例的学习器，就能达到 99.8% 对的精度；然而这样的学习器往往没有价值，因为它不能预测出任何正例。&lt;/p>
&lt;p>从线性分类器的角度讨论容易理解，在我们用 $y = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b$ 对新样本 $\boldsymbol{x}$ 进行分类时，事实上是在用预测出的 $y$ 值与一个阈值进行比较，例如通常在 $y&amp;gt;0.5$ 时判别为正例，否则为反例。$y$ 实际上表达了正例的可能性，几率 $\frac{y}{1-y}$ 则反映了正例可能性与反例可能性之比值，阈值设置为 0.5 恰表明分类器认为真实正、反例可能性相同，即分类器决策规则为&lt;/p>
&lt;p>$$ 若 \frac{y}{1-y} &amp;gt; 1 则预测为正例 （式 1）$$&lt;/p>
&lt;p>然而，当训练集中正、反例的数目不同时，令 $m^+$ 表示正例数目，$m^-$ 表示反例数目，则观测几率是 $\frac{m^+}{m^-}$，由于我们通常假设训练集是真实样本总体的无偏采样，因此观测几率就代表了真实几率。于是，只要分类器的预测几率高于观测几率就应判定为正例，即&lt;/p>
&lt;p>$$ 若 \frac{y}{1-y} &amp;gt; \frac{m^+}{m^-} 则预测为正例 （式 2）$$&lt;/p>
&lt;p>但是，我们的分类器是基于式 1 进行决策，因此，需对其预测值进行调整，使其在基于式(3.46)决策时,实际是在执行式 1。要做到这一点很容易，只需令&lt;/p>
&lt;p>$$ \frac{y'}{1-y'} = \frac{y}{1-y} \times \frac{m^-}{m^+} （式 3）$$&lt;/p>
&lt;p>其中，$\frac{m^-}{m^+}$ 表示&lt;strong>观测反例几率&lt;/strong>，$\frac{y}{1-y}$ 表示&lt;strong>预测正例几率&lt;/strong>，这两项相乘得到&lt;strong>再缩放预测正例几率&lt;/strong>。这就是类别不平衡学习的一个基本策略——“再缩放”（rescaling）。&lt;/p>
&lt;p>再缩放的思想虽简单，但实际操作却并不平凡，主要因为“训练集是真实样本总体的无偏采样”这个假设往往并不成立，也就是说，我们未必能有效地基于训练集观测几率来推断出真实几率。现有技术大体上有三类做法：&lt;/p>
&lt;ol>
&lt;li>欠采样（undersampling）&lt;br>
直接对训练集里的反类样例进行“欠采样”（undersampling），即去除一些反例使得正、反例数目接近，然后再进行学习；&lt;/li>
&lt;li>过采样（oversampling）&lt;br>
即增加一些正例使得正、反例数目接近,然后再进行学习;&lt;/li>
&lt;li>阈值移动（threshold-moving）&lt;br>
直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将式 3 嵌入到其决策过程中。&lt;/li>
&lt;/ol>
&lt;p>欠采样法的时间开销通常远小于过采样法，因为前者丢弃了很多反例，使得分类器训练集远小于初始训练集，而过采样法增加了很多正例，其训练集大于初始训练集。&lt;/p>
&lt;p>需注意的是，过采样法不能简单地对初始正例样本进行重复采样，否则会招致严重的过拟合；过采样法的代表性算法 SMOTE[Chawlaetal.,2002] 是通过对训练集里的正例进行插值来产生额外的正例。另一方面，欠采样法若随机丢弃反例，可能丢失一些重要信息；欠采样法的代表性算法 Easy Ensemble[Liu et al.,2009] 则是利用集成学习机制，将反例划分为若干个集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来看却不会丢失重要信息。&lt;/p>
&lt;p>值得一提的是，“再缩放”也是“代价敏感学习”（cost-sensitive learning）的基础。在代价敏感学习中将式 3 中的 $m^-/m^+$ 用 $cost^+/cost^-$ 代替即可，其中 $cost^+$ 是将正例误分为反例的代价，$cost^-$ 是将反例误分为正例的代价。&lt;/p>
&lt;h1 id="参考文献">参考文献&lt;/h1>
&lt;ol>
&lt;li>&lt;a class="link" href="https://zh.wikipedia.org/wiki/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB" target="_blank" rel="noopener"
>海明距离&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>《机器学习》笔记（第一、二章）</title><link>https://sudrizzz.github.io/posts/machine-learning-note-1/</link><pubDate>Tue, 22 Dec 2020 09:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/machine-learning-note-1/</guid><description>&lt;p>《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。&lt;/p>
&lt;h1 id="1-绪论">1 绪论&lt;/h1>
&lt;h2 id="12-基本术语">1.2 基本术语&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>术语&lt;/th>
&lt;th>英语原意&lt;/th>
&lt;th>释义&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>数据集&lt;/td>
&lt;td>data set&lt;/td>
&lt;td>一组关于一个事件或对象的描述的集合&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>样本 / 示例&lt;/td>
&lt;td>sample / instance&lt;/td>
&lt;td>数据集中的每条记录&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>属性 / 特征&lt;/td>
&lt;td>attribute / feature&lt;/td>
&lt;td>反映样本在某方面的表现或性质的事项&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>训练数据&lt;/td>
&lt;td>training data&lt;/td>
&lt;td>用于训练的数据&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>训练样本&lt;/td>
&lt;td>training sample&lt;/td>
&lt;td>训练数据中的每个样本&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>假设&lt;/td>
&lt;td>hypothesis&lt;/td>
&lt;td>通过训练学得数据的某种规律&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>真实&lt;/td>
&lt;td>ground-truth&lt;/td>
&lt;td>潜在规律本身&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>预测&lt;/td>
&lt;td>prediction&lt;/td>
&lt;td>训练结果生成的模型&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>分类&lt;/td>
&lt;td>classification&lt;/td>
&lt;td>预测离散值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>二分类&lt;/td>
&lt;td>binary classification&lt;/td>
&lt;td>只涉及两个特征的分类&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>多分类&lt;/td>
&lt;td>multi-class classification&lt;/td>
&lt;td>涉及多个特征的分类&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>回归&lt;/td>
&lt;td>regression&lt;/td>
&lt;td>预测连续值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>聚类&lt;/td>
&lt;td>clustering&lt;/td>
&lt;td>对训练样本进行分组&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>簇&lt;/td>
&lt;td>cluster&lt;/td>
&lt;td>聚类后的每一个组&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>监督学习&lt;/td>
&lt;td>supervised learning&lt;/td>
&lt;td>训练数据有标记信息的训练（分类与回归）&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>无监督学习&lt;/td>
&lt;td>unsupervised learning&lt;/td>
&lt;td>训练数据没有标记信息的训练（聚类）&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="2-模型评估与选择">2 模型评估与选择&lt;/h1>
&lt;h2 id="21-经验误差与过拟合">2.1 经验误差与过拟合&lt;/h2>
&lt;h3 id="误差">误差&lt;/h3>
&lt;p>通常我们把分类错误的样本数占样本总数的比例称为“错误率”（error rate），即如果在 m 个样本中有 a 个样本分类错误，则错误率 $ E = \frac{a}{m} $； 相应的，$ 1 - \frac{a}{m} $ 称为“精度”（accuracy），即“精度 = 1 - 错误率”。&lt;/p>
&lt;p>更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”（error），学习器在训练集上的误差称为”训练误差“（training error） 或“经验误差”（empirical error）, 在新样本上的误差称为“泛化误差”（generalization errorr）。&lt;/p>
&lt;h3 id="过拟合与欠拟合">过拟合与欠拟合&lt;/h3>
&lt;p>为了达到更好的学习效果，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”，这样才能在遇到新样本时做出正确的判别。然而，当学习器把训练样本学得“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。这种现象在机器学习中称为“过拟合”（overfitting）。 与“过拟合”相对的是“欠拟合”（underfitting），这是指对训练样本的一般性质尚未学好。&lt;/p>
&lt;p>下图展示了欠拟合与过拟合，蓝色点为训练数据，橙色点为测试数据，红色曲线为拟合曲线。&lt;/p>
&lt;p>最优拟合
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222151854.png" alt="20201222151854" />&lt;/p>
&lt;p>欠拟合（underfitting）
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222153133.png" alt="20201222153133" />&lt;/p>
&lt;p>过拟合（overfitting）
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222152022.png" alt="20201222152022" />&lt;/p>
&lt;p>过拟合的训练误差（蓝色）与泛化误差（红色）
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222152706.png" alt="20201222152706" />&lt;/p>
&lt;h2 id="22-评估方法">2.2 评估方法&lt;/h2>
&lt;h3 id="221-留出法">2.2.1 留出法&lt;/h3>
&lt;p>留出法（hold-out）直接将数据集 $D$ 划分为两个互斥的集合，其中一个集合作为训练集 $S$，另一个作为测试集 $T$，即&lt;/p>
&lt;p>$$ D = S \cup T , S \cap T=\varnothing $$&lt;/p>
&lt;p>需要注意的是训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。&lt;/p>
&lt;h3 id="222-交叉验证法">2.2.2 交叉验证法&lt;/h3>
&lt;p>交叉验证法（cross validation）先将数据集 $D$ 划分为 $k$ 个大小相似的互斥子集，即&lt;/p>
&lt;p>$$ D = D_1 \cup D_2 \cup \dots \cup D_k , D_i \cap D_j = \varnothing (i \ne j)$$&lt;/p>
&lt;p>每个子集 $D_{i}$ 都尽可能保持数据分布的一致性，即从 $D$ 中通过分层采样得到。然后每次用 $k - 1$ 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可以获得 $k$ 组训练/测试集，从而可进行 $k$ 次训练和测试，最终返回的是这 $k$ 个测试结果得得得均值。显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于 $k$ 的取值，为强调这一点，通常把交叉验证法称为 ”$k$ 折交叉验证“（$k$-fold cross validation）。$k$ 最常用的取值是 10，此时成为 10 折交叉验证。下图为 10 折交叉验证的示意图。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222174250.png" alt="20201222174250" />&lt;/p>
&lt;p>假定数据集 $D$ 中包含 $m$ 个样本，令 $k=m$，则得到了交叉验证法的一个特例：留一法（Leave-One-Out，简称 LOO）。显然，留一法不受随机样本划分方式的影响，因为 $m$ 个样本只有唯一的方式划分为 $m$ 个子集——每个子集包含一个样本；留一法使用的训练集与初始数据集相比只少了一个样本，这就使得在绝大多数情况下，留一法中被实际评估的模型与期望评估的用 $D$ 训练出的模型很相似。因此，留一法的评估结果往往被认为比较准确。&lt;/p>
&lt;p>然而，留一法也有其缺陷：在数据集比较大时，训练 $m$ 个模型的计算开销可能是难以忍受的（例如数据集包含 1 百万个样本，则需训练 1 百万个模型)，而这还是在未考虑算法调参的情况下。另外，留一法的估计结果也未必永远比其他评估方法准确；“没有免费的午餐”定理对实验评估方法同样适用。&lt;/p>
&lt;h3 id="223-自助法">2.2.3 自助法&lt;/h3>
&lt;p>自助法的主要步骤是，给定包含 $m$ 个样本的数据集 $D$，我们对它采样产生数据集 $D^{'}$：每次随机从 $D$ 中挑选一个样本，将其拷贝放入 $D^{'}$，然后再将该样本放回初始数据集 $D$ 中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行 $m$ 次后，我们就得到了包含 $m$ 个样本的数据集 $D^{'}$，这就是自助采样的结果。显然，$D$ 中有一部分样本会在 $D^{'}$中多次出现，而另一部分样本不出现。可以做一个简单的估计，样本在 $m$ 次采样中始终不被采到的概率是 $(1 - \frac{1}{m})^m$，取极限得到&lt;/p>
&lt;p>$$ \lim_{m \rightarrow \infty } (1 - \frac{1}{m})^m = \frac{1}{e} \approx 0.368 $$&lt;/p>
&lt;p>即通过自助采样，初始数据集 $D$ 中约有 36.8% 的样本未出现在采样数据集 $D^{'}$ 中。于是我们可将 $D^{'}$ 用作训练集, $D$ \ $D^{'}$ 用作测试集；这样，实际评估的模型与期望评估的模型都使用 $m$ 个训练样本，而我们仍有数据总量约 1/3 的、没在训练集中出现的样本用于测试。这样的测试结果，亦称“包外估计”(out-of-bag estimate)。&lt;/p>
&lt;p>自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集；这对集成学习等方法有很大的好处。然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些。&lt;/p>
&lt;h2 id="23-性能度量">2.3 性能度量&lt;/h2>
&lt;p>在预测任务中，给定样例集 $D = \{ (x_1, y_1), (x_2, y_2), \dots , (x_m, y_m) \} $ ，其中 $y_i$ 是 $x_i$ 的真实标记。要评估学习器 $f$ 的性能，就要把学习器预测结果 $f(x)$ 与真实标记 $y$ 进行比较。&lt;/p>
&lt;p>回归任务最常用的性能度量是”均方误差“（mean squared error），即 Loss function&lt;/p>
&lt;p>$$ L(f) = E(f; D) = \frac{1}{m} \sum_{i=1}^{m}(f(x_i) - y_i)^2 $$&lt;/p>
&lt;p>更一般的，对于数据分布 $\mathcal{D}$ 和概率密度函数 $p(\cdot)$，均方误差可描述为&lt;/p>
&lt;p>$$ L(f) = E(f; D) = \int_{x\sim D}^{}(f(x) - y)^2 p(x)dx $$&lt;/p>
&lt;p>则最优学习器 $f^*$ 可以表示为&lt;/p>
&lt;p>$$ f^* = arg \min_f L(f) $$&lt;/p>
&lt;h3 id="231-错误率与精度">2.3.1 错误率与精度&lt;/h3>
&lt;p>错误率和精度，这是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务。错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例。对样例集 $D$，分类错误率定义为&lt;/p>
&lt;p>$$ E(f; D) = \frac{1}{m} \sum_{i=1}^{m} \mathbb I (f(x_i) \neq y_i) $$&lt;/p>
&lt;p>精度定义为&lt;/p>
&lt;p>$$ acc(f; D) = \frac{1}{m} \sum_{i=1}^{m} \mathbb I (f(x_i) = y_i) \\ = 1 - E(f; D) $$&lt;/p>
&lt;p>更一般的，对于数据分布 $\mathcal{D}$ 和概率密度函数 $p(\cdot)$，错误率与精度可分别描述为&lt;/p>
&lt;p>$$ E(f; D) = \int_{x\sim D}^{}\mathbb I (f(x) \neq y) p(x)dx $$&lt;/p>
&lt;p>$$ acc(f; D) = \int_{x\sim D}^{}\mathbb I (f(x) = y) p(x)dx \\ = 1 - E(f; D)$$&lt;/p>
&lt;h3 id="232-查准率查全率与-f1-度量">2.3.2 查准率、查全率与 F1 度量&lt;/h3>
&lt;p>错误率和精度虽常用，但并不能满足所有任务需求。以西瓜问题为例，假定瓜农拉来一车西瓜，我们用训练好的模型对这些西瓜进行判别，显然，错误率衡量了有多少比例的瓜被判别错误。但是若我们关心的是“挑出的西瓜中有多少。比例是好瓜”，或者“所有好瓜中有多少比例被挑了出来”，那么错误率显然就不够用了，这时需要使用其他的性能度量。&lt;/p>
&lt;p>类似的需求在信息检索、Web 搜索等应用中经常出现，例如在信息检索中，我们经常会关心“检索出的信息中有多少比例是用户感兴趣的”，“用户感兴趣的信息中有多少被检索出来了”。“查准率”（precision）与”查全率“（recall）是更为适用于此类需求的性能度量。&lt;/p>
&lt;p>对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例（true positive）、假正例（false positive）、真反例（true negative）、假反例（false negative）四种情形，令 TP、FP、TN、FN 分别表示其对应的样例数，则显然有 TP + FP + TN + FN = 样例总数。分类结果的”混淆矩阵“（confusion matrix）如下表所示。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201225161654.png" alt="20201225161654" />&lt;/p>
&lt;p>查准率 $P$ 与查全率 $R$ 分别定义为&lt;/p>
&lt;p>$$ P = \frac{TP}{TP + FP} $$&lt;/p>
&lt;p>$$ R = \frac{TP}{TP + FN} $$&lt;/p>
&lt;p>查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。
我们可以这样理解查准率与查全率：&lt;/p>
&lt;blockquote>
&lt;p>查准率：预测为正例的结果中，真·正例所占的比例；&lt;br>
查全率：所有正例中，预测为正例所占的比例。&lt;/p>
&lt;/blockquote>
&lt;p>在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为”最可能“是正例的样本，排在最后的则是学习器认为”最不可能“是正例的样本。按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。以查准率为纵轴、查全率为横轴作图，就得到了查准率-查全率曲线，简称”P-R 曲线“，显示该曲线的图称为”P-R 图“。下图是”P-R 图“的一个示例。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201225164329.png" alt="20201225164329" />&lt;/p>
&lt;p>P-R 图直观地显示出学习器在样本总体上的查全率、查准率在进行比较时，若一个学习器的 P-R 曲线被另一个学习器的曲线完全”包住“，则可断言后者的性能优于前者，例如上图中学习器 A 的性能优于学习器 C；如果两个学习器的 P-R 曲线发生了交叉，例如上图中的 A 与 B，则难以一般性地断言两者孰优孰劣,只能在具体的查准率或查全率条件下进行比较。然而，在很多情形下，人们往往仍希望把学习器 A 与 B 比出个高低。这时一个比较合理的判据是比较 P-R 曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对”双高“的比例。但这个值不太容易估算，因此，人们设计了一些综合考虑查准率、查全率的性能度量。&lt;/p>
&lt;p>“平衡点”（Break-Event Point，简称 BEP）就是这样一个度量，它是“查准率=查全率”时的取值，例如上图中学习器 C 的 BEP 是 0.64，而基于 BEP 的比较，可认为学习器 A 优于 B。&lt;/p>
&lt;h3 id="233-roc-与-auc">2.3.3 ROC 与 AUC&lt;/h3>
&lt;p>与 2.3.2 节中介绍的 P-R 曲线相似，我们根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横、纵坐标作图，就得到了“ROC 曲线”。与 P-R 曲线使用查准率、查全率为纵、横轴不同，ROC 曲线的纵轴是“真正例率”（True Positive Rate, 简称 TPR）,横轴是“假正例率”（False PositiveRate，简称 FPR），基于上文中相关表格中的符号，两者分别定义为&lt;/p>
&lt;p>$$ TPR = \frac{TP}{TP + FN} $$&lt;/p>
&lt;p>$$ FPR = \frac{FP}{TN + FP} $$&lt;/p>
&lt;h3 id="234-代价敏感错误率与代价曲线">2.3.4 代价敏感错误率与代价曲线&lt;/h3>
&lt;p>为权衡不同类型错误所造成的不同损失，可为错误赋予”非均等代价“（unequal cost）。&lt;/p>
&lt;p>以二分类任务为例，我们可根据任务的领域知识设定一个”代价矩阵“（cost matrix），如下表所示，其中 $cost_{ij}$ 表示将第 $i$ 类样本预测为第 $j$ 类样本的代价；一般来说，$cost_{ii} = 0$；若将第 0 类判别为第 1 类所造成的损失更大，则 $cost_{01} &amp;gt; cost_{10}$；损失程度相差越大，$cost_{01}$ 与 $cost_{10}$ 值的差别越大。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201225171957.png" alt="20201225171957" />&lt;/p>
&lt;p>回顾前面介绍的一些性能度量可看出，它们大都隐式地假设了均等代价，并没有考虑不同错误会造成不同的后果。在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化“总体代价”（total cost）。若将上表中的第 0 类作为正类、第 1 类作为反类，令 $D^+$ 与 $D^-$ 分别代表样例集 $D$ 的正例子集和反例子集，则“代价敏感”（cost-sensitive）错误率为&lt;/p>
&lt;p>$$ E(f; D; cost) = \frac{1}{m} (\sum_{x_i \in D^+} \mathbb I (f(x_i) \neq y_i) \times cost_{01} \\ + \sum_{x_i \in D^-} \mathbb I (f(x_i) \neq y_i) \times cost_{10}) $$&lt;/p>
&lt;p>类似的，可给出基于分布定义的代价敏感错误率，以及其他一些性能度量如精度的代价敏感版本。若令 $cost_{ij}$ 中的 $i$、$j$ 取值不限于 0、1, 则可定义出多分类任务的代价敏感性能度量。&lt;/p>
&lt;h1 id="参考文献">参考文献&lt;/h1>
&lt;ol>
&lt;li>&lt;a class="link" href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9" target="_blank" rel="noopener"
>过拟合-维基百科&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://zh.wikipedia.org/wiki/%E5%88%86%E5%B1%82%E6%8A%BD%E6%A0%B7" target="_blank" rel="noopener"
>分层抽样&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://datawhalechina.github.io/leeml-notes/" target="_blank" rel="noopener"
>李宏毅机器学习笔记(LeeML-Notes)&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>GAN 网络之手写数字生成</title><link>https://sudrizzz.github.io/posts/gan-for-hand-written-digits/</link><pubDate>Tue, 08 Dec 2020 10:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/gan-for-hand-written-digits/</guid><description>&lt;h1 id="环境搭建">环境搭建&lt;/h1>
&lt;p>本例中，所涉及的系统与软件版本列表如下。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>名称&lt;/th>
&lt;th>版本&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>操作系统&lt;/td>
&lt;td>Windows 20H2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Anaconda&lt;/td>
&lt;td>Anaconda3-2020.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>python&lt;/td>
&lt;td>3.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>tensorflow&lt;/td>
&lt;td>1.8.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>本例代码存放于 &lt;a href="https://github.com/sudrizzz/MachineLearning">https://github.com/sudrizzz/MachineLearning&lt;/a>。&lt;/p>
&lt;h2 id="anaconda-安装">Anaconda 安装&lt;/h2>
&lt;p>通过清华大学开源软件镜像站，我们可以直接下载最新版本的 Anaconda，本例中使用的 Anaconda 下载链接：
&lt;a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2020.11-Windows-x86_64.exe">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2020.11-Windows-x86_64.exe&lt;/a>&lt;/p>
&lt;p>Anaconda 安装教程网络上已经有很多，故此处不再赘述。&lt;/p>
&lt;p>安装完成后，我们需要手动配置 Anaconda 的环境变量，在用户变量的 Path 中添加 Anaconda 的安装路径以及其子文件夹，具体内容如下。&lt;/p>
&lt;pre>&lt;code>C:\Users\xvyn\anaconda3
C:\Users\xvyn\anaconda3\Scripts
C:\Users\xvyn\anaconda3\Library\bin
&lt;/code>&lt;/pre>&lt;p>上述配置请根据 Anaconda 实际安装路径进行调整，配置完成的效果如下图所示。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201208152533.png" alt="20201208152533" />&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201208152633.png" alt="20201208152633" />&lt;/p>
&lt;p>完成后打开 cmd 输入下列命令，如果输出内容与下列内容类似，则表示配置正确，可继续后面的步骤。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda --version
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>输出
conda 4.9.2
&lt;/code>&lt;/pre>
&lt;h2 id="创建虚拟环境">创建虚拟环境&lt;/h2>
&lt;p>通过如下命令进行创建一个虚拟环境。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda create -n handwrittendigits
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>-n handwrittendigits&lt;/code> 的作用是指定虚拟环境的名称，本例中指定为 &lt;code>handwrittendigits&lt;/code>。&lt;/p>
&lt;p>执行结束后，可通过下列命令查看 Anaconda 中所有的虚拟环境。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda info --evns
&lt;/code>&lt;/pre>&lt;/div>&lt;p>输出如下&lt;/p>
&lt;pre>&lt;code>(base) PS C:\Users\xvyn&amp;gt; conda info --envs
conda environments:
base * C:\Users\xvyn\anaconda3
handwrittendigits C:\Users\xvyn\anaconda3\envs\handwrittendigits
&lt;/code>&lt;/pre>
&lt;p>其中，标记 * 的表示目前已启用，命令行前半部分的 (base) 也表示目前启用的是哪个虚拟环境，此例中为 base 环境。&lt;/p>
&lt;h2 id="切换虚拟环境">切换虚拟环境&lt;/h2>
&lt;p>如果使用 PowerShell 进行 Anaconda 的一些操作，需要以 &lt;strong>管理员&lt;/strong> 身份运行 PowerShell，然后执行下列命令。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>set-executionpolicy remotesigned
&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行完成后可通过下列命令进行切换虚拟环境。若使用其他 Shell 工具进行操作，则可直接执行下列命令。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda activate handwrittendigits
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果执行时报错如下，则可以通过 &lt;a href="https://github.com/conda/conda/issues/7980">https://github.com/conda/conda/issues/7980&lt;/a> 来解决。&lt;/p>
&lt;pre>&lt;code>Can't execute `conda activate` from batch script
&lt;/code>&lt;/pre>
&lt;p>详细操作为：&lt;/p>
&lt;ol>
&lt;li>安装并打开 Git Bash&lt;/li>
&lt;li>执行 &lt;code>source ~/anaconda3/etc/profile.d/conda.sh&lt;/code>&lt;/li>
&lt;li>执行 &lt;code>conda init&lt;/code>&lt;/li>
&lt;li>重启 PowerShell&lt;/li>
&lt;/ol>
&lt;p>切换环境操作结束后，可以注意到命令行左侧的括号内容由 (base) 变为 (handwrittendigits)，表明切换成功，后面的操作均在此虚拟环境中进行。&lt;/p>
&lt;pre>&lt;code>实际操作过程
(base) PS C:\Users\xvyn&amp;gt; conda activate handwrittendigits
(handwrittendigits) PS C:\Users\xvyn&amp;gt;
再次查看所有虚拟环境
(handwrittendigits) PS C:\Users\xvyn&amp;gt; conda info --envs
conda environments:
base C:\Users\xvyn\anaconda3
handwrittendigits * C:\Users\xvyn\anaconda3\envs\handwrittendigits
&lt;/code>&lt;/pre>
&lt;h2 id="更换镜像源">更换镜像源&lt;/h2>
&lt;p>由于 Anaconda 和 pip 官方镜像源访问缓慢，故需要将镜像源更换为国内镜像源，例如清华大学、中科大与阿里云镜像源。使用下列命令可以查看当前 Anaconda 镜像源。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda config --show
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在输出中找到 channel 部分，有如下内容。&lt;/p>
&lt;pre>&lt;code>channels:
- defaults
default_channels:
- https://repo.anaconda.com/pkgs/main
- https://repo.anaconda.com/pkgs/r
- https://repo.anaconda.com/pkgs/msys2
&lt;/code>&lt;/pre>
&lt;h3 id="更换-anaconda-镜像源">更换 Anaconda 镜像源&lt;/h3>
&lt;p>以清华大学镜像源为例，执行下列命令即可完成更换。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
&lt;span class="ln">2&lt;/span>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
&lt;span class="ln">3&lt;/span>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
&lt;span class="ln">4&lt;/span>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
&lt;span class="ln">5&lt;/span>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/
&lt;span class="ln">6&lt;/span>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/
&lt;span class="ln">7&lt;/span>conda config --set show_channel_urls yes
&lt;/code>&lt;/pre>&lt;/div>&lt;p>恢复默认源&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda config --remove-key channels
&lt;/code>&lt;/pre>&lt;/div>&lt;p>除了上述命令行操作方式外，也可以直接修改 C:\Users&amp;lt;USER&amp;gt;\.condarc 文件来实现换源。参考 &lt;a class="link" href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/" target="_blank" rel="noopener"
>Anaconda 镜像使用帮助&lt;/a> 修改后的文件内容如下所示。&lt;/p>
&lt;pre>&lt;code>ssl_verify: false
show_channel_urls: true
channels:
- defaults
default_channels:
- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro
- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
custom_channels:
conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
&lt;/code>&lt;/pre>
&lt;h3 id="更换-pip-镜像源">更换 pip 镜像源&lt;/h3>
&lt;p>以清华大学镜像源为例，执行下列命令即可完成更换。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>pip config &lt;span class="nb">set&lt;/span> global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="安装-tensorflow">安装 tensorflow&lt;/h2>
&lt;p>手写数字生成例子所需要的 tensorflow 版本为 1.x，本例中我们使用的实际版本为 1.8.0。将虚拟环境切换到 handwrittendigits 后，执行以下命令开始安装。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda install tensorflow-gpu&lt;span class="o">=&lt;/span>1.8.0
&lt;/code>&lt;/pre>&lt;/div>&lt;p>上述命令中 &lt;code>tensorflow-gpu&lt;/code> 表示安装的 tensorflow 为 GPU 版本，&lt;code>=1.8.0&lt;/code> 指定了安装的版本号。若需要安装 CPU 版 tensorflow 1.8.0，执行以下命令即可。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>conda install &lt;span class="nv">tensorflow&lt;/span>&lt;span class="o">=&lt;/span>1.8.0
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="安装-python">安装 Python&lt;/h2>
&lt;p>由于需要 1.8.0 版本的 tensorflow，此版本仅兼容 3.5 到 3.7 版本的 Python，故需要先删除 conda 环境中默认安装的 Python，并安装 3.6 版本。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="c1"># 移除自带 Python&lt;/span>
&lt;span class="ln">2&lt;/span>conda remove python
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="c1"># 安装 3.6 版本&lt;/span>
&lt;span class="ln">5&lt;/span>conda install &lt;span class="nv">python&lt;/span>&lt;span class="o">=&lt;/span>3.6
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="测试-demo">测试 Demo&lt;/h1>
&lt;h2 id="使用-pycharm-创建项目">使用 PyCharm 创建项目&lt;/h2>
&lt;p>在创建项目时，需要将虚拟环境（图中 Location 项）配置为前文中创建的虚拟环境所在目录，然后点击创建项目。&lt;/p>
&lt;p>&lt;em>由于此前作者已经创建过项目，故创建窗口下方会提示虚拟环境目录不为空，忽略即可。&lt;/em>&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201208194401.png" alt="20201208194401" />&lt;/p>
&lt;h2 id="运行项目">运行项目&lt;/h2>
&lt;p>将以下代码置于项目 &lt;code>main.py&lt;/code> 中，运行。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln"> 1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kn">from&lt;/span> &lt;span class="nn">tensorflow.examples.tutorials.mnist&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">input_data&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.gridspec&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">gridspec&lt;/span>
&lt;span class="ln"> 6&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">logging&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;span class="ln"> 8&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">exists&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;./log&amp;#39;&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 10&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mkdir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;./log&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 11&lt;/span>&lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">exists&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;./out&amp;#39;&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 12&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mkdir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;./out&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 13&lt;/span>
&lt;span class="ln"> 14&lt;/span>
&lt;span class="ln"> 15&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">get_logger&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filepath&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">level&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">logging&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">INFO&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 16&lt;/span> &lt;span class="n">logger&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">logging&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getLogger&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="vm">__name__&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 17&lt;/span> &lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">setLevel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">level&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 18&lt;/span>
&lt;span class="ln"> 19&lt;/span> &lt;span class="c1"># create a file handler&lt;/span>
&lt;span class="ln"> 20&lt;/span> &lt;span class="n">handler&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">logging&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FileHandler&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filepath&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 21&lt;/span> &lt;span class="n">handler&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">setLevel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">logging&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">INFO&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 22&lt;/span>
&lt;span class="ln"> 23&lt;/span> &lt;span class="c1"># create a logging format&lt;/span>
&lt;span class="ln"> 24&lt;/span> &lt;span class="c1"># formatter = logging.Formatter(&amp;#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&amp;#39;)&lt;/span>
&lt;span class="ln"> 25&lt;/span> &lt;span class="c1"># handler.setFormatter(formatter)&lt;/span>
&lt;span class="ln"> 26&lt;/span>
&lt;span class="ln"> 27&lt;/span> &lt;span class="c1"># add the handlers to the logger&lt;/span>
&lt;span class="ln"> 28&lt;/span> &lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">addHandler&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">handler&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 29&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">logger&lt;/span>
&lt;span class="ln"> 30&lt;/span>
&lt;span class="ln"> 31&lt;/span>
&lt;span class="ln"> 32&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">samples&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 33&lt;/span> &lt;span class="n">fig&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">figure&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">figsize&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln"> 34&lt;/span> &lt;span class="n">gs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">gridspec&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GridSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 35&lt;/span> &lt;span class="n">gs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">update&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wspace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.05&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hspace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.05&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 36&lt;/span>
&lt;span class="ln"> 37&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sample&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">samples&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 38&lt;/span> &lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">gs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 39&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;off&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 40&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_xticklabels&lt;/span>&lt;span class="p">([])&lt;/span>
&lt;span class="ln"> 41&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_yticklabels&lt;/span>&lt;span class="p">([])&lt;/span>
&lt;span class="ln"> 42&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_aspect&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;equal&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 43&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sample&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;Greys_r&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 44&lt;/span>
&lt;span class="ln"> 45&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">fig&lt;/span>
&lt;span class="ln"> 46&lt;/span>
&lt;span class="ln"> 47&lt;/span>
&lt;span class="ln"> 48&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">random_data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">row&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">column&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 49&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uniform&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mf">1.&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">1.&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">row&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">column&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 50&lt;/span>
&lt;span class="ln"> 51&lt;/span>
&lt;span class="ln"> 52&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">weight_variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">stddev&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 53&lt;/span> &lt;span class="n">initial&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">truncated_normal&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">stddev&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">stddev&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 54&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">initial&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 55&lt;/span>
&lt;span class="ln"> 56&lt;/span>
&lt;span class="ln"> 57&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">bias_variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">bais&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 58&lt;/span> &lt;span class="n">initial&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">constant&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bais&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 59&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">initial&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 60&lt;/span>
&lt;span class="ln"> 61&lt;/span>
&lt;span class="ln"> 62&lt;/span>&lt;span class="c1"># 鉴别网络weights&lt;/span>
&lt;span class="ln"> 63&lt;/span>&lt;span class="n">d_w1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight_variable&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">784&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 64&lt;/span>&lt;span class="n">d_b1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">bias_variable&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 65&lt;/span>
&lt;span class="ln"> 66&lt;/span>&lt;span class="n">d_w2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight_variable&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 67&lt;/span>&lt;span class="n">d_b2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">bias_variable&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 68&lt;/span>
&lt;span class="ln"> 69&lt;/span>&lt;span class="n">param_d&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">d_w1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_w2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_b1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_b2&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="ln"> 70&lt;/span>
&lt;span class="ln"> 71&lt;/span>&lt;span class="c1"># 生成网络weights&lt;/span>
&lt;span class="ln"> 72&lt;/span>&lt;span class="n">g_w1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight_variable&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 73&lt;/span>&lt;span class="n">g_b1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">bias_variable&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 74&lt;/span>
&lt;span class="ln"> 75&lt;/span>&lt;span class="n">g_w2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">weight_variable&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">784&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 76&lt;/span>&lt;span class="n">g_b2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">bias_variable&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">784&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 77&lt;/span>
&lt;span class="ln"> 78&lt;/span>&lt;span class="n">param_g&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">g_w1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_w2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_b1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_b2&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="ln"> 79&lt;/span>
&lt;span class="ln"> 80&lt;/span>
&lt;span class="ln"> 81&lt;/span>&lt;span class="c1"># 鉴别网络&lt;/span>
&lt;span class="ln"> 82&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">d_network&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 83&lt;/span> &lt;span class="n">d1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_w1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">d_b1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 84&lt;/span> &lt;span class="n">d_out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">d1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_w2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">d_b2&lt;/span>
&lt;span class="ln"> 85&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">d_out&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 86&lt;/span>
&lt;span class="ln"> 87&lt;/span>
&lt;span class="ln"> 88&lt;/span>&lt;span class="c1"># 生成网络&lt;/span>
&lt;span class="ln"> 89&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">g_network&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 90&lt;/span> &lt;span class="n">g1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_w1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">g_b1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 91&lt;/span> &lt;span class="n">g_out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_w2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">g_b2&lt;/span>
&lt;span class="ln"> 92&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g_out&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 93&lt;/span>
&lt;span class="ln"> 94&lt;/span>
&lt;span class="ln"> 95&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">placeholder&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">784&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 96&lt;/span>&lt;span class="n">z&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">placeholder&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">100&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln"> 97&lt;/span>
&lt;span class="ln"> 98&lt;/span>&lt;span class="n">d_out_real&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">d_network&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 99&lt;/span>
&lt;span class="ln">100&lt;/span>&lt;span class="n">g_out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">g_network&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">z&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">101&lt;/span>&lt;span class="n">d_out_fake&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">d_network&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g_out&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">102&lt;/span>
&lt;span class="ln">103&lt;/span>&lt;span class="n">d_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reduce_mean&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">d_out_real&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">1.&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">d_out_fake&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">104&lt;/span>&lt;span class="n">g_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reduce_mean&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">d_out_fake&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">105&lt;/span>
&lt;span class="ln">106&lt;/span>&lt;span class="n">d_optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AdamOptimizer&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">minimize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">d_loss&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">var_list&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">param_d&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">107&lt;/span>&lt;span class="n">g_optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AdamOptimizer&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">minimize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g_loss&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">var_list&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">param_g&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">108&lt;/span>
&lt;span class="ln">109&lt;/span>&lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">256&lt;/span>
&lt;span class="ln">110&lt;/span>&lt;span class="n">max_step&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1000000&lt;/span>
&lt;span class="ln">111&lt;/span>&lt;span class="n">mnist&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">input_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read_data_sets&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;../mnist&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">one_hot&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">112&lt;/span>&lt;span class="n">logger&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">get_logger&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;./log/info.log&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">113&lt;/span>
&lt;span class="ln">114&lt;/span>&lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Session&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="ln">115&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">global_variables_initializer&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="ln">116&lt;/span> &lt;span class="k">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;training&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">117&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="ln">118&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">step&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">max_step&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln">119&lt;/span> &lt;span class="n">batch_real&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mnist&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">next_batch&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">120&lt;/span> &lt;span class="n">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_loss_train&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">d_optimizer&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_loss&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">feed_dict&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">batch_real&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">z&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">random_data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">100&lt;/span>&lt;span class="p">)})&lt;/span>
&lt;span class="ln">121&lt;/span> &lt;span class="n">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_loss_train&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">g_optimizer&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_loss&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">feed_dict&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">z&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">random_data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">100&lt;/span>&lt;span class="p">)})&lt;/span>
&lt;span class="ln">122&lt;/span>
&lt;span class="ln">123&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">step&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="mi">1000&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="ln">124&lt;/span> &lt;span class="n">samples&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g_out&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">feed_dict&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">z&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">random_data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">100&lt;/span>&lt;span class="p">)})&lt;/span>
&lt;span class="ln">125&lt;/span>
&lt;span class="ln">126&lt;/span> &lt;span class="n">fig&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">samples&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">127&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">savefig&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;out/{}.png&amp;#39;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zfill&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">)),&lt;/span> &lt;span class="n">bbox_inches&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;tight&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">128&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;span class="ln">129&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">close&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fig&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">130&lt;/span>
&lt;span class="ln">131&lt;/span> &lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">info&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;step &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s2">: d_loss is &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s2">, gan_loss is &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_loss_train&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_loss_train&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">132&lt;/span> &lt;span class="k">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;step &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s2">: d_loss is &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s2">, g_loss is &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d_loss_train&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">g_loss_train&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>运行时的截图如下，可以看到已经生成了多张手写数字的图片。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201208201913.png" alt="20201208201913" />&lt;/p>
&lt;p>至此，GAN 网络手写数字生成环境搭建已经完成，后续将进行更加深入的学习。&lt;/p>
&lt;h1 id="参考文章">参考文章&lt;/h1>
&lt;ol>
&lt;li>&lt;a class="link" href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda.html" target="_blank" rel="noopener"
>Anaconda 源使用帮助&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/yang1688899/gan_practice/blob/master/gan_mnist/gan_mnist.py" target="_blank" rel="noopener"
>gan_practice&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/conda/conda/issues/7980#issuecomment-515887073" target="_blank" rel="noopener"
>Can&amp;rsquo;t execute &lt;code>conda activate&lt;/code> from bash script&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.jianshu.com/p/c845bfd09582" target="_blank" rel="noopener"
>python 安装 TensorFlow 吐血整理&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://zhuanlan.zhihu.com/p/103134466" target="_blank" rel="noopener"
>conda 安装指定版本的指定包&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://luanlengli.github.io/2019/12/19/Python-pip%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%AE%BE%E7%BD%AE%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E6%BA%90.html" target="_blank" rel="noopener"
>Python pip 命令行设置国内镜像源&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>FastDFS 搭建分布式文件管理系统</title><link>https://sudrizzz.github.io/posts/getting-to-know-fastdfs/</link><pubDate>Wed, 04 Nov 2020 17:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-fastdfs/</guid><description>&lt;h1 id="fastdfs-简介">FastDFS 简介&lt;/h1>
&lt;p>FastDFS 是一个开源的高性能分布式文件系统（Distributed File System）。它的主要功能包括：文件存储、文件同步和文件访问以及高容量和负载平衡。主要解决了海量数据存储问题，特别适合以中小文件（建议范围：4KB &amp;lt; file_size &amp;lt; 500MB）为载体的在线服务。&lt;/p>
&lt;p>FastDFS 开源地址：https://github.com/happyfish100/fastdfs&lt;/p>
&lt;p>由于网络上已有很多详细的关于 FastDFS 的介绍，故此处不再赘述。请查看参考文章中的第 1、2 条。&lt;/p>
&lt;h2 id="fastdfs-架构图">FastDFS 架构图&lt;/h2>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201103150000.jpg" alt="20201103150000" />&lt;/p>
&lt;h2 id="fastdfs-上传流程">FastDFS 上传流程&lt;/h2>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201104100033.png" alt="20201104100033" />&lt;/p>
&lt;h2 id="fastdfs-下载流程">FastDFS 下载流程&lt;/h2>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201104100107.png" alt="20201104100107" />&lt;/p>
&lt;h1 id="安装-fastdfs">安装 FastDFS&lt;/h1>
&lt;h2 id="配置防火墙">配置防火墙&lt;/h2>
&lt;p>本篇文章是基于 CentOS v8.2.2004 版本，以下操作均为单机环境，单机 IP 地址为 192.168.61.128。在安装 FastDFS 之前，需要先进行防火墙的设置。防火墙的相关命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="c1"># 暂时关闭防火墙&lt;/span>
&lt;span class="ln">2&lt;/span>systemctl stop firewalld
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="c1"># 永久关闭防火墙&lt;/span>
&lt;span class="ln">5&lt;/span>systemctl disable firewalld
&lt;span class="ln">6&lt;/span>
&lt;span class="ln">7&lt;/span>&lt;span class="c1"># 启用防火墙&lt;/span>
&lt;span class="ln">8&lt;/span>systemctl &lt;span class="nb">enable&lt;/span> firewalld
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="下载安装-libfastcommon">下载安装 libfastcommon&lt;/h2>
&lt;p>libfastcommon 是从 FastDFS 抽取出来的公共 c 函数库。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln"> 1&lt;/span>&lt;span class="c1"># 下载&lt;/span>
&lt;span class="ln"> 2&lt;/span>wget https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz
&lt;span class="ln"> 3&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="c1"># 解压&lt;/span>
&lt;span class="ln"> 5&lt;/span>tar -zxvf V1.0.43.tar.gz
&lt;span class="ln"> 6&lt;/span>&lt;span class="nb">cd&lt;/span> libfastcommon-1.0.43
&lt;span class="ln"> 7&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="c1"># 编译安装&lt;/span>
&lt;span class="ln"> 9&lt;/span>./make.sh
&lt;span class="ln">10&lt;/span>./make.sh install
&lt;/code>&lt;/pre>&lt;/div>&lt;p>libfastcommon.so 安装到了 &lt;code>/usr/lib64/libfastcommon.so&lt;/code>，但是 FastDFS 主程序设置的 lib 目录是 &lt;code>/usr/local/lib&lt;/code>，所以需要创建软链接。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so
&lt;span class="ln">2&lt;/span>ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so
&lt;span class="ln">3&lt;/span>ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so
&lt;span class="ln">4&lt;/span>ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="下载安装-fastdfs">下载安装 FastDFS&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln"> 1&lt;/span>&lt;span class="c1"># 下载&lt;/span>
&lt;span class="ln"> 2&lt;/span>wget https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz
&lt;span class="ln"> 3&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="c1"># 解压&lt;/span>
&lt;span class="ln"> 5&lt;/span>tar -zxvf V6.06.tar.gz
&lt;span class="ln"> 6&lt;/span>&lt;span class="nb">cd&lt;/span> fastdfs-6.06
&lt;span class="ln"> 7&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="c1"># 编译安装&lt;/span>
&lt;span class="ln"> 9&lt;/span>./make.sh
&lt;span class="ln">10&lt;/span>./make.sh install
&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装完成之后，服务脚本存储在 &lt;code>/etc/init.d/&lt;/code> 中，详细文件如下：&lt;/p>
&lt;pre>&lt;code>/etc/init.d/fdfs_storaged
/etc/init.d/fdfs_tracker
&lt;/code>&lt;/pre>
&lt;p>默认配置文件存储在 &lt;code>/etc/fdfs/&lt;/code> 中，详细文件如下：&lt;/p>
&lt;pre>&lt;code>/etc/fdfs/client.conf.sample
/etc/fdfs/storage.conf.sample
/etc/fdfs/tracker.conf.sample
&lt;/code>&lt;/pre>
&lt;p>命令工具存储在 &lt;code>/usr/bin/&lt;/code> 中，详细文件如下：&lt;/p>
&lt;pre>&lt;code>fdfs_appender_test
fdfs_appender_test1
fdfs_append_file
fdfs_crc32
fdfs_delete_file
fdfs_download_file
fdfs_file_info
fdfs_monitor
fdfs_regenerate_filename
fdfs_storaged
fdfs_test
fdfs_test1
fdfs_trackerd
fdfs_upload_appender
fdfs_upload_file
stop.sh
restart.sh
&lt;/code>&lt;/pre>
&lt;h1 id="配置-fastdfs-tracker-服务">配置 FastDFS Tracker 服务&lt;/h1>
&lt;h2 id="修改配置文件">修改配置文件&lt;/h2>
&lt;p>从上文可知，配置文件在 &lt;code>/etc/fdfs/&lt;/code> 中，我们需要拷贝一份并进行一些修改。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /etc/fdfs
&lt;span class="ln">2&lt;/span>cp tracker.conf.sample tracker.conf
&lt;span class="ln">3&lt;/span>vim tracker.conf
&lt;/code>&lt;/pre>&lt;/div>&lt;p>需要修改的部分如下：&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config"># Tracker 数据和日志存储目录
base_path = /home/fastdfs/tracker
# HTTP 服务端口
http.server_port = 80
&lt;/code>&lt;/pre>&lt;p>根据上述配置，创建配置中的目录&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>mkdir -p /home/fastdfs/tracker
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="启动-tracker-服务">启动 Tracker 服务&lt;/h2>
&lt;p>初次成功启动，会在 base_path 即 &lt;code>/home/fastdfs/tracker&lt;/code> 下创建 data、logs 两个目录。启动命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>/etc/init.d/fdfs_trackerd start
&lt;span class="ln">2&lt;/span>&lt;span class="c1"># 或&lt;/span>
&lt;span class="ln">3&lt;/span>service fdfs_trackerd start
&lt;/code>&lt;/pre>&lt;/div>&lt;p>启动后，可以通过 netstat 命令查看是都启动成功，若得到以下类似输出，22122 端口处于监听状态，则表示 Tracker 服务安装并启动成功。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>netstat -unltp &lt;span class="p">|&lt;/span> grep fdfs
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># 输出内容
tcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 6220/fdfs_trackerd
&lt;/code>&lt;/pre>
&lt;p>同理，可以通过下列命令关闭 Tracker 服务或者设置 Tracker 开机自启：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="c1"># 关闭服务&lt;/span>
&lt;span class="ln">2&lt;/span>service fdfs_trackerd stop
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="c1"># 开机自启&lt;/span>
&lt;span class="ln">5&lt;/span>chkconfig fdfs_trackerd on
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="配置-fastdfs-storage-服务">配置 FastDFS Storage 服务&lt;/h1>
&lt;h2 id="修改配置文件-1">修改配置文件&lt;/h2>
&lt;p>与配置 Tracker 服务类似，首先我们也需要拷贝样例配置文件并进行相应修改。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /etc/fdfs
&lt;span class="ln">2&lt;/span>cp storage.conf.sample storage.conf
&lt;span class="ln">3&lt;/span>vim storage.conf
&lt;/code>&lt;/pre>&lt;/div>&lt;p>需要修改的部分如下：&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config"># Tracker 数据和日志存储目录
base_path = /home/fastdfs/storage
# 存放文件时 storage server 支持多个路径。这里配置存放文件的基路径数目，通常只配一个目录
store_path_count=1
# 逐一配置 store_path_count 个路径，索引号基于 0
# 如果不配置 store_path0，那它就和 base_path 对应的路径一样
store_path0=/home/fastdfs/file
# FastDFS 存储文件时，采用了两级目录。这里配置存放文件的目录个数。
# 如果本参数为 N（默认 256），那么 storage server 在初次运行时，会在 store_path 下自动创建 N*N 个存放文件的子目录
subdir_count_per_path=256
# tracker_server 的列表 ，会主动连接 tracker_server
# 有多个 tracker server 时，每个 tracker server 写一行
tracker_server=192.168.61.128:22122
# HTTP 服务端口
http.server_port = 80
&lt;/code>&lt;/pre>&lt;p>根据上述配置，创建配置中的目录&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="c1"># base_path&lt;/span>
&lt;span class="ln">2&lt;/span>mkdir -p /home/fastdfs/storage
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="c1"># store_path0&lt;/span>
&lt;span class="ln">5&lt;/span>mkdir -p /home/fastdfs/file
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="启动-storage-服务">启动 Storage 服务&lt;/h2>
&lt;p>启动 Storage 前确保 Tracker 是启动的。初次启动成功，会在 base_path 即 &lt;code>/home/fastdfs/storage/&lt;/code> 目录下创建 data、logs 两个目录。启动命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>/etc/init.d/fdfs_storaged start
&lt;span class="ln">2&lt;/span>&lt;span class="c1"># 或&lt;/span>
&lt;span class="ln">3&lt;/span>service fdfs_storaged start
&lt;/code>&lt;/pre>&lt;/div>&lt;p>启动后，可以通过下列命令查看 Storage 服务是否启动成功。若输出结果与下列输出类似，23000 端口正处于监听状态，则 Storage 服务启动成功。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>netstat -unltp &lt;span class="p">|&lt;/span> grep fdfs
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># 输出内容
tcp 0 0 0.0.0.0:23000 0.0.0.0:* LISTEN 6257/fdfs_storaged
tcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 6220/fdfs_trackerd
&lt;/code>&lt;/pre>
&lt;p>同理，可以通过下列命令关闭 Tracker 服务或者设置 Tracker 开机自启：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="c1"># 关闭服务&lt;/span>
&lt;span class="ln">2&lt;/span>service fdfs_storaged stop
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="c1"># 开机自启&lt;/span>
&lt;span class="ln">5&lt;/span>chkconfig fdfs_storaged on
&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时我们可以在 store_path0 目录下看到 Storage 服务自动创建的 N*N 个子目录&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>ls /home/fastdfs/file/data/
&lt;span class="ln">2&lt;/span>
&lt;span class="ln">3&lt;/span>&lt;span class="c1"># 统计文件夹数量&lt;/span>
&lt;span class="ln">4&lt;/span>ls -l &lt;span class="p">|&lt;/span> grep &lt;span class="s2">&amp;#34;^d&amp;#34;&lt;/span> &lt;span class="p">|&lt;/span> wc -l
&lt;span class="ln">5&lt;/span>
&lt;span class="ln">6&lt;/span>&lt;span class="nb">cd&lt;/span> &lt;span class="m">00&lt;/span>
&lt;span class="ln">7&lt;/span>ls -l &lt;span class="p">|&lt;/span> grep &lt;span class="s2">&amp;#34;^d&amp;#34;&lt;/span> &lt;span class="p">|&lt;/span> wc -l
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># 输出内容
00 0A 14 1E 28 32 3C 46 50 5A 64 6E 78 82 8C 96 A0 AA B4 BE C8 D2 DC E6 F0 FA
01 0B 15 1F 29 33 3D 47 51 5B 65 6F 79 83 8D 97 A1 AB B5 BF C9 D3 DD E7 F1 FB
02 0C 16 20 2A 34 3E 48 52 5C 66 70 7A 84 8E 98 A2 AC B6 C0 CA D4 DE E8 F2 FC
03 0D 17 21 2B 35 3F 49 53 5D 67 71 7B 85 8F 99 A3 AD B7 C1 CB D5 DF E9 F3 FD
04 0E 18 22 2C 36 40 4A 54 5E 68 72 7C 86 90 9A A4 AE B8 C2 CC D6 E0 EA F4 FE
05 0F 19 23 2D 37 41 4B 55 5F 69 73 7D 87 91 9B A5 AF B9 C3 CD D7 E1 EB F5 FF
06 10 1A 24 2E 38 42 4C 56 60 6A 74 7E 88 92 9C A6 B0 BA C4 CE D8 E2 EC F6
07 11 1B 25 2F 39 43 4D 57 61 6B 75 7F 89 93 9D A7 B1 BB C5 CF D9 E3 ED F7
08 12 1C 26 30 3A 44 4E 58 62 6C 76 80 8A 94 9E A8 B2 BC C6 D0 DA E4 EE F8
09 13 1D 27 31 3B 45 4F 59 63 6D 77 81 8B 95 9F A9 B3 BD C7 D1 DB E5 EF F9
256
256
&lt;/code>&lt;/pre>
&lt;h1 id="文件上传测试">文件上传测试&lt;/h1>
&lt;h2 id="修改配置文件-2">修改配置文件&lt;/h2>
&lt;p>与配置 Storage 服务类似，首先我们也需要拷贝客户端样例配置文件并进行相应修改。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /etc/fdfs
&lt;span class="ln">2&lt;/span>cp client.conf.sample client.conf
&lt;span class="ln">3&lt;/span>vim client.conf
&lt;/code>&lt;/pre>&lt;/div>&lt;p>需要修改的部分如下：&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config"># Client 的数据和日志目录
base_path=/home/fastdfs/client
# Tracker端口
tracker_server=192.168.61.128:22122
&lt;/code>&lt;/pre>&lt;h2 id="上传图片测试">上传图片测试&lt;/h2>
&lt;p>执行下列命令，尝试上传一张图片到 FastDFS 中：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>fdfs_upload_file /home/Pictures/1989.jpg
&lt;/code>&lt;/pre>&lt;/div>&lt;p>上传成功后，会输出文件 ID：group1/M00/00/00/wKg9gF-f0aKAUJAlAARra4mLMhc390.jpg&lt;/p>
&lt;p>返回的文件 ID 由 group、存储目录、两级子目录、fileid、文件后缀名（由客户端指定，主要用于区分文件类型）拼接而成。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201104093640.png" alt="20201104093640" />&lt;/p>
&lt;h1 id="配置-nginx">配置 Nginx&lt;/h1>
&lt;p>安装 Nginx 的相关操作请查看文章 &lt;a class="link" href="https://sudrizzz.github.io/posts/getting-to-know-nginx/" target="_blank" rel="noopener"
>初识 Nginx&lt;/a>，此处不再赘述。&lt;/p>
&lt;h2 id="修改配置">修改配置&lt;/h2>
&lt;p>经过上述操作之后，文件已经可以通过命令行的方式上传到 FastDFS 中，但还无法下载，此时我们需要使用 Nginx 来实现下载功能。修改 Nginx 配置文件，在 server 组内添加以下内容：&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">server {
listen 80;
server_name localhost;
# 添加以下部分
location /group1/M00 {
alias /home/fastdfs/file/data;
}
}
&lt;/code>&lt;/pre>&lt;p>然后重启 Nginx，访问服务器 ip/fileid 进行测试，根据上述例子，此处访问 http://192.168.61.128/group1/M00/00/00/wKg9gF-f0aKAUJAlAARra4mLMhc390.jpg&lt;/p>
&lt;p>测试结果如下图，可以看到已经访问成功，HTTP 状态码返回 200。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201104104028.png" alt="20201104104028" />&lt;/p>
&lt;h1 id="配置-fastdfs-nginx-module-模块">配置 fastdfs-nginx-module 模块&lt;/h1>
&lt;h2 id="模块简介">模块简介&lt;/h2>
&lt;p>fastdfs-nginx-module 可以重定向文件链接到源服务器，避免由于 Storage 服务器复制延迟导致文件无法访问而产生的错误。&lt;/p>
&lt;h2 id="下载解压">下载解压&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>wget https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz
&lt;span class="ln">2&lt;/span>tar -zxvf V1.22.tar.gz
&lt;span class="ln">3&lt;/span>&lt;span class="nb">cd&lt;/span> fastdfs-nginx-module
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="为-nginx-添加模块">为 Nginx 添加模块&lt;/h2>
&lt;p>首先进入 Nginx 源目录，然后执行 &lt;code>./configure&lt;/code> 命令，具体命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>nginx -s stop
&lt;span class="ln">2&lt;/span>&lt;span class="nb">cd&lt;/span> /usr/local/software/nginx-1.18.0
&lt;span class="ln">3&lt;/span>./configure --prefix&lt;span class="o">=&lt;/span>/usr/local/nginx/ --add-module&lt;span class="o">=&lt;/span>&lt;span class="nv">$YOUR_PATH&lt;/span>/fastdfs-nginx-module/src
&lt;span class="ln">4&lt;/span>make &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> make install
&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中，&lt;code>/usr/local/software/nginx-1.18.0&lt;/code> 为 Nginx 源目录，&lt;code>--prefix&lt;/code> 参数指定新版本生成的目录，&lt;code>--add-module&lt;/code> 参数表示添加模块，&lt;code>$YOUR_PATH&lt;/code> 需要手动替换为 fastdfs-nginx-module 模块的文件路径，本例中为 &lt;code>/usr/local/software/fastdfs-nginx-module&lt;/code>。&lt;/p>
&lt;p>安装好之后可以通过以下命令查看 Nginx 模块，如果输出与下列内容类似，则表示模块添加成功。&lt;/p>
&lt;pre>&lt;code>nginx -V
&lt;/code>&lt;/pre>&lt;pre>&lt;code># 输出内容
nginx version: nginx/1.18.0
built by gcc 8.3.1 20191121 (Red Hat 8.3.1-5) (GCC)
configure arguments: --prefix=/usr/local/nginx/ --add-module=/usr/local/software/fastdfs-nginx-module/src
&lt;/code>&lt;/pre>
&lt;h2 id="修改-nginx-配置">修改 Nginx 配置&lt;/h2>
&lt;p>修改 nginx.conf，在 server 中做出如下修改：&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">server {
listen 80;
server_name localhost;
# 删除以下部分
location /group1/M00 {
alias /home/fastdfs/file/data;
}
# 添加以下部分
location ~/group[0-9]/ {
ngx_fastdfs_module;
}
}
&lt;/code>&lt;/pre>&lt;h2 id="修改-fastdfs-nginx-module-配置">修改 fastdfs-nginx-module 配置&lt;/h2>
&lt;p>复制 fastdfs-nginx-module 源码中的配置文件到 &lt;code>/etc/fdfs&lt;/code> 目录，兵做以下修改。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /usr/local/software/fastdfs-nginx-module/src
&lt;span class="ln">2&lt;/span>cp mod_fastdfs.conf /etc/fdfs/
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code class="language-config" data-lang="config"># Tracker Server
tracker_server=192.168.61.128:22122
# Storage Server 默认端口
storage_server_port=23000
# 如果文件 ID 的 uri 中包含 /group**，则要设置为 true
url_have_group_name = true
# Storage 配置的 store_path0 路径，必须和 storage.conf 中的一致
store_path0=/home/fastdfs/file
&lt;/code>&lt;/pre>&lt;p>复制 FastDFS 的部分配置文件到 &lt;code>/etc/fdfs&lt;/code> 目录&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /usr/local/software/fastdfs-5.05/conf/
&lt;span class="ln">2&lt;/span>cp anti-steal.jpg http.conf mime.types /etc/fdfs/
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="测试">测试&lt;/h2>
&lt;p>配置完成之后，我们先启动 Nginx 服务，并观察输出内容，如果与下列输出类似，则表示配置成功。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>nginx
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># 输出内容
ngx_http_fastdfs_set pid=11648
&lt;/code>&lt;/pre>
&lt;p>此时我们可以在浏览器中访问前文中上传的文件，能下载文件则表示 fastdfs-nginx-module 模块安装成功。注意和和前文中直接使用 Nginx 路由访问不同的是，这里配置 fastdfs-nginx-module 模块，可以重定向文件链接到源服务器取文件。访问结果如下图所示。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201104104028.png" alt="20201104104028" />&lt;/p>
&lt;p>至此，FastDFS 搭建分布式文件管理系统就初步完成了，在下一篇文章中，将介绍如何在客户端上通过 Java 来实现文件的上传和下载。&lt;/p>
&lt;h1 id="参考文章">参考文章&lt;/h1>
&lt;ol>
&lt;li>&lt;a class="link" href="https://www.cnblogs.com/chiangchou/p/fastdfs.html" target="_blank" rel="noopener"
>用 FastDFS 一步步搭建文件管理系统&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.cnblogs.com/myitnews/p/12214319.html" target="_blank" rel="noopener"
>FastDFS 简介&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://programmer.ink/think/fastdfs-distributed-file-storage.html" target="_blank" rel="noopener"
>FastDFS Distributed File Storage&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="http://bbs.chinaunix.net/forum.php?mod=viewthread&amp;amp;tid=1941456" target="_blank" rel="noopener"
>FastDFS 配置文件详解（修订版 1）&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://sudrizzz.github.io/posts/getting-to-know-nginx/" target="_blank" rel="noopener"
>初识 Nginx&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/happyfish100/fastdfs-nginx-module/blob/master/INSTALL" target="_blank" rel="noopener"
>fastdfs nginx module installation introduction&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Spark 分布式内存计算框架</title><link>https://sudrizzz.github.io/posts/spark-distributed-programming/</link><pubDate>Fri, 23 Oct 2020 20:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/spark-distributed-programming/</guid><description>&lt;h1 id="spark-简介">Spark 简介&lt;/h1>
&lt;p>Spark 是一种基于内存的、用以实现高效集群计算的平台。准确地讲，Spark 是一个大数据并行计算框架，是对广泛使用的 MapReduce 计算模型的扩展。Spark 有着自己的生态系统，但同时兼容
HDFS、Hive 等分布式存储系统，可以完美融入 Hadoop 的生态圈中，代替 MapReduce 去执行更为高效的分布式计算。两者的区别在于：基于 MapReduce 的计算引擎通常会将中间结果输出到磁盘上进行存储和容错；而 Spark 则是将中间结果尽量保存在内存中以减少底层存储系统的 I/O，以提高计算速度。&lt;/p>
&lt;h1 id="spark-编程模型">Spark 编程模型&lt;/h1>
&lt;h2 id="核心数据结构-rdd">核心数据结构 RDD&lt;/h2>
&lt;p>Spark 将数据抽象成弹性分布式数据集（Resilient Distributed Dataset, RDD），RDD 实际是分布在集群多个节点上数据的集合，通过操作 RDD 对象来并行化操作集群上的分布式数据。&lt;/p>
&lt;p>RDD 有两种创建方式:&lt;/p>
&lt;ol>
&lt;li>并行化驱动程序中已有的原生集合;&lt;/li>
&lt;li>引用 HDFS、HBase 等外部存储系统上的数据集。&lt;/li>
&lt;/ol>
&lt;p>RDD 可以缓存在内存中，每次对 RDD 操作的结果都可以放到内存中，下一次操作时可直接从内存中读取，相对于 MapReduce,它省去了大量的磁盘 I/O 操作。另外，持久化的 RDD 能够在错误中自动恢复，如果某部分 RDD 丢失，Spark 会自动重算丢失的部分。&lt;/p>
&lt;h2 id="rdd-上的操作">RDD 上的操作&lt;/h2>
&lt;p>从相关数据源获取初始数据形成初始 RDD 后，需要根据应用的需求对得到的初始 RDD 进行必要的处理，来获取满足需求的数据内容，从而对中间数据进行计算加工，得到最终的数据。&lt;/p>
&lt;p>RDD 支持两种操作，一种是转换（Transformation）操作，另一种是行动（Action）操作。&lt;/p>
&lt;h3 id="转换transformation操作">转换（Transformation）操作&lt;/h3>
&lt;p>转换操作即将一个 RDD 转换为一个新的 RDD。值得注意的是，转换操作是惰性的，这就意味着对 RDD 调用某种转换操作时，操作并不会立即执行，而是 Spark 在内部记录下所要求执行的操作的相关信息，当在行动操作中需要用到这些转换出来的 RDD 时才会被计算，下表所示为基本的转换操作。通过转换操作，可以从已有的 RDD 生成出新的 RDD, Spark 使用谱系（Lineage）记录新旧 RDD 之间的依赖关系，一旦持久化的 RDD 丢失部分数据时，Spark 能通过谱系图重新计算丢失的数据。&lt;/p>
&lt;blockquote>
&lt;p>输入数据为 {1, 2, 3, 3}&lt;/p>
&lt;/blockquote>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>函数名&lt;/th>
&lt;th>目的&lt;/th>
&lt;th>示例&lt;/th>
&lt;th style="text-align:center">结果&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>map()&lt;/td>
&lt;td>将数据集中的每个元素经过用户自定义的函数转换形成一个新的 RDD&lt;/td>
&lt;td>rdd.map(x =&amp;gt; x * 2)&lt;/td>
&lt;td style="text-align:center">{2, 4, 6, 6}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>flatMap()&lt;/td>
&lt;td>与 map() 类似，但每个元素输入项都可以被映射到 0 个或多个的输出项，最终将结果“扁平化“后输出&lt;/td>
&lt;td>rdd.flatMap(x =&amp;gt; (1 to x))&lt;/td>
&lt;td style="text-align:center">{1, 1, 2, 1, 2, 3, 1, 2, 3, 3}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>filter()&lt;/td>
&lt;td>对 RDD 元素进行过滤，把经过指定函数后返回值为 true 的元素组成一个新的 RDD&lt;/td>
&lt;td>rdd.filter(x =&amp;gt; (x != 3))&lt;/td>
&lt;td style="text-align:center">{1, 2}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>distinct()&lt;/td>
&lt;td>对数据进行去重，返回一个新的 RDD&lt;/td>
&lt;td>rdd.distinct()&lt;/td>
&lt;td style="text-align:center">{1, 2, 3}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>sample(withReplacement, fraction, seed)&lt;/td>
&lt;td>以指定的随机种子随机抽样出数量为 fraction 的数据，withReplacement 表示是抽出的数据是否放回，true 为有放回的抽样，false 为无放回的抽样&lt;/td>
&lt;td>rdd.sample(true,0.5,3)&lt;/td>
&lt;td style="text-align:center">非确定的&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="行动action操作">行动（Action）操作&lt;/h3>
&lt;p>行动操作会触发 Spark 提交作业，对 RDD 进行实际的计算，并将最终求得的结果返回到驱动器程序，或者写入外部存储系统中。由于行动操作会得到一个结果，所以 Spark 会强制对 RDD 的转换操作进行求值，下表所示为基本的行动操作。&lt;/p>
&lt;blockquote>
&lt;p>输入数据为 {1, 2, 3, 3}&lt;/p>
&lt;/blockquote>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>函数名&lt;/th>
&lt;th>目的&lt;/th>
&lt;th>示例&lt;/th>
&lt;th style="text-align:center">结果&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>collect()&lt;/td>
&lt;td>返回 RDD 中的所有元素&lt;/td>
&lt;td>rdd.collect()&lt;/td>
&lt;td style="text-align:center">{1, 2, 3, 3}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>count()&lt;/td>
&lt;td>返回 RDD 中元素的个数&lt;/td>
&lt;td>rdd.count()&lt;/td>
&lt;td style="text-align:center">4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>countByValue()&lt;/td>
&lt;td>返回 RDD 中各元素出现的次数&lt;/td>
&lt;td>rdd.countByValue()&lt;/td>
&lt;td style="text-align:center">{(1, 1), (2, 1), (3, 2)}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>take(n)&lt;/td>
&lt;td>从 RDD 中返回 n 个元素（任意位置）&lt;/td>
&lt;td>rdd.take(2)&lt;/td>
&lt;td style="text-align:center">{2, 3}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>top(n)&lt;/td>
&lt;td>从 RDD 中返回&lt;strong>前&lt;/strong> n 个元素&lt;/td>
&lt;td>rdd.top(2)&lt;/td>
&lt;td style="text-align:center">{1, 2}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>reduce(func)&lt;/td>
&lt;td>并行整合 RDD 中的所有数据&lt;/td>
&lt;td>rdd.reduce((x, y) =&amp;gt; x + y)&lt;/td>
&lt;td style="text-align:center">9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>fold(zero)(func)&lt;/td>
&lt;td>与 reduce() 类似，但需要提供初始值。加法的默认是 0；乘法的默认是 1&lt;/td>
&lt;td>rdd.fold(1)((x, y) =&amp;gt; x + y)&lt;/td>
&lt;td style="text-align:center">10&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>aggregate()&lt;/td>
&lt;td>与 reduce() 类似，但通常返回不同类型的函数&lt;/td>
&lt;td>rdd.aggregate((0, 0))&lt;!-- raw HTML omitted -->((x, y) =&amp;gt; &lt;!-- raw HTML omitted -->(x._1 + y, x._2 + 1), &lt;!-- raw HTML omitted -->(x, y) =&amp;gt; &lt;!-- raw HTML omitted -->(x._1 + y._1, x._2 + y._2))&lt;/td>
&lt;td style="text-align:center">(9, 4)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>foreach(func)&lt;/td>
&lt;td>对 RDD 中的每个元素使用给定的函数&lt;/td>
&lt;td>rdd.foreach(func)&lt;/td>
&lt;td style="text-align:center">无&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="示例">示例&lt;/h1>
&lt;p>以下两个示例的数据集与源代码均可以在下述链接中进行下载
&lt;a href="https://github.com/sudrizzz/BigDataTechnologyFoundation_SourceCodeAndDataSet/tree/main/ch08">https://github.com/sudrizzz/BigDataTechnologyFoundation_SourceCodeAndDataSet/tree/main/ch08&lt;/a>&lt;/p>
&lt;h2 id="一分词">一、分词&lt;/h2>
&lt;p>WordCount（单词统计程序）是大数据领域经典的例子，与 Hadoop 实现的 WordCount 程序相比，Spark 实现的版本要显得更加简洁。&lt;/p>
&lt;h3 id="从-mapreduce-到-spark">从 MapReduce 到 Spark&lt;/h3>
&lt;p>在经典的计算框架 MapReduce 中，问题会被拆成两个主要阶段: map 阶段和 reduce 阶段。对单词计数来说，MapReduce 程序从 HDFS 中读取一行字符串。在 map 阶段，将字符串分割成单词，并生成 &amp;lt;word, 1&amp;gt; 这样的键值对；在 reduce 阶段，将单词对应的计数值（初始为 1）全部累加起来，最后得到单词的总出现次数。&lt;/p>
&lt;p>在 Spark 中，并没有 map/reduce 这样的划分，而是以 RDD 的转换来呈现程序的逻辑。首先，Spark 程序将从 HDFS 中按行读取的文本作为初始 RDD（即集合的每一个元素都是一行字符串）；然后，通过 flatMap 操作将每一行字符串分割成单词，并收集起来作为新的单词 RDD；接着，使用 map 操作将每一个单词映射成 &amp;lt;word, 1&amp;gt;这样的键值对，转换成新的键值对 RDD；最后，通过 reduceByKey 操作将相同单词的计数值累加起来，得到单词的总出现次数。&lt;/p>
&lt;h3 id="java-实现">Java 实现&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln"> 1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.spark.SparkConf&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.spark.api.java.JavaPairRDD&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.spark.api.java.JavaRDD&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.spark.api.java.JavaSparkContext&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">scala.Tuple2&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 6&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.Arrays&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.List&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.regex.Pattern&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln">10&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">SparkDemo&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Pattern&lt;/span> &lt;span class="n">kSpace&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Pattern&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">compile&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34; &amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">13&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="n">SparkConf&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">SparkConf&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setAppName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;WordCount&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="n">JavaSparkContext&lt;/span> &lt;span class="n">sc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">JavaSparkContext&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">17&lt;/span>
&lt;span class="ln">18&lt;/span> &lt;span class="n">JavaRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">textFile&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">]).&lt;/span>&lt;span class="na">rdd&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">toJavaRDD&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">19&lt;/span> &lt;span class="n">JavaRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">lines&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">flatMap&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">kSpace&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">split&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">iterator&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="ln">20&lt;/span> &lt;span class="n">JavaPairRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">ones&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">mapToPair&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Tuple2&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">1&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="ln">21&lt;/span> &lt;span class="n">JavaPairRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">counts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ones&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">reduceByKey&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">sum&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">22&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Tuple2&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">output&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">counts&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">collect&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">23&lt;/span>
&lt;span class="ln">24&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Tuple2&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">tuple&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">25&lt;/span> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tuple&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">_1&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; : &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">tuple&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">_2&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="ln">26&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">27&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">close&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">28&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">29&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="运行过程分析">运行过程分析&lt;/h3>
&lt;ol>
&lt;li>初始化
创建配置文件 SparkConf，这里仅设置应用名称；再创建 JavaSparkContext，在程序中主要通过 JavaSparkContext 来访问 Spark 集群；&lt;/li>
&lt;li>处理数据
&lt;ol>
&lt;li>根据参数使用 Spark.read().textFile() 方法按行读取输入文件，并转换成 RDD lines；&lt;/li>
&lt;li>使用 flatMap 操作将所有行按空格分割切割成词，并生成新的 RDD words；&lt;/li>
&lt;li>使用 map 操作( Java 中为 mapToPair )，将词映射成 &amp;lt;word, 1&amp;gt;键值对 RDD ones，其中 1 表示出现一次；&lt;/li>
&lt;li>使用 reduceByKey 操作将所有相同的 word 对应的计数累加起来，得到新的 RDD counts；&lt;/li>
&lt;li>使用 collect 操作将所有结果打印出来；&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>关闭 JavaSparkContext。&lt;/li>
&lt;/ol>
&lt;h3 id="执行">执行&lt;/h3>
&lt;p>将上述代码生成 Jar 包之后，将其放到服务器中，执行下面的命令即可开始运行。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>./bin/spark-submit --class SparkDemo ~/Documents/SparkDemo.jar ~/Documents/sample.txt
&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中&lt;/p>
&lt;ul>
&lt;li>&amp;ndash;class SparkDemo 用来指定主类名&lt;/li>
&lt;li>~/Documents/SparkDemo.jar 指定 Jar 包路径&lt;/li>
&lt;li>~/Documents/sample.txt 指定测试文本路径&lt;/li>
&lt;/ul>
&lt;p>sample.txt 文本内容如下所示&lt;/p>
&lt;pre>&lt;code>Your want text it even a text notes having wrong even about fake want or not even but. Language way contentwise just language contentwise recipes set start are. Recipes a words than with meeting days ?looks? even than is name story more story words generator anything gone. Having story but fairly random some adequate want it set has a kind looking having. Fantasy anything you looks just copy work text random sets even fake having. Piece some recipes repetitive adequate wrong wrong way options to repetitive working some dummy repetitive copy realistic you fake. Work or just fairly with is unrelated having language about set forever not game repetitive adequate now you looks it of even dummy now. That but design language unrelated copy you text placeholder has review those of with fake. Random to want the has gardening which business some realistic that and just work. Gardening you realistic kind and name looks about name words words way which some name.
The that copy story realistic the adequate text meeting options game gone piece has options has name random. Days wrong set realistic design repetitive adequate review text your or but having start about right are story fairly fairly but to language sets adequate. But work want sets right kind some having contentwise fairly convincing language notes right name from but want realistic unrelated words. From about generator not looks or fairly copy has more. Forever from gone which or that having a with some having the work wrong generator design a fantasy way convincing. Working in dummy not now happily but to it of happily story want those kind looking right words business it generator language are. A you anything sets fake sets kind notes meeting having has in copy realistic is you. Copy or fairly set story.
Wrong and days not work of want piece options unrelated way random just just recipes. Your recipes gardening start fairly. Happily start game days want from in set meeting that forever random. Support has wrong than your language are random business a even design has. Way design dummy unrelated set generator game convincing. Text contentwise copy to of set kind notes a you ?looks? gone work. Way forever result you to not. Your your meeting generator way placeholder looking than has want in repetitive more kind start has you but language a. A than notes name story and a just days some with in options looking just not are want looks. Kind some from review even.
Some start random meeting recipes is a a ?looks? unrelated more the about but are dummy. Words review fake now kind of you meeting it design your. To just a about to. Not realistic name from with fake is. Work even business options fake wrong result notes want the more has dummy a notes random. Gone right repetitive fairly want now it want days review. Has notes want random name that random fantasy not unrelated in is dummy work work random game design now. Business result a and piece from working. Your some recipes copy sets are has kind story support fantasy has and some fantasy a which anything are the.
Language piece that kind copy right anything dummy a of copy which fantasy placeholder which the work are convincing random. Your gone way copy you copy are that game but looking gardening result is start text the words the a anything. Want piece set set fantasy generator sets a more are happily or ?looks? just the and sets not anything. Support to just start game work looks copy that in of but words placeholder support now fairly fake even now. Text adequate words not fairly looks from game that result name realistic or you fake working want. Kind you some looking of review has sets than want the way working has. Of fantasy gardening and kind just game those adequate your from or text are you story working happily. Business set way gardening more dummy want are you business ?looks? work to placeholder are design options sets having. Working from options work right not meeting story it is of which way fake meeting. Adequate story than words want the anything.
Language some gone random or just fairly gone which adequate sets having and adequate or text random from review. From unrelated those a start the ?looks? game business. With copy and which set kind game contentwise which anything the set story notes about or forever. Way anything work ?looks? a contentwise adequate and meeting. Options which realistic words it of to right game random way random your those and those anything some you notes gone gardening dummy than fake. But language just a your work with that set the. Are dummy business story not gardening start wrong fantasy fake and words having text which recipes your ?looks? wrong or. Generator fake than set looking text now forever more design ?looks? text but than has than wrong.
Way than fake gardening those a now it language but piece. A is even looks just result that which realistic gone are working right fake some. Which language wrong having with that looks.
&lt;/code>&lt;/pre>&lt;p>执行结果如下所示&lt;/p>
&lt;pre>&lt;code>right : 9
Fantasy : 1
review : 5
convincing : 2
is : 8
Business : 2
even : 1
Are : 1
even : 10
start : 10
// 此处省略数行
&lt;/code>&lt;/pre>
&lt;h2 id="二统计用户的视频上传数">二、统计用户的视频上传数&lt;/h2>
&lt;h3 id="场景分析">场景分析&lt;/h3>
&lt;p>接下来使用 Spark 来统计 Youtube 的测试数据集中每个用户的视频上传数量。稍加分析，会发现统计每个用户的视频数量其实与 WordCount 中统计每个单词出现的次数的逻辑几乎一致，区别在于处理 Youtube 测试数据集的格式略为复杂些。将给定的数据集按行划分，每行代表一条记录，除了视频类别这一字段中间有可能出现空格之外，其他的字段都是用空格分割。可以考虑使用正则表达式来匹配记录，并提取所需要的信息。&lt;/p>
&lt;p>在测试数据集中，假定每行所代表的视频都是唯一的，所以仅仅需要用户 ID 这一条信息。在提取到用户 ID 之后，可以像 WordCount 一样，组成 &amp;lt;ID, 1&amp;gt; 这样的用来计数的键值对，这步之后的逻辑便与 WordCount 相似了。&lt;/p>
&lt;h3 id="java-实现-1">Java 实现&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln"> 1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.spark.SparkConf&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.spark.api.java.JavaPairRDD&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.spark.api.java.JavaRDD&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.spark.api.java.JavaSparkContext&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">scala.Tuple2&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 6&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.ArrayList&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.List&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.regex.Matcher&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.regex.Pattern&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln">11&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">SparkDemo&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Pattern&lt;/span> &lt;span class="n">EXTRACT&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Pattern&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">compile&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;(\\S+)\\s+(\\S+)\\s+(\\d+)\\s+(\\D+[a-zA-Z])\\s+(\\d+)\\s+(\\d+)\\s+(\\d+\\.?\\d*)\\s+(\\d+)\\s+(\\d+)\\s+(.*)&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">14&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="n">SparkConf&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">SparkConf&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setAppName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;CountUploader&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">17&lt;/span> &lt;span class="n">JavaSparkContext&lt;/span> &lt;span class="n">sc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">JavaSparkContext&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">18&lt;/span>
&lt;span class="ln">19&lt;/span> &lt;span class="n">JavaRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">textFile&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">]);&lt;/span>
&lt;span class="ln">20&lt;/span> &lt;span class="n">JavaRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">filtered&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">lines&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">filter&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">EXTRACT&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">matcher&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">matches&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="ln">21&lt;/span> &lt;span class="n">JavaPairRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">records&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">filtered&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">mapToPair&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">22&lt;/span> &lt;span class="n">Matcher&lt;/span> &lt;span class="n">m&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">EXTRACT&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">matcher&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">23&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">m&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">matches&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">24&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Tuple2&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">m&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">group&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">m&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">group&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="ln">25&lt;/span> &lt;span class="o">});&lt;/span>
&lt;span class="ln">26&lt;/span> &lt;span class="n">JavaPairRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">groups&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">records&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">groupByKey&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">mapToPair&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">t&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">27&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">ArrayList&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;();&lt;/span>
&lt;span class="ln">28&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">_2&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">forEach&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">29&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Tuple2&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">t&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">_1&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">list&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">30&lt;/span> &lt;span class="o">});&lt;/span>
&lt;span class="ln">31&lt;/span> &lt;span class="c1">// 手动实现 sortBy 操作
&lt;/span>&lt;span class="ln">32&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">JavaRDD&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Tuple2&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">tops&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">groups&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">keyBy&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">t&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">_2&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">size&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">sortByKey&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">values&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">33&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Tuple2&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">topList&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tops&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">take&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">100&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">34&lt;/span>
&lt;span class="ln">35&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Tuple2&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">t&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">topList&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">36&lt;/span> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;User: &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">_1&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;, Number of videos: &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">_2&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">size&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="ln">37&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">38&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">stop&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">39&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">40&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="执行-1">执行&lt;/h3>
&lt;p>将上述代码生成 Jar 包之后，将其放到服务器中，执行下面的命令即可开始运行。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>./bin/spark-submit --class SparkDemo ~/Documents/SparkDemo.jar ~/Documents/YoutubeDataSets.txt
&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行结果如下所示&lt;/p>
&lt;pre>&lt;code>User: machinima, Number of videos: 21
User: hotforwords, Number of videos: 19
User: theevang1, Number of videos: 19
User: kushtv, Number of videos: 19
User: supermac18, Number of videos: 18
User: NBA, Number of videos: 18
User: somedia, Number of videos: 17
User: tokiohotelchannel, Number of videos: 17
User: AtheneWins, Number of videos: 16
User: davidisbetterthenyou, Number of videos: 16
// 此处省略数行
&lt;/code>&lt;/pre>
&lt;h1 id="参考文章">参考文章&lt;/h1>
&lt;ol>
&lt;li>&lt;a class="link" href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations" target="_blank" rel="noopener"
>RDD Operations&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.cnblogs.com/MOBIN/p/5373256.html" target="_blank" rel="noopener"
>Spark 函数详解系列之 RDD 基本转换&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://juejin.im/post/6844904147502759943" target="_blank" rel="noopener"
>Spark 教程之 RDD 操作-转换和执行（示例）&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://yxnchen.github.io/technique/Spark%E7%AC%94%E8%AE%B0-%E7%8E%A9%E8%BD%ACRDD%E6%93%8D%E4%BD%9C/" target="_blank" rel="noopener"
>Spark 笔记-玩转 RDD 操作&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://stackoverflow.com/questions/37018249/rdd-aggregate-in-spark" target="_blank" rel="noopener"
>RDD Aggregate in spark&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="http://dblab.xmu.edu.cn/blog/1327/" target="_blank" rel="noopener"
>利用开发工具 IntelliJ IDEA 编写 Spark 应用程序（Scala+Maven）&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>MapReduce 分布式编程</title><link>https://sudrizzz.github.io/posts/mapreduce-distributed-programming/</link><pubDate>Sat, 17 Oct 2020 20:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/mapreduce-distributed-programming/</guid><description>&lt;h1 id="词频统计程序示例">词频统计程序示例&lt;/h1>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201014180000.png" alt="20201014180000" />&lt;/p>
&lt;p>假设将一个英文文本大文件作为输入，统计文件中单词出现的频数。最基本的操作是把输入文件的每一行传递给 map 函数完成对单词的拆分并输出中间结果，中间结果为 &amp;lt;word, 1&amp;gt; 的形式， 表示程序对一个单词，都对应一个计数 1。使用 reduce 函数收集 map 函数的结果作为输入值，并生成最终 &amp;lt;word, count&amp;gt; 形式的结果，完成对每个单词的词频统计。它们对应 MapReduce 处理数据流程如上图所示。&lt;/p>
&lt;h1 id="mapreduce-程序的运行过程">MapReduce 程序的运行过程&lt;/h1>
&lt;p>如图所示，MapReduce 运行阶段数据传递经过输入文件、Map 阶段、中间文件、 Reduce 阶段、输出文件五个阶段，用户程序只与 Map 阶段和 Reduce 阶段的 Worker 直接相关，其他事情由 Hadoop 平台根据设置自行完成。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201014190000.png" alt="20201014190000" />&lt;/p>
&lt;p>从用户程序 User Program 开始，用户程序 User Program 链接了 MapReduce 库，实现了最基本的 map 函数和 reduce 函数。&lt;/p>
&lt;ol>
&lt;li>MapReduce 库先把 User Program 的输入文件划分为 M 份，如上图左方所示，将数据分成了分片 0~4，每一份通常为 16MB~64MB；然后使用 fork 将用户进程复制到集群内其他机器上。&lt;/li>
&lt;li>User Program 的副本中有一个 Master 副本和多个 Worker 副本。Master 是负责调度的，为空闲 Worker 分配 Map 作业或者 Reduce 作业。&lt;/li>
&lt;li>被分配了 Map 作业的 Worker，开始读取对应分片的输入数据, Map 作业数量与输入文件划分数 M 相同，并与分片一一对应; Map 作业将输入数据转化为键值对表示形式并传递给 map 函数，map 函数产生的中间键值对被缓存在内存中。&lt;/li>
&lt;li>缓存的中间键值对会被定期写入本地磁盘，而且被分为 R 个区（R 的大小是由用户定义的），每个区会对应一个 Reduce 作业；这些中间键值对的位置会被通报给 Master, Master 负责将信息转发给 Reduce Worker。&lt;/li>
&lt;li>Master 通知分配了 Reduce 作业的 Worker 负责数据分区，Reduce Worker 读取键值对数据并依据键排序，使相同键的键值对聚集在一起。同一个分区可能存在多个键的键值对，而 reduce 函数的一次调用的键值是唯一的， 所以必须进行排序处理。&lt;/li>
&lt;li>Reduce Worker 遍历排序后的中间键值对，对于每个唯一的键，都将键与关联的值传递给 reduce 函数，reduce 函数产生的输出会写回到数据分区的输出文件中。&lt;/li>
&lt;li>当所有的 Map 和 Reduce 作业都完成了，Master 唤醒 User Program，MapReduce 函数调用返回 User Program。&lt;/li>
&lt;/ol>
&lt;p>执行完毕后，MapReduce 的输出放在 R 个分区的输出文件中，即每个 Reduce 作业分别对应一个输出文件。用户可将这 R 个文件作为输入交给另一个 MapReduce 程序处理，而不需要主动合并这 R 个文件。在 MapReduce 计算过程中，输入数据来自分布式文件系统，中间数据放在本地文件系统，最终输出数据写入分布式文件系统。&lt;/p>
&lt;p>必须指出 Map 或 Reduce 作业和 map 或 reduce 函数存在以下几个区别:&lt;/p>
&lt;ol>
&lt;li>Map 或 Reduce 作业是从计算框架的角度来认识的，而 map 或 reduce 函数是需要程序员编写代码完成的，并在运行过程中被对用 Map 或 Reduce 作业调度;&lt;/li>
&lt;li>Map 作业处理一个输入数据的分片，可能需要多次调用 map 函数来处理输入的键值对;&lt;/li>
&lt;li>Reduce 作业处理一个分区的中间键值对，期间要对每个不同的键调用一次 reduce 函数，一个 Reduce 作业最终对应一个输出文件。&lt;/li>
&lt;/ol>
&lt;h1 id="经典-mapreduce-任务调度模型">经典 MapReduce 任务调度模型&lt;/h1>
&lt;p>经典 MapReduce 任务调度模型采用主从结构（Master/Slave），包含四个组成部分：Client、JobTracker、TaskTracker、Task。支撑 MapReduce 计算框架的是 JobTracker 和 TaskTracker 两类后台进程。框架结构如下图所示。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201014200000.png" alt="20201014200000" />&lt;/p>
&lt;ol>
&lt;li>Client
每一个 Job 在 Ciat 端将运行 MapRecdce 程序所需要的所有 Jar 文件和类的集合，打包成一个 Jar 文件存储在 HDFS 中，并把文件路径提交到 JobTracker。&lt;/li>
&lt;li>JobTracker
JobTracker 主要负责资源的监控和作业调度，一个 Hadoop 集群只有一个 JobTracker，并不参与具体的计算任务。根据提交的 Job，JobTackor 会创建一系列 Task（即 MapTask、ReduceTask），分发到每个 TaskTracker 服务中去执行。常用的作业调度算法主要包括 FIFO(First In First Out) 调度器（默认）、公平调度器、容量调度器等。&lt;/li>
&lt;li>TaskTracker
TaskTracker 主要负责汇报心跳和执行 JobTracker 分发的任务。TaskTracker 会周期性地通过 HeartBeat 将本节点上资源的使用情况和任务的运行进度汇报给 JobTracker，JobTracker 会根据心跳信息和当前作业运行情况为 TaskTracker 下达任务，主要包括启动任务、提交任务、杀死任务和重新初始化命令等。&lt;/li>
&lt;li>Task
Task 分为 MapTask 和 ReduceTask 两种，均由 TaskTracker 启动，执行 JobTracker 分发的任务。MapTask 解析每条数据记录，传递给用户编写的 map 函数并执行，最后将输出结果写入 HDFS；ReduceTask 从 MapTask 的执行结果中，对数据进行排序，将数据按分组传递给用户编写的 reduce 函数执行。&lt;/li>
&lt;/ol>
&lt;p>TaskTracker 分布在 Map-Reduce 集群每个节点上，主要是监视所在机器的资源情况和当前机器的 tasks 运行状况。TaskTracker 通过 HeartBeat 发送给 JobTracker，JobTracker 会根据这些信息给新提交的 job 分配计算节点。经典 MapReduce 框架 MR V1 模型简单直观，但是不能满足大规模集群任务调度的需要。主要表现为以下四点:&lt;/p>
&lt;ol>
&lt;li>JobTracker 是 MapReduce 的集中处理点，存在单点故障问题；&lt;/li>
&lt;li>当 MapRcduce job 非常多的时候，会造成很大的内存开销，就增加了 JobTracker 失败的风险，业界普遍认为该调度模型支持的上限为 4000 个节点;&lt;/li>
&lt;li>在 TaskTracker 端，以 Map/Reduce Task 的数目作为资源的表示过于简单，没有考虑到 CPU/内存的占用情况，如果两个大内存消耗的 Task 被调度到一起， 就很容易出现内存消耗殆尽的问题;&lt;/li>
&lt;li>TaskTracker 把资源强制划分为 Map Task Slot 和 Reduce Task Slot，如果当系统中只有 Map Task 或者只有 Reduce Task 时，会造成资源的浪费，导致集群资源利用不足。&lt;/li>
&lt;/ol>
&lt;h1 id="yarn-框架原理及运行机制">YARN 框架原理及运行机制&lt;/h1>
&lt;p>为了从根本上解决经典 MapReduce 框架的性能瓶颈，Hadoop 的 MapReduce 框架完全重构，叫做 YARN 或者 MR V2。&lt;/p>
&lt;p>YARN 的基本思想就是将经典调度框架中 JobTracker 的资源管理和任务调度/监控功能分离成两个单独的组件，即一个全局的资源管理器 ResoureManager 和每个应用程序特有的 ApplicationMaster。ResoureManager 负责整个系统资源的管理和分配，而 ApplicationMaster 则负责单个应用程序的资源管理。&lt;/p>
&lt;p>YARN 调度框架包括 ResourceManager、ApplicationMaster、NodeMananger 及 Container 等组件概念。&lt;/p>
&lt;p>ResourceManager 是基于应用程序对资源的需求进行调度的。每一个应用程序需要不同类型的资源，因此就需要不同的容器。这些资源包括内存、CPU、磁盘、网络等。
ApplicationMaster 负责向调度器申请、释放资源，清求 NodeManager 运行任务、跟踪应用程序的状态和监控它们的进程。&lt;/p>
&lt;p>NodeManager 是 YARN 中单个节点的代理，负责与应用程序的 ApplicationMaster 和集群管理者 ResourceManager 交互；从 ApplicationMaster 上接收有关 Container 的命令并执行（例如，启动、停止 Container）；向 ResourceManager 汇报各个 Container 执行状态和节点健康状况，并读取有关 Container 的命令；执行应用程序的容器、监控应用程序的资源使用情况并且向 ResourceManager 调度器汇报。&lt;/p>
&lt;p>Container 是 YARN 中资源的抽象，它封装了节点上一定量的资源（CPU 和内存等）。一个应用程序所需的 Container 分为两类：一类是运行 ApplicationMaster 的 Container，是由 ResourceManager（向内部的资源调度器）申请和启动的，用户提交应用程序时，可指定唯一的 ApplicationMaster 所需的资源；另一类是运行各类任务的 Container，是由 ApplicationMaster 向 ResourceManager 申请的，并由 ApplicationMaster 与 NodeManager 通信后启动。&lt;/p>
&lt;p>用户向 YARN 提交一个应用程序后，YARN 将分为两个阶段运行该应用程序：第一个阶段是启动 ApplicationMaster；第二个阶段是由 ApplicationMaster 创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行成功。&lt;/p>
&lt;p>YARN 任务调度流程如下图所示。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201014205100.jpg" alt="20201014205100" />&lt;/p>
&lt;ol>
&lt;li>用户向 YARN 提交应用程序；&lt;/li>
&lt;li>ResourceManager 为该应用程序在某个 NodeManagr 分配一个 Container，并要求 NodeManager 启动应用程序的 ApplicationMaster；&lt;/li>
&lt;li>ApplicationMaster 启动后立即向 ResourceManager 注册，此时用户可以直接通过 ResourceManager 查看应用程序的运行状态，然后它将为各个任务申请分布在某些 NodeManager 上的容器资源，并监控它的运行状态（步骤 4~7），直到运行结束；&lt;/li>
&lt;li>ApplicationMaster 采用轮询的方式向 ResourceManager 申请和领取资源；&lt;/li>
&lt;li>ApplicationMaster 申请到资源后，即与资源容器所在的 NodeManager 通信，要求其在容器内启动任务;&lt;/li>
&lt;li>NodeManager 为任务初始化运行环境（包括环境变量、jar 包、二进制程序等)，启动任务；&lt;/li>
&lt;li>运行各个任务的容器通过向 ApplicationMaster 汇报自己的状态和进度，使 ApplicationMaster 随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。用户可以向 ApplicationMaster 查询应用程序的当前运行状态；&lt;/li>
&lt;li>应用程序运行完成后，ApplicationMaster 向 ResourceManager 注销并关闭。&lt;/li>
&lt;/ol>
&lt;p>YARN 框架和经典的 MRV1 调度框架相比，主要有以下优化：&lt;/p>
&lt;ol>
&lt;li>ApplicationMaster 使得检测每一个 Job 子任务状态的程序分布式化，减少了 JobTracker 资源消耗；&lt;/li>
&lt;li>在 YARN 中，用户可以对不同的编程模型写自己的 ApplicationMaster, 可以让更多类型的编程模型运行在 Hadoop 集群上，如 Spark 基于内存的计算模型；&lt;/li>
&lt;li>Container 提供 Java 虚拟机内存的隔离，优化了经典调度框架中 Map Slot 和 Reduce Slot 分开造成集群资源闲置的不足。&lt;/li>
&lt;/ol>
&lt;h1 id="youtube-数据集统计分析">Youtube 数据集统计分析&lt;/h1>
&lt;p>本例的数据来自于 Youtube 的数据集，完整的数据集以及源代码下载地址请点击以下链接
&lt;a href="https://github.com/sudrizzz/BigDataTechnologyFoundation-SourceCodeAndDataSet/blob/main/ch04">https://github.com/sudrizzz/BigDataTechnologyFoundation-SourceCodeAndDataSet/blob/main/ch04&lt;/a>&lt;/p>
&lt;p>该数据集各字段的具体含义如表所示：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>字段名&lt;/th>
&lt;th>解释及数据类型&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>video ID&lt;/td>
&lt;td>视频 ID：每个视频存在唯一的 11 位字符串&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>uploader&lt;/td>
&lt;td>上传者用户名：字符串类型&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>age&lt;/td>
&lt;td>视频上传日期与 2007 年 2 月 15 日（YouTube 创立日）的间隔天数：整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>category&lt;/td>
&lt;td>视频类别：字符串类型&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>length&lt;/td>
&lt;td>视频长度：整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>views&lt;/td>
&lt;td>浏览量：整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>rate&lt;/td>
&lt;td>视频评分：浮点值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ratings&lt;/td>
&lt;td>评分次数：整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>comments&lt;/td>
&lt;td>评论数：整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>related IDs&lt;/td>
&lt;td>相关视频 ID，每个相关视频的 ID 均为单独的一列：字符串类型&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="视频类型统计">视频类型统计&lt;/h2>
&lt;p>场景：从已经上传的视频中，统计每一个视频类型下的视频数量。下表所示为数据集数据格式示例。category 列代表了视频类型，因而 map 函数只需逐行读取，返回视频类型为键和数字 1 为值的键值对，再传给 reduce 函数处理即可。map 函数的输入键依然为文本文件中行的偏移量，值为行内容。reduce 函数输出键值对为视频类型和该视频类型中的视频数量。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>video ID&lt;/th>
&lt;th>uploader&lt;/th>
&lt;th>age&lt;/th>
&lt;th>category&lt;/th>
&lt;th>length&lt;/th>
&lt;th>views&lt;/th>
&lt;th>rate&lt;/th>
&lt;th>ratings&lt;/th>
&lt;th>comments&lt;/th>
&lt;th>Related IDs&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>PRGUU_ggO3k&lt;/td>
&lt;td>tom&lt;/td>
&lt;td>704&lt;/td>
&lt;td>Entertainment&lt;/td>
&lt;td>262&lt;/td>
&lt;td>11235&lt;/td>
&lt;td>3.86&lt;/td>
&lt;td>247&lt;/td>
&lt;td>280&lt;/td>
&lt;td>tpAL3iOurl4&amp;hellip;ifn1njiY4s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>RX24KLBhwMI&lt;/td>
&lt;td>jsack&lt;/td>
&lt;td>687&lt;/td>
&lt;td>Blogs&lt;/td>
&lt;td>512&lt;/td>
&lt;td>24149&lt;/td>
&lt;td>4.22&lt;/td>
&lt;td>315&lt;/td>
&lt;td>474&lt;/td>
&lt;td>PkGUU_ggO3k&amp;hellip;tpAl3iOurl4&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="mapper-类代码实现">Mapper 类代码实现&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln"> 1&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Map&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">Mapper&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">LongWritable&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">IntWritable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 2&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">IntWritable&lt;/span> &lt;span class="n">ONE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">IntWritable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Text&lt;/span> &lt;span class="n">tx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Text&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln"> 4&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">LongWritable&lt;/span> &lt;span class="n">key&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Text&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Context&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InterruptedException&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">line&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">line&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">split&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;\t&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">str&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">3&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">tx&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">str&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="n">3&lt;/span>&lt;span class="o">]);&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">tx&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ONE&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">13&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>第 2 行构造 IntWritable 可持久化对象并赋值为 1；第 8~10 行过滤字段，将一条记录中的分类 category 作为 map 函数的 value 输出。&lt;/p>
&lt;h3 id="reduce-类代码实现">Reduce 类代码实现&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln">1&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Reduce&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">Reducer&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">IntWritable&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">IntWritable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">2&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">reduce&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Text&lt;/span> &lt;span class="n">key&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">IntWritable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Context&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InterruptedException&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">3&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">IntWritable&lt;/span> &lt;span class="n">v&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">5&lt;/span> &lt;span class="n">sum&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">6&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">7&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">key&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">IntWritable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">sum&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="ln">8&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">9&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>reduce 函数接收 Map 阶段传来的键值对，第 3~6 行遍历每一组记录，累加同一视频类型下的视频数量，第 7 行通过 context 输出计算结果。&lt;/p>
&lt;h3 id="运行">运行&lt;/h3>
&lt;ol>
&lt;li>通过 IDEA-Build-Build Artifacts 功能将代码打包为 jar 文件，命名为 CategoryCount.jar&lt;/li>
&lt;li>登录 Hadoop 集群，将数据集文件 YoutubeDataSets.txt 传到 HDFS 下 /tmp 目录下&lt;/li>
&lt;li>执行如下命令，开始运行程序&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>hadoop jar CategoryCount.jar CategoryCount /tmp/YoutubeDataSets.txt /tmp/output
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="4">
&lt;li>执行如下命令，查看各类别视频数量&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>hadoop fs -cat /tmp/output/part-r-00000
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以得到如下输出&lt;/p>
&lt;pre>&lt;code>UNA 32
Autos &amp;amp; Vehicles 77
Comedy 420
Education 65
Entertainment 911
Film &amp;amp; Animation 261
Howto &amp;amp; Style 138
Music 870
News &amp;amp; Politics 343
Nonprofits &amp;amp; Activism 43
People &amp;amp; Blogs 399
Pets &amp;amp; Animals 95
Science &amp;amp; Technology 80
Sports 253
Travel &amp;amp; Events 113
&lt;/code>&lt;/pre></description></item><item><title>HDFS 文件管理</title><link>https://sudrizzz.github.io/posts/hdfs-file-system/</link><pubDate>Mon, 12 Oct 2020 15:20:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/hdfs-file-system/</guid><description>&lt;blockquote>
&lt;p>本文所有代码均可在 &lt;a href="https://github.com/sudrizzz/HDFSOperations">https://github.com/sudrizzz/HDFSOperations&lt;/a> 查看。&lt;/p>
&lt;/blockquote>
&lt;h1 id="通过命令行访问-hdfs">通过命令行访问 HDFS&lt;/h1>
&lt;p>命令行是最简单、最直接操作文件的方式。这里介绍通过诸如读取文件、新建目录、移动文件、删除数据、列出目录等命令来进一步认识 HDFS。也可以输入 hadoop fs -help 命令获取每个命令的详细帮助。若熟悉 Linux 命令，Hadoop 命令看起来非常直观且易于使用。&lt;/p>
&lt;h2 id="对文件和目录的操作">对文件和目录的操作&lt;/h2>
&lt;p>通过命令行对 HDFS 文件和目录的操作主要包括：创建、浏览、删除文件和目录，以及从本地文件系统与 HDFS 文件系统互相拷贝等。常用命令格式如下。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln"> 1&lt;/span>hadoop fs -ls &amp;lt;path&amp;gt; &lt;span class="c1"># 列出 path 目录下的所有内容（文件和目录）&lt;/span>
&lt;span class="ln"> 2&lt;/span>hadoop fs -lsr &amp;lt;path&amp;gt; &lt;span class="c1"># 递归列出 path 下的所有内容（文件或目录）&lt;/span>
&lt;span class="ln"> 3&lt;/span>hadoop fs -df &amp;lt;path&amp;gt; &lt;span class="c1"># 查看目录的使用情况&lt;/span>
&lt;span class="ln"> 4&lt;/span>hadoop fs -du &amp;lt;path&amp;gt; &lt;span class="c1"># 显示目录中所有文件及目录大小&lt;/span>
&lt;span class="ln"> 5&lt;/span>hadoop fs -touchz &amp;lt;path&amp;gt; &lt;span class="c1"># 创建一个路径为为 path 的 0 字节的 HDFS 空文件&lt;/span>
&lt;span class="ln"> 6&lt;/span>hadoop fs -mkdir &amp;lt;path&amp;gt; &lt;span class="c1"># 查看目录的使用情况&lt;/span>
&lt;span class="ln"> 7&lt;/span>hadoop fs -rm &lt;span class="o">[&lt;/span>-skipTrash&lt;span class="o">]&lt;/span> &amp;lt;path&amp;gt; &lt;span class="c1"># 将 HDFS 上路径为 &amp;lt;path&amp;gt; 的文件移动到回收站，加上 -skipTrash，则直接删除&lt;/span>
&lt;span class="ln"> 8&lt;/span>hadoop fs -rmr &lt;span class="o">[&lt;/span>-skipTrash&lt;span class="o">]&lt;/span> &amp;lt;path&amp;gt; &lt;span class="c1"># 将 HDFS 上路径为 &amp;lt;path&amp;gt; 的目录以及目录下的文件移动到回收站。如果加上 -skipTrash，则直接删除&lt;/span>
&lt;span class="ln"> 9&lt;/span>hadoop fs -moveFromLocal &amp;lt;localsrc&amp;gt;...&amp;lt;dst&amp;gt; &lt;span class="c1"># 将 &amp;lt;localsrc&amp;gt; 本地文件移动到 HDFS 的 &amp;lt;dst&amp;gt; 目录下路径下&lt;/span>
&lt;span class="ln">10&lt;/span>hadoop fs -moveToLocal &lt;span class="o">[&lt;/span>-crc&lt;span class="o">]&lt;/span> &amp;lt;src&amp;gt; &amp;lt;localdst&amp;gt; &lt;span class="c1"># 将 HDFS 上路径为 &amp;lt;src&amp;gt; 的文件移动到本地 &amp;lt;localdst&amp;gt; 路径下&lt;/span>
&lt;span class="ln">11&lt;/span>hadoop fs -put &amp;lt;localsrc&amp;gt;...&amp;lt;dst&amp;gt; &lt;span class="c1"># 从本地文件系统中复制单个或者多个源路径到目标文件系统&lt;/span>
&lt;span class="ln">12&lt;/span>hadoop fs -cat &amp;lt;src&amp;gt; &lt;span class="c1"># 浏览 HDFS 路径为 &amp;lt;src&amp;gt; 的文件的内容&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="修改权限或用户组">修改权限或用户组&lt;/h2>
&lt;p>HDFS 提供了一些命令可以用来修改文件的权限、所属用户以及所属组别，具体格式如下:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;code>hadoop fs -chmod [-R] &amp;lt;MODE [,MODE]...|OCTALMODE&amp;gt; PATH...&lt;/code>&lt;br>
改变 HDFS 上路径为 PATH 的文件的权限，R 选项表示递归执行该操作。&lt;br>
例如: &lt;code>hadoop fs -chmod -R +r /user/test&lt;/code>，表示将 /user/test 目录下的所有文件赋予读的权限&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>hadoop fs -chown [-R][OWNER][:[GROUP]]PATH...&lt;/code>&lt;br>
改变 HDFS 上路径为 PATH 的文件的所属用户，-R 选项表示递归执行该操作。&lt;br>
例如: &lt;code>hadoop fs -chown -R hadoop:hadoop /user/test&lt;/code>，表示将 /user/test 目录下所有文件的所属用户和所属组别改为 hadoop&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>hadoop fs -chgrp ［-R] GROUP PATH...&lt;/code>&lt;br>
改变 HDFS 上路径为 PATH 的文件的所属组别，-R 选项表示递归执行该操作。&lt;br>
例如: &lt;code>hadoop fs -chown -R hadoop /user/test&lt;/code> 表示将 /user/test 目录下所有文件的所属组别改为 hadoop&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="其他命令">其他命令&lt;/h2>
&lt;p>HDFS 除了提供上述两类操作之外，还提供许多实用性较强的操作，如显示指定路径上的内容，上传本地文件到 HDFS 指定文件夹，以及从 HDFS 上下载文件到本地等命令。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;code>hadoop fs -tail [-f] &amp;lt;file&amp;gt;&lt;/code>&lt;br>
显示 HDFS 上路径为 &amp;lt;file&amp;gt; 的文件的最后 1KB 的字节，-f 选项会使显示的内容随着文件内容更新而更新。&lt;br>
例如: &lt;code>hadoop fs -tail -f /user/test.txt&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>hadoop fs -stat [format] &amp;lt;path&amp;gt;&lt;/code>&lt;br>
显示 HDFS 上路径为 &amp;lt;path&amp;gt; 的文件或目录的统计信息。格式为：%b 文件大小，%n 文件名，%r 复制因子，%y、%Y 修改日期。&lt;br>
例如：&lt;code>hadoop fs -stat %b %n %o %r /user/test&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>hadoop fs -put &amp;lt;localsrc&amp;gt;...&amp;lt;dt&amp;gt;&lt;/code>&lt;br>
将 &amp;lt;localsrc&amp;gt; 本地文件上传到 HDFS 的 &amp;lt;dst&amp;gt; 目录下。&lt;br>
例如: &lt;code>hadoop fs -put /home/hadoop/test.txt /user/hadoop&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>hadoop fs -count [-q] &amp;lt;path&amp;gt;&lt;/code>&lt;br>
显示 &amp;lt;path&amp;gt; 下的目录数及文件数，输出格式为”目录数 文件数 大小 文件名“，加上 -q 可以查看文件索引的情况。&lt;br>
例如: &lt;code>hadoop fs -count /&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>hadoop fs -get [-ignoreCrc] [-crc] &amp;lt;src&amp;gt; &amp;lt;localdst&amp;gt;&lt;/code>&lt;br>
将 HDFS 上 &amp;lt;src&amp;gt; 的文件下载到本地的 &amp;lt;localdst&amp;gt; 目录，可用 -ignorecrc 选项复制 CRC 校验失败的文件，使用 -crc 选项复制文件以及 CRC 信息。&lt;br>
例如: &lt;code>hadoop fs -get /user/hadoop/a.txt /home/hadoop&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>hadoop fs -getmerge &amp;lt;src&amp;gt; &amp;lt;localdst&amp;gt; [addnl]&lt;/code>&lt;br>
将 HDFS 上 &amp;lt;src&amp;gt; 目录下的所有文件按文件名排序并合并成一个文件输出到本地的 &amp;lt;localdst&amp;gt; 目录，addnl 是可选的，用于指定在每个文件结尾添加一个换行符。&lt;br>
例如: &lt;code>hadoop fs -getmerge /user/test /home/hadoop/o&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>hadoop fs -test -[ezd] &amp;lt;path&amp;gt;&lt;/code>&lt;br>
检查 HDFS 上路径为 &amp;lt;path&amp;gt; 的文件。-e 检查文件是否存在，如果存在则返回 0。-z 检查文件是否为 0 字节，如果是则返回 0。-d 检查路径是否是目录，如果是则返回 1，否则返回 0。&lt;br>
例如：&lt;code>hadoop fs -test -e /user/test.txt&lt;/code>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h1 id="通过-java-api-访问-hdfs">通过 Java API 访问 HDFS&lt;/h1>
&lt;h2 id="使用-hadoop-url-读取数据">使用 Hadoop URL 读取数据&lt;/h2>
&lt;p>要从 Hadoop 文件系统读取数据，最简单的方法是使用 java.net.URL 对象打开数据流，从中读取数据。&lt;/p>
&lt;p>让 Java 程序能够识别 Hadoop 的 HDFS URL 方案还需要一些额外的工作，这里采用的方法是通过 org.apache.hdfs.FsUrlStreamHandlerFactor 实例调用 java.net.URL 对象的 setURLStreamHandlerFactory 实例方法。每个 Java 虚拟机只能调用一次这个方法，因此通常在静态方法中调用。下述范例展示的程序以标准输出方式显示 Hadoop 文件系统中的文件，类似于 UNIX 中的 cat 命令。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln"> 1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.fs.FsUrlStreamHandlerFactory&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.io.IOUtils&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 3&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.io.InputStream&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.net.URL&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 6&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">URLCat&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="n">URL&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setURLStreamHandlerFactory&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">FsUrlStreamHandlerFactory&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">11&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span>&lt;span class="o">{&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="n">InputStream&lt;/span> &lt;span class="n">inputStream&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="n">inputStream&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">URL&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">]).&lt;/span>&lt;span class="na">openStream&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="n">IOUtils&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">copyBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">inputStream&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">4096&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">17&lt;/span> &lt;span class="o">}&lt;/span> &lt;span class="k">finally&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">18&lt;/span> &lt;span class="n">IOUtils&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">closeStream&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">inputStream&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">19&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">20&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">21&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>编译代码，导出为 URLCat.jar 文件，并在 /user/hadoop/ 中准备一个测试文件 test，然后执行命令：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>hadoop jar hdfsclient.jar URLCat hdfs://master:9000/user/hadoop/test
&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行完成后可以在屏幕上看到 /user/hadoop/test 文件中的内容。该程序是从 HDFS 读取文件的最简单的方式，即用 java.net.URL 对象打开数据流。其中，第 8~10 行静态代码块的作用是设置 URL 类能够识别 Hadoop 的 HDFS URL。第 16 行 IOUtils 是 Hadoop 中定义的类，调用其静态方法 copyBytes 实现从 HDFS 文件系统拷贝文件到标准输出流。4096 表示用来拷贝的缓冲区大小，false 表示拷贝完成后不关闭拷贝源。&lt;/p>
&lt;h2 id="通过-filesystem-api-读取数据">通过 FileSystem API 读取数据&lt;/h2>
&lt;p>在实际开发中，访问 HDFS 最常用的类是 FileSystem 类。Hadoop 文件系统中通过 Hadoop Path 对象来定位文件。可以将路径视为一个 Hadoop 文件系统 URI，如 hdfs:localhost/user/hadoop/test。FileSystem 是一个通用的文件系统 API，获取 FileSystem 实例有下面几个静态方法:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln">1&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="nf">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>
&lt;span class="ln">2&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="nf">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">URI&lt;/span> &lt;span class="n">uri&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>
&lt;span class="ln">3&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="nf">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">URI&lt;/span> &lt;span class="n">uri&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">user&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="k">throw&lt;/span> &lt;span class="n">IOException&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>下面分别给出几个常用操作的代码示例。&lt;/p>
&lt;h3 id="读取文件">读取文件&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln"> 1&lt;/span>&lt;span class="nd">@Test&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">readFile&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">uri&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hdfs://master:9000/user/hadoop/test&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">configuration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">fileSystem&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">URI&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">uri&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">configuration&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="n">InputStream&lt;/span> &lt;span class="n">in&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="n">in&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">open&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">uri&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="n">IOUtils&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">copyBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">in&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">4096&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="o">}&lt;/span> &lt;span class="k">finally&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="n">IOUtils&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">closeStream&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">in&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">13&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>上述代码直接使用 FileSystem 以标准输出格式显示 Hadoop 文件系统中的文件。&lt;/p>
&lt;p>第 4 行产生一个 Confguation 类的实例，代表了 Hadoop 平台的配置信息，并在第 5 行作为引用传递到 FileSystem 的静态方法 get 中，产生 FileSystem 对象。&lt;/p>
&lt;p>第 9 行与上例类似，调用 Hadoop 中 IOUtils，并在 finally 字中关闭数据流，同时也可以在输入流和输出流之间复制数据。copyBytes 方的最后两个参数，第一个设置用于复制的缓冲区大小，第二个设置复制结束后是否关闭数据流。&lt;/p>
&lt;h3 id="写入文件">写入文件&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln"> 1&lt;/span>&lt;span class="nd">@Test&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">writeFile&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;C:\\Users\\Desktop\\test&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">destination&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hdfs://master:9000/user/hadoop/test2&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="n">BufferedInputStream&lt;/span> &lt;span class="n">inputStream&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">BufferedInputStream&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">FileInputStream&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">source&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">configuration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">fileSystem&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">URI&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">destination&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">configuration&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="n">OutputStream&lt;/span> &lt;span class="n">outputStream&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">destination&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="n">IOUtils&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">copyBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">inputStream&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">outputStream&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">4096&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="创建目录">创建目录&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln">1&lt;/span>&lt;span class="nd">@Test&lt;/span>
&lt;span class="ln">2&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">createFolder&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln">3&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">uri&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hdfs://master:9000/user/test&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">configuration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">5&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">fileSystem&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">URI&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">uri&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">configuration&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">6&lt;/span> &lt;span class="n">Path&lt;/span> &lt;span class="n">path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">uri&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">7&lt;/span> &lt;span class="n">fileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">mkdirs&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln">8&lt;/span> &lt;span class="n">fileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">close&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">9&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="删除文件或目录">删除文件或目录&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln"> 1&lt;/span>&lt;span class="nd">@Test&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">deleteFile&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">uri&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hdfs://master:9000/user/hadoop/test2&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">configuration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">fileSystem&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">URI&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">uri&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">configuration&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="n">Path&lt;/span> &lt;span class="n">path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hdfs://master:9000/user/hadoop&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">isDeleted&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">delete&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">isDeleted&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="n">fileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">close&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用 FileSystem 的 delete() 方法可以永久性删除文件或目录。如果要递归删除文件夹，则需要将其第二个参数设为 true。&lt;/p>
&lt;h3 id="列出文件或目录">列出文件或目录&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="ln"> 1&lt;/span>&lt;span class="nd">@Test&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">listFiles&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">uri&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hdfs://master:9000/user&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">configuration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">fileSystem&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">URI&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">uri&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">configuration&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="n">Path&lt;/span> &lt;span class="n">path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">uri&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="n">FileStatus&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">status&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">listStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">FileStatus&lt;/span> &lt;span class="n">fileStatus&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">status&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">fileStatus&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getPath&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="n">fileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">close&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>文件系统的重要特性是提供浏览和检索其目录结构下所存文件与目录相关信息的功能。 FileStatus 类封装了文件系统中文件和目录的元数据，例如文件长度、块大小、副本、修改时间、所有者以及权限信息等。编译运行上述代码后控制台将会打印出 /user 目录下的名称或者文件名。&lt;/p>
&lt;h1 id="小结">小结&lt;/h1>
&lt;h2 id="hdfs-组成部分">HDFS 组成部分&lt;/h2>
&lt;ul>
&lt;li>HDFS 是一个分布式文件存储系统&lt;/li>
&lt;li>Client 提交读写请求（拆分 blocksize）&lt;/li>
&lt;li>NameNode 全局把控（存储数据位置）&lt;/li>
&lt;li>DataNode 存储数据（将数据存储进去，且以 Pipeline 的方式把数据写完）&lt;/li>
&lt;/ul>
&lt;h2 id="hdfs-数据交互">HDFS 数据交互&lt;/h2>
&lt;h3 id="写入数据">写入数据&lt;/h3>
&lt;ol>
&lt;li>使用 HDFS 提供的客户端 Client，向远程的 NameNode 发起 RPC 请求&lt;/li>
&lt;li>NameNode 会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件创建一个记录，否则会让客户端抛出异常&lt;/li>
&lt;li>当客户端开始写入文件的时候，客户端会将文件切分成多个 packets，并在内部以数据队列 data queue（数据队列） 的形式管理这些 packets，并向 NameNode 申请 blocks，获取用来存储 replicas 的合适的 DataNode 列表，列表的大小根据 NameNode 中 replication（副本份数）的设定而定&lt;/li>
&lt;li>开始以 pipeline（管道）的形式将 packet 写入所有的 replicas 中。客户端把 packet 以流的方式写入第一个 DataNode，该 DataNode 把该 packet 存储之后，再将其传递给在此 pipeline 中的下一个 DataNode，直到最后一个 DataNode，这种写数据的方式呈流水线的形式&lt;/li>
&lt;li>最后一个 DataNode 成功存储之后会返回一个 ack packet（确认队列），在 pipeline 里传递至客户端，在客户端的开发库内部维护着 &amp;ldquo;ack queue&amp;rdquo;，成功收到 DataNode 返回的 ack packet 后会从 &amp;ldquo;data queue&amp;rdquo; 移除相应的 packet&lt;/li>
&lt;li>如果传输过程中，有某个 DataNode 出现了故障，那么当前的 pipeline 会被关闭，出现故障的 DataNode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 DataNode 中继续以 pipeline 的形式传输，同时 NameNode 会分配一个新的 DataNode，保持 replicas 设定的数量。&lt;/li>
&lt;li>客户端完成数据的写入后，会对数据流调用 close() 方法，关闭数据流&lt;/li>
&lt;li>只要写入了 dfs.replication.min（最小写入成功的副本数）的复本数（默认为 1），写操作就会成功，并且这个块可以在集群中异步复制，直到达到其目标复本数（dfs.replication 的默认值为 3），因为 NameNode 已经知道文件由哪些块组成，所以它在返回成功前只需要等待数据块进行最小量的复制&lt;/li>
&lt;/ol>
&lt;h3 id="读取数据">读取数据&lt;/h3>
&lt;ol>
&lt;li>客户端调用 FileSystem 实例的 open 方法，获得这个文件对应的输入流 InputStream&lt;/li>
&lt;li>通过 RPC 远程调用 NameNode，获得 NameNode 中此文件对应的数据块保存位置，包括这个文件的副本的保存位置（主要是各 DataNode 的地址）&lt;/li>
&lt;li>获得输入流之后，客户端调用 read 方法读取数据。选择最近的 DataNode 建立连接并读取数据&lt;/li>
&lt;li>如果客户端和其中一个 DataNode 位于同一机器（比如 MapReduce 过程中的 mapper 和 reducer)，那么就会直接从本地读取数据&lt;/li>
&lt;li>到达数据块末端，关闭与这个 DataNode 的连接，然后重新查找下一个数据块&lt;/li>
&lt;li>不断执行第 2~5 步直到数据全部读完&lt;/li>
&lt;li>客户端调用 close，关闭输入流 DFS InputStream&lt;/li>
&lt;/ol>
&lt;h1 id="hdfs-漫画">HDFS 漫画&lt;/h1>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201023190000.png" alt="20201023190000" />&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201023190100.png" alt="20201023190100" />&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201023190200.png" alt="20201023190200" />&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201023190300.png" alt="20201023190300" />&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201023190400.png" alt="20201023190400" />&lt;/p>
&lt;blockquote>
&lt;p>以上漫画版权均归原图作者所有&lt;/p>
&lt;/blockquote>
&lt;h1 id="参考文章">参考文章&lt;/h1>
&lt;p>&lt;a href="https://www.cnblogs.com/qingyunzong/p/8548806.html">https://www.cnblogs.com/qingyunzong/p/8548806.html&lt;/a>&lt;/p></description></item><item><title>初识 Hadoop</title><link>https://sudrizzz.github.io/posts/getting-to-know-hadoop/</link><pubDate>Thu, 24 Sep 2020 09:20:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-hadoop/</guid><description>&lt;h1 id="前言">前言&lt;/h1>
&lt;p>本系列文章是基于《大数据技术基础》与 &lt;a class="link" href="https://coding.imooc.com/class/128.html" target="_blank" rel="noopener"
>10 小时入门大数据&lt;/a> 课程，如果有兴趣可以先阅读该书并观看视频教程。本系列文章中所用到的软件版本及其下载地址如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>名称&lt;/th>
&lt;th>版本&lt;/th>
&lt;th>下载地址&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>CentOS&lt;/td>
&lt;td>8.2.2004&lt;/td>
&lt;td>&lt;a href="https://mirrors.tuna.tsinghua.edu.cn/centos/8.2.2004/isos/x86_64/CentOS-8.2.2004-x86_64-minimal.iso">https://mirrors.tuna.tsinghua.edu.cn/centos/8.2.2004/isos/x86_64/CentOS-8.2.2004-x86_64-minimal.iso&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>JDK&lt;/td>
&lt;td>14.0.2&lt;/td>
&lt;td>&lt;a href="https://www.oracle.com/java/technologies/javase/jdk14-archive-downloads.html">https://www.oracle.com/java/technologies/javase/jdk14-archive-downloads.html&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Hadoop&lt;/td>
&lt;td>2.10.1&lt;/td>
&lt;td>&lt;a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.10.1/hadoop-2.10.1-src.tar.gz">https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.10.1/hadoop-2.10.1-src.tar.gz&lt;/a>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="环境准备">环境准备&lt;/h1>
&lt;h2 id="配置网络">配置网络&lt;/h2>
&lt;p>此篇文章所使用的 CentOS 环境均是使用 VMware 15 虚拟的，具体安装教程请查看 &lt;a class="link" href="https://www.cnblogs.com/bobo-pcb/p/11708459.html" target="_blank" rel="noopener"
>使用 VMware 15 安装虚拟机和使用 CentOS 8&lt;/a>，此处不再赘述。安装好一个节点之后，我们可以采用“虚拟机克隆”的方式，直接完成另外两个节点系统的安装。&lt;/p>
&lt;p>虚拟机的网络配置采用 DHCP 自动分配模式，每台机器的 IP 地址可以通过命令 &lt;code>ip address&lt;/code> 或 &lt;code>ifconfig&lt;/code> 查看，其中 &lt;code>ifconfig&lt;/code> 输出如下，第一组配置中 &lt;code>ens33&lt;/code> 即为本机网络配置，&lt;code>inet&lt;/code> 项对应的即为本机 ip（192.168.61.128）。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="ln"> 1&lt;/span>ens33: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500
&lt;span class="ln"> 2&lt;/span> inet 192.168.61.128 netmask 255.255.255.0 broadcast 192.168.61.255
&lt;span class="ln"> 3&lt;/span> inet6 fe80::20c:29ff:fe65:9052 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt;
&lt;span class="ln"> 4&lt;/span> ether 00:0c:29:65:90:52 txqueuelen 1000 (Ethernet)
&lt;span class="ln"> 5&lt;/span> RX packets 38037 bytes 6542757 (6.2 MiB)
&lt;span class="ln"> 6&lt;/span> RX errors 0 dropped 0 overruns 0 frame 0
&lt;span class="ln"> 7&lt;/span> TX packets 30479 bytes 16809162 (16.0 MiB)
&lt;span class="ln"> 8&lt;/span> TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
&lt;span class="ln"> 9&lt;/span>
&lt;span class="ln">10&lt;/span>lo: flags=73&amp;lt;UP,LOOPBACK,RUNNING&amp;gt; mtu 65536
&lt;span class="ln">11&lt;/span> inet 127.0.0.1 netmask 255.0.0.0
&lt;span class="ln">12&lt;/span> inet6 ::1 prefixlen 128 scopeid 0x10&amp;lt;host&amp;gt;
&lt;span class="ln">13&lt;/span> loop txqueuelen 1000 (Local Loopback)
&lt;span class="ln">14&lt;/span> RX packets 23656 bytes 13542580 (12.9 MiB)
&lt;span class="ln">15&lt;/span> RX errors 0 dropped 0 overruns 0 frame 0
&lt;span class="ln">16&lt;/span> TX packets 23656 bytes 13542580 (12.9 MiB)
&lt;span class="ln">17&lt;/span> TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
&lt;span class="ln">18&lt;/span>
&lt;span class="ln">19&lt;/span>virbr0: flags=4099&amp;lt;UP,BROADCAST,MULTICAST&amp;gt; mtu 1500
&lt;span class="ln">20&lt;/span> ether 52:54:00:d2:b3:31 txqueuelen 1000 (Ethernet)
&lt;span class="ln">21&lt;/span> RX packets 0 bytes 0 (0.0 B)
&lt;span class="ln">22&lt;/span> RX errors 0 dropped 0 overruns 0 frame 0
&lt;span class="ln">23&lt;/span> TX packets 0 bytes 0 (0.0 B)
&lt;span class="ln">24&lt;/span> TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
&lt;/code>&lt;/pre>&lt;/div>&lt;p>本篇文章中三台集群的 IP 分别如下，下文中不再赘述。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">主机名&lt;/th>
&lt;th style="text-align:center">IP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">master&lt;/td>
&lt;td style="text-align:center">192.168.61.128&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">slave1&lt;/td>
&lt;td style="text-align:center">192.168.61.129&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">slave2&lt;/td>
&lt;td style="text-align:center">192.168.61.131&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="配置-host">配置 host&lt;/h2>
&lt;p>以上三台机器要搭建成为集群，就需要让它们互相认识。这个认识的过程是通过 &lt;code>/etc/hosts&lt;/code> 文件来实现的。这一步需要修改每一台机器的 hosts 文件，将以下内容分别粘贴到各个机器的 hosts 文件中。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>vim /etc/hosts
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>192.168.61.128 master
192.168.61.129 slave1
192.168.61.131 slave2
&lt;/code>&lt;/pre>&lt;h2 id="配置-jdk">配置 JDK&lt;/h2>
&lt;p>因为 Hadoop 的环境依赖于 Java JDK，所以需要确保虚拟机中已经正确安装了 JDK，除此之外我们还需要将 JDK 地址配置到环境变量中。在本例中，我的 JDK 安装位置是 &lt;code>/usr/java/jdk-14.0.2&lt;/code>。&lt;/p>
&lt;h3 id="修改-bash_profile">修改 bash_profile&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>vim ~/.bash_profile
&lt;/code>&lt;/pre>&lt;/div>&lt;p>添加以下内容到 .bash_profile 文件末尾：&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">export JAVA_HOME=/usr/java/jdk-14.0.2
export PATH=$JAVA_HOME/bin:$PATH
&lt;/code>&lt;/pre>&lt;p>修改完成并保存后，还需要执行 &lt;code>source&lt;/code> 命令使环境变量立即生效。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">source&lt;/span> ~/.bash_profile
&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后即可使用 &lt;code>java -version&lt;/code> 检查环境变量是否配置成功，执行结果如下所示。&lt;/p>
&lt;pre>&lt;code>java version &amp;quot;14.0.2&amp;quot; 2020-07-14
Java(TM) SE Runtime Environment (build 14.0.2+12-46)
Java HotSpot(TM) 64-Bit Server VM (build 14.0.2+12-46, mixed mode, sharing)
&lt;/code>&lt;/pre>&lt;h2 id="配置-ssh-免密钥登录">配置 SSH 免密钥登录&lt;/h2>
&lt;p>在 Linux 集群间配置免密钥登录，是 Hadoop 集群运维的基础。以下操作在 master 节点进行，实现从 master 免密钥登录 slave1、slave2 节点。生成 ssh 密钥的命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>ssh-keygen
&lt;/code>&lt;/pre>&lt;/div>&lt;p>生成过程中会有一些提示，一路回车即可。执行结果如下所示。&lt;/p>
&lt;pre>&lt;code>root@master:/usr/local/software# ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
/root/.ssh/id_rsa already exists.
Overwrite (y/n)? y
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:DC7+sETaazn0f4OVgxozjdw2XM1Tb60cqoaQvDGXpg8 root@master
The key's randomart image is:
+---[RSA 3072]----+
| |
| . |
| . o . ..|
| . o . + . +|
| oo.*S+ . + + |
| =..% @ + . o |
| ..=oE# = o |
| .+==.o = |
| .o..ooo . |
+----[SHA256]-----+
&lt;/code>&lt;/pre>&lt;p>接下来需要将生成的公钥上传到 slave1 节点，命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>ssh-copy-id root@slave1
&lt;/code>&lt;/pre>&lt;/div>&lt;p>首次通过 master 终端将公钥传给 salve 终端，需要输入 slave 节点的登录密码。上述命令中我们是传输到 slave1 的 root 账户下，所以需要输入 root 用户的密码，传送完毕即可实现免密码登录。执行结果如下。&lt;/p>
&lt;pre>&lt;code>root@master:/usr/local/software# ssh-copy-id root@slave1
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &amp;quot;/root/.ssh/id_rsa.pub&amp;quot;
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@slave1's password:
Number of key(s) added: 1
Now try logging into the machine, with: &amp;quot;ssh 'root@slave1'&amp;quot;
and check to make sure that only the key(s) you wanted were added.
&lt;/code>&lt;/pre>&lt;p>slave2 节点命令同上，只需更改传送到的节点名称，执行结果如下。&lt;/p>
&lt;pre>&lt;code>root@master:/usr/local/software# ssh-copy-id root@slave2
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &amp;quot;/root/.ssh/id_rsa.pub&amp;quot;
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@slave2's password:
Number of key(s) added: 1
Now try logging into the machine, with: &amp;quot;ssh 'root@slave2'&amp;quot;
and check to make sure that only the key(s) you wanted were added.
&lt;/code>&lt;/pre>&lt;p>现在可以尝试登录子节点 slave1 和 slave2。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>ssh root@slave1
&lt;/code>&lt;/pre>&lt;/div>&lt;p>成功登录 salve1 节点的提示如下。&lt;/p>
&lt;pre>&lt;code>root@master:/usr/local/software# ssh root@slave1
Web console: https://slave1:9090/ or https://192.168.61.129:9090/
Last login: Fri Sep 24 14:56:46 2020 from 192.168.61.1
&lt;/code>&lt;/pre>&lt;h1 id="完善配置">完善配置&lt;/h1>
&lt;p>以下配置均在 master 节点上完成，配置完成后可直接复制到 slave 节点，以免重复劳动。&lt;/p>
&lt;h2 id="安装-hadoop">安装 Hadoop&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /usr/local/software
&lt;span class="ln">2&lt;/span>wget http://mirror.cogentco.com/pub/apache/hadoop/common/hadoop-2.10.1/hadoop-2.10.1-src.tar.gz
&lt;span class="ln">3&lt;/span>tar -zxvf hadoop-2.10.1-src.tar.gz
&lt;span class="ln">4&lt;/span>&lt;span class="nb">cd&lt;/span> hadoop-2.10.1-src
&lt;span class="ln">5&lt;/span>mv * ~/hadoop
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在正式使用 Hadoop 集群之前，我们还需要对其配置文件进行修改。本节中的配置内容请以 &lt;a class="link" href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener"
>官方文档&lt;/a> 为准。&lt;/p>
&lt;p>Hadoop 的配置文件均存放在 Hadoop 所在目录的 /etc/hadoop/ 文件夹下。&lt;/p>
&lt;h2 id="修改配置文件">修改配置文件&lt;/h2>
&lt;h3 id="编辑-core-sitexml">编辑 core-site.xml&lt;/h3>
&lt;p>文件 core-site.xml 用来配置 Hadoop 集群的通用属性，包括指定 NameNode 的地址、指定使用 Hadoop 时临时文件的存放路径、指定检查点备份日志的最长时间等。&lt;/p>
&lt;p>使用 vim 打开文件：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>vim ~/hadoop-2.10.1/etc/hadoop/core-site.xml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用以下内容替换 core-site.xml 中的内容：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="ln"> 1&lt;/span>&lt;span class="cp">&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt;&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="cp">&amp;lt;?xml-stylesheet type=&amp;#34;text/xsl&amp;#34; href=&amp;#34;configuration.xsl&amp;#34;?&amp;gt;&lt;/span>
&lt;span class="ln"> 3&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="nt">&amp;lt;configuration&amp;gt;&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="c">&amp;lt;!-- 指定 namenode 的地址 --&amp;gt;&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>fs.defaultFS&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>hdfs://master:9000&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln">10&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="c">&amp;lt;!-- 指定使用 Hadoop 时临时文件的存放路径 --&amp;gt;&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hadoop.tmp.dir&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>/home/hadoop/temp&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln">16&lt;/span>&lt;span class="nt">&amp;lt;/configuration&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>第 6~9 行配置 fs.defaultFS 的属性为 hdfs://master:9000，master 是主机名；第 12~15 行指定 Hadoop 的临时文件夹为 /home/hadoop/temp，此文件夹用户可以自己指定。&lt;/p>
&lt;h3 id="编辑-hdfs-sitexml">编辑 hdfs-site.xml&lt;/h3>
&lt;p>文件 hdfs-site.xml 用来配置分布式文件系统 HDFS 的属性，包括指定 HDFS 保存数据的副本数量，指定 HDFS 中 NameNode、DataNode 的存储位置等。&lt;/p>
&lt;p>使用 vim 打开文件：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>vim ~/hadoop-2.10.1/etc/hadoop/hdfs-site.xml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用以下内容替换 hdfs-site.xml 中的内容：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="ln"> 1&lt;/span>&lt;span class="cp">&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt;&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="cp">&amp;lt;?xml-stylesheet type=&amp;#34;text/xsl&amp;#34; href=&amp;#34;configuration.xsl&amp;#34;?&amp;gt;&lt;/span>
&lt;span class="ln"> 3&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="nt">&amp;lt;configuration&amp;gt;&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="c">&amp;lt;!-- 指定 HDFS 保存数据的副本数量 --&amp;gt;&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>dfs.replication&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>1&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="nt">&amp;lt;/configuration&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中，第 7~8 行，指定 HDFS 文件快的副本数为 1。数据块副本一般为 3 以上，本文章仅作示例，故指定为 1。&lt;/p>
&lt;h3 id="编辑-yarn-sitexml">编辑 yarn-site.xml&lt;/h3>
&lt;p>YARN 是 MapReduce 的调度框架。文件 yarn-site.xml 用配置 YARN 的属性，包括指定 NameNodeManager 获取数据的方式，指定 ResourceManager 的地址，配置 YARN 打印工作日志等。&lt;/p>
&lt;p>使用 vim 打开文件：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>vim ~/hadoop-2.10.1/etc/hadoop/yarn-site.xml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用以下内容替换 yarn-site.xml 中的内容：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="ln"> 1&lt;/span>&lt;span class="cp">&amp;lt;?xml version=&amp;#34;1.0&amp;#34;?&amp;gt;&lt;/span>
&lt;span class="ln"> 2&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="nt">&amp;lt;configuration&amp;gt;&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="c">&amp;lt;!-- 指定 NameNodeManager 获取数据的方式是 shuffle --&amp;gt;&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>yarn.nodemanager.aux-services&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>mapreduce_shuffle&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>yarn.nodemanager.env-whitelist&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln">13&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="c">&amp;lt;!-- 指定 YARN 中 ResourceManager 所在的主机名 --&amp;gt;&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>yarn.resourcemanager.hostname&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln">17&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>master&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln">18&lt;/span> &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln">19&lt;/span>&lt;span class="nt">&amp;lt;/configuration&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中，第 15~19 行配置了 ResourceManager 所在的主机名，如果不进行配置，将会导致 MapReduce 不能获得资源，任务不能执行。&lt;/p>
&lt;h3 id="编辑-mapred-sitexml">编辑 mapred-site.xml&lt;/h3>
&lt;p>文件 mapred-site.xml 主要是配置 MapReduce 的属性，主要是 Hadoop 系统提交的 Map/Reduce 程序运行在 YARN 上。&lt;/p>
&lt;p>首先复制一份 mapred-site.xml.template 文件为 mapred-site.xml，然后打开并进行修改。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>vim ~/hadoop-2.10.1/etc/hadoop/mapred-site.xml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用以下内容替换 mapred-site.xml 中的内容：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="ln"> 1&lt;/span>&lt;span class="cp">&amp;lt;?xml version=&amp;#34;1.0&amp;#34;?&amp;gt;&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="cp">&amp;lt;?xml-stylesheet type=&amp;#34;text/xsl&amp;#34; href=&amp;#34;configuration.xsl&amp;#34;?&amp;gt;&lt;/span>
&lt;span class="ln"> 3&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="nt">&amp;lt;configuration&amp;gt;&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>mapreduce.framework.name&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>yarn&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>mapreduce.application.classpath&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln">13&lt;/span>&lt;span class="nt">&amp;lt;/configuration&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中，第 5~8 行为 MapReduce 指定任务调度框架为 YARN。&lt;/p>
&lt;h3 id="编辑-slaves">编辑 slaves&lt;/h3>
&lt;p>slaves 文件为 Hadoop 提供了子节点的主机名。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>vim ~/hadoop-2.10.1/etc/hadoop/slaves
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用以下内容替换 slaves 中的内容：&lt;/p>
&lt;pre>&lt;code>slave1
slave2
&lt;/code>&lt;/pre>&lt;h2 id="复制文件到子节点">复制文件到子节点&lt;/h2>
&lt;p>使用下面的命令将 Hadoop 文件复制到其他节点，本文中为 slave1 和 slave2，命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> ~/hadoop
&lt;span class="ln">2&lt;/span>scp -r hadoop-2.10.1 root@slave1:~/hadoop/
&lt;span class="ln">3&lt;/span>scp -r hadoop-2.10.1 root@slave2:~/hadoop/
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="配置-hadoop-环境变量">配置 Hadoop 环境变量&lt;/h2>
&lt;p>注意，此操作需要同时在所有节点（master，slave1，slave2）都执行一次，操作命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>vim ~/.bash_profile
&lt;/code>&lt;/pre>&lt;/div>&lt;p>将以下内容追加到 .bash_profile 文件末尾：&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">#HADOOP
export HADOOP_HOME=/root/hadoop/hadoop-2.10.1
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
&lt;/code>&lt;/pre>&lt;p>然后执行下列命令使环境变量生效：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">source&lt;/span> ~/.bash_profile
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="创建临时文件存放目录">创建临时文件存放目录&lt;/h2>
&lt;p>我们在 core-site.xml 文件中指定了 Hadoop 临时文件存放路径，但是文件夹并没有创建，此操作需要同时在所有节点（master，slave1，slave2）都执行一次，操作命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>mkdir /home/hadoop/temp
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="启动集群">启动集群&lt;/h1>
&lt;h2 id="格式化文件系统">格式化文件系统&lt;/h2>
&lt;p>注意，格式化仅需要在第一次使用 Hadoop 集群时进行，后续使用时无需格式化，并且在使用过程中进行格式化，所有文件将会丢失。此操作需要在 master 节点上进行，执行如下命令：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>hdfs namenode -format
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="启动-hadoop-集群">启动 Hadoop 集群&lt;/h2>
&lt;p>Hadoop 启动或停止服务的脚本均存放在 sbin 目录中，所以切换到 /home/hadoop/hadoop-2.10.1/sbin 目录下，执行以下命令：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>start-all.sh
&lt;/code>&lt;/pre>&lt;/div>&lt;p>需要注意的是，在启动过程中，Hadoop 会提示这样的启动方式已经过时，使用如下启动方式即可规避过时提示：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>start-dfs.sh
&lt;span class="ln">2&lt;/span>start-yarn.sh
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="查看进程是否启动成功">查看进程是否启动成功&lt;/h2>
&lt;p>在 master 节点终端执行 jps 命令，在打印结果中会看到四个进程，分别是 NodeManager、SecondaryNameNode、ResourceManager、Jps。如果出现了这四个进程表示启动成功。结果如下：&lt;/p>
&lt;pre>&lt;code>root@master:~/hadoop/hadoop-2.10.1/sbin# jps
17874 NameNode
18070 SecondaryNameNode
18281 ResourceManager
18554 Jps
&lt;/code>&lt;/pre>&lt;p>此时在 slave1 和 slave2 的节点的终端执行 jps 命令，在输出结果中会看到三个进程，分别是 Jps、NodeManager、DataNode，如果出现了这三个进程表示子节点进程启动成功。结果如下：&lt;/p>
&lt;pre>&lt;code>root@slave1:~# jps
15776 NodeManager
15639 DataNode
16106 Jps
&lt;/code>&lt;/pre>&lt;h2 id="查看-webui">查看 WebUI&lt;/h2>
&lt;h3 id="hadoop-页面">Hadoop 页面&lt;/h3>
&lt;p>如果要在宿主机上访问虚拟机 master 节点的 WebUI，需要先将虚拟机的防火墙关闭（此处仅仅是做示例，生产环境不建议这么做），然后访问虚拟机 master 节点 IP:50070 即可。&lt;/p>
&lt;p>防火墙相关命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="c1"># 暂时关闭防火墙&lt;/span>
&lt;span class="ln">2&lt;/span>systemctl stop firewalld
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="c1"># 永久关闭防火墙&lt;/span>
&lt;span class="ln">5&lt;/span>systemctl disable firewalld
&lt;span class="ln">6&lt;/span>
&lt;span class="ln">7&lt;/span>&lt;span class="c1"># 启用防火墙&lt;/span>
&lt;span class="ln">8&lt;/span>systemctl &lt;span class="nb">enable&lt;/span> firewalld
&lt;/code>&lt;/pre>&lt;/div>&lt;p>例如本例中 master 节点地址为 192.168.61.128，则访问 192.168.61.128:50070，页面如下图：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200926201409.png" alt="20200926201409" />&lt;/p>
&lt;h3 id="yarn-页面">YARN 页面&lt;/h3>
&lt;p>如上例，与 Hadoop 管理页面不同的是，YARN Web 页面地址端口是 8088，页面如下图：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200926203912.png" alt="20200926203912" />&lt;/p>
&lt;h1 id="运行实例">运行实例&lt;/h1>
&lt;p>在 Hadoop 自带的 examples 中有一种利用分布式系统计算圆周率的方法，采用的是拟蒙特卡罗（Quasi-Monte Carlo）算法来对 $ \pi $ 的值进行估算。下面通过运行该程序来检验 Hadoop 集群是否安装配置成功。&lt;/p>
&lt;p>在 master 节点终端中执行下面的命令：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>hadoop jar hadoop-2.10.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar pi &lt;span class="m">100&lt;/span> &lt;span class="m">100000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Hadoop 的命令类似 Java 命令，通过 jar 指定要运行的程序所在的 jar 包 hadoop-mapreduce-examples-2.10.1.jar。参数 pi 表示需要计算的圆周率 $ \pi $。后面两个参数中，100 是指要运行 100 次 map，100000 表示每个 map 的任务次数，即每个节点要模拟飞镖 100000 次。执行过程及结果如下图：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200926210747.png" alt="20200926210747" />&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200926211331.png" alt="20200926211331" />&lt;/p>
&lt;pre>&lt;code>Job Finished in 131.634 seconds
Estimated value of Pi is 3.14158440000000000000
&lt;/code>&lt;/pre>&lt;p>至此，Hadoop 环境配置完成。&lt;/p>
&lt;h1 id="备注">备注&lt;/h1>
&lt;p>如果在执行 mapreduce 任务中报错如 &lt;a class="link" href="https://stackoverflow.com/questions/21005643/container-is-running-beyond-memory-limits" target="_blank" rel="noopener"
>此问题&lt;/a> 的描述，参考 &lt;a class="link" href="https://web.archive.org/web/20170610145449/http://hortonworks.com/blog/how-to-plan-and-configure-yarn-in-hdp-2-0/" target="_blank" rel="noopener"
>此篇文章&lt;/a>，需要在 mapred-site.xml 文件中添加下列配置：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="ln"> 1&lt;/span>&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln"> 2&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>mapreduce.map.memory.mb&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>4096&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>mapreduce.reduce.memory.mb&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>8192&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>mapreduce.map.java.opts&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>-Xmx3072m&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="ln">13&lt;/span>&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>mapreduce.reduce.java.opts&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>-Xmx6144m&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="ln">16&lt;/span>&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>CMU 15-213 存储器层次结构</title><link>https://sudrizzz.github.io/posts/cmu-15-213-lesson3/</link><pubDate>Sun, 20 Sep 2020 15:20:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/cmu-15-213-lesson3/</guid><description>&lt;h1 id="前言">前言&lt;/h1>
&lt;p>本课的第三、四章分别是程序的机器级表示和处理器体系结构，由于过于硬核，此处略过。第五章是优化程序性能，讲解了如何最大限度地提高程序执行效能，此处也略过。本文基于第六章存储器层级结构。&lt;/p>
&lt;h1 id="存储技术">存储技术&lt;/h1>
&lt;p>在本节中主要介绍 SRAM 存储器、DRAM 存储器、ROM 存储器以及机械和固态硬盘。&lt;/p>
&lt;h2 id="随机访问存储器">随机访问存储器&lt;/h2>
&lt;p>随机访问存储器（Random Access Memory, RAM）分为两类：静态的和动态的。静态随机访问存储器（Static Random Access Memory, SRAM）比动态随机访问存储器（Dynamic Random Access Memory, DRAM）更快，但也贵得多。目前 CPU 中的三级缓存都是 SRAM。&lt;/p>
&lt;h3 id="易失性存储器">易失性存储器&lt;/h3>
&lt;p>需要注意的是，虽然 SRAM 是静态随机访问存储器，但是其“静态”是相对于动态随机访问存储器的，仍然属于“易失性存储器”，而非真正意义上的静态，同时 DRAM 也属于“易失性存储器”。通俗的说，就是断电之后保存的信息就会丢失。&lt;/p>
&lt;h4 id="sram">SRAM&lt;/h4>
&lt;p>SRAM 将每个位存储在一个双稳态的存储器单元中，每个单元是用一个六晶体管来实现的，在通电的情况下，它可以无限期地保持在两个不同的电压配置或状态之一，其他任何状态都是不稳定的。当从不稳定状态开始，电路会迅速转换到两个稳定状态中的一个。这样的存储器单元类似于下图倒转的钟摆模型。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200918161742.png" alt="20200918161742" />&lt;/p>
&lt;p>由于上述的特性（SRAM 的双稳态特性），只要有电，它就会永远保持它的值。即使有干扰（例如电子噪音）来扰乱电压，当干扰消除后，电路就会恢复到稳定值。这样体现了上述表格中的持续性和不敏感性。&lt;/p>
&lt;h4 id="dram">DRAM&lt;/h4>
&lt;p>DRAM 将每个位存储位对一个电容的充电，每个单元由一个电容和一个访问晶体管组成。但是与 SRAM 不同，DRAM 存储单元对抗干扰非常敏感。当电容的电压被扰乱之后，它就永远不会恢复了。&lt;/p>
&lt;h4 id="小结">小结&lt;/h4>
&lt;p>下表总结了 SRAM 和 DRAM 存储器的特性。只要有供电，SRAM 就会保持不变。与 DRAM 不同，它不需要刷新。SRAM 的存取比 DRAM 快。SRAM 对诸如光和电噪声这样的干扰不敏感。代价是 SRAM 单元比 DRAM 单元使用更多的晶体管，因而密集度低，而且更贵，功耗更大。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">&lt;/th>
&lt;th style="text-align:center">每位晶体管数&lt;/th>
&lt;th style="text-align:center">相对访问时间&lt;/th>
&lt;th style="text-align:center">持续的？&lt;/th>
&lt;th style="text-align:center">敏感的？&lt;/th>
&lt;th style="text-align:center">相对花费&lt;/th>
&lt;th style="text-align:center">应用&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">SRAM&lt;/td>
&lt;td style="text-align:center">6&lt;/td>
&lt;td style="text-align:center">1X&lt;/td>
&lt;td style="text-align:center">是&lt;/td>
&lt;td style="text-align:center">否&lt;/td>
&lt;td style="text-align:center">1000x&lt;/td>
&lt;td style="text-align:center">高速缓存存储器&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">DRAM&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">10X&lt;/td>
&lt;td style="text-align:center">否&lt;/td>
&lt;td style="text-align:center">是&lt;/td>
&lt;td style="text-align:center">1X&lt;/td>
&lt;td style="text-align:center">主存，帧缓冲区&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="非易失性存储器">非易失性存储器&lt;/h3>
&lt;p>显然，非易失性存储器指即使断电也不会丢失数据的存储器，非易失性存储器包括以下几种：&lt;/p>
&lt;ul>
&lt;li>只读存储器（Read-Only Memory, ROM）：在生产期间被编程，虽然 ROM 中有的类型既可以读也可以写，但是他们整体上都被称为只读存储器&lt;/li>
&lt;li>可编程存储器（Programmable ROM, PROM）：只能被编程一次&lt;/li>
&lt;li>可擦写可编程存储器（Eraseable PROM, EPROM）：有一个透明的石英窗口，允许光到达存储单元。紫外线或者 X 射线照射透过窗口，EPROM 单元就被清除为 0。对 EPROM 编程时通过使用一种把 1 写入 EPROM 的特殊设备来完成的，EPROM 能够被擦除和重编程的次数的数量级可以达到 1000 次&lt;/li>
&lt;li>电子可擦除可编程存储器（Electrically Eraseable PROM, EEPROM）：类似与 EPROM，但它不需要独立的编程设备，可以直接在印刷电路板上编程，EEPROM 可以编程的次数的数量级可以达到 $ 10^{5} $ 次&lt;/li>
&lt;li>闪存（Flash Memory）：基于 EEPROM，多用于手机、相机等产品中，大约 100000 次擦写后失效&lt;/li>
&lt;/ul>
&lt;p>需要说明的是，存储在 ROM 设备中的程序通常被称为固件（firmware）。例如 BIOS、磁盘驱动控制器、显卡驱动控制器等等。&lt;/p>
&lt;h3 id="访问主存">访问主存&lt;/h3>
&lt;p>数据流通过称为总线（bus）的共享电子电路在处理器和 DRAM 主存之间来来回回。例如下图中，连接 I/O 桥接器与总线接口的系统总线（system bus），连接主存与 I/O 桥接器的内存总线(memory bus)。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200918171907.png" alt="20200918171907" />&lt;/p>
&lt;h4 id="从主存读数据">从主存读数据&lt;/h4>
&lt;p>数据移动路径：主存 -&amp;gt; 内存总线 -&amp;gt; I/O 桥接器 -&amp;gt; 系统总线 -&amp;gt; 总线接口 -&amp;gt; 寄存器&lt;/p>
&lt;h4 id="从主存写数据">从主存写数据&lt;/h4>
&lt;p>数据移动路径：寄存器 -&amp;gt; 总线接口 -&amp;gt; 系统总线 -&amp;gt; I/O 桥接器 -&amp;gt; 内存总线 -&amp;gt; 主存&lt;/p>
&lt;h2 id="机械硬盘">机械硬盘&lt;/h2>
&lt;h3 id="构造">构造&lt;/h3>
&lt;p>磁盘是由盘片（platter）组成的，每个盘片有两个表面（surface）。盘片中央有一个可以旋转的主轴（spindle），它使得盘片以固定的旋转速率（rotational rate）旋转，通常是 5400-15000 转每分钟（Revolution Per Minute，RPM）。磁盘通常包含一个或多个盘片，并封装在一个密闭的空间中。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200921102634.png" alt="20200921102634" />&lt;/p>
&lt;p>每个盘片的表面是由一组磁道（track）同心圆组成的，每个磁道又被划分为一组扇区（sector）。每个扇区包含相等数据量的数据位（通常是 512 字节），扇区之间由一些间隙（gap）隔开，间隙存储用来表示扇区的格式化位。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200921102745.png" alt="20200921102745" />&lt;/p>
&lt;h3 id="容量">容量&lt;/h3>
&lt;p>在磁盘容量的计算中，总是按照 1000 进制为准，例如 $ 1GB = 10^{9} Bytes $&lt;/p>
&lt;p>磁盘容量是由以下技术因素决定的：&lt;/p>
&lt;ul>
&lt;li>记录密度（Recording density）（位/英寸）：磁道一英寸的段中可以放入的位数&lt;/li>
&lt;li>磁道密度（Track density）（道/英寸）：从盘片中心出发半径一英寸的段内可以有的磁道数&lt;/li>
&lt;li>面密度（Areal density）（位/平方英寸）：记录密度与磁道密度的乘积&lt;/li>
&lt;/ul>
&lt;p>磁盘容量的计算方式：&lt;/p>
&lt;p>$$ 磁盘容量 = \frac{字节数}{扇区} \times \frac{平均扇区数}{磁道} \times \frac{磁道数}{表面} \times \frac{表面数}{盘片} \times \frac{盘片数}{磁道} $$&lt;/p>
&lt;p>例如现有一磁盘，总共有 5 个盘片，每个盘片有 2 个表面，每个表面有 20000 个磁道，每个磁道平均有 300 个扇区，每个扇区有 512 个字节，计算其磁盘容量。&lt;/p>
&lt;p>$$
\begin{aligned}
磁盘容量 &amp;amp;= \frac{512 字节}{扇区} \times \frac{300 扇区}{磁盘} \times \frac{20000 磁道}{表面} \times \frac{2 表面}{盘片} \times \frac{5盘片}{磁盘} \newline
&amp;amp;= 512 \times 300 \times 20000 \times 2 \times 5 \ Byte \newline
&amp;amp;= 30.72 \ GB
\end{aligned}
$$&lt;/p>
&lt;h2 id="固态硬盘">固态硬盘&lt;/h2>
&lt;p>固态硬盘示意图如下：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200922160917.png" alt="20200922160917" />&lt;/p>
&lt;p>一个固态硬盘由 B 个块的序列组成，每个块由 P 页组成。通常，页的大小是 512 字节~4KB，块是由 32~128 页组成的，块的大小为 16KB~512KB。数据是以页为单位读写的，只有在一页所属的块整个被擦除之后，才能写这一页（通常是指该块中的所有位都被设置为 1）。在进行 100000 次重复写之后，块将会磨损损坏。&lt;/p>
&lt;h3 id="分类">分类&lt;/h3>
&lt;p>现阶段的固态硬盘主要分为以下几类&lt;/p>
&lt;ul>
&lt;li>单阶存储单元（Single-Level Cell，SLC）：一个存储单元能存储 1 bit 信息，SLC 闪存的优点是传输速度更快，功率消耗更低和存储单元的寿命更长&lt;/li>
&lt;li>多阶存储单元（Multi-Level Cell，MLC）：一个存储单元能存储 2 bit 信息，MLC 闪存可降低生产成本，但比起 SLC 闪存，其传输速度较慢，功率消耗较高和存储单元的寿命较低&lt;/li>
&lt;li>三阶存储单元（Triple-Level Cell，TLC）：一个存储单元能存储 3 bit 信息，TLC 的写入速度比 SLC 和 MLC 慢，寿命也比 SLC 和 MLC 短（使用 LDPC 的话，约有 1500 次），大约 1000 次&lt;/li>
&lt;li>四阶存储单元（Quad-Level Cell，QLC）：一个存储单元能存储 4 bit 信息，寿命为四者之中最短，大约只有 500 次&lt;/li>
&lt;/ul>
&lt;p>在假设低电位表示二进制的 0，高电位表示二进制的 1 时，SLC、MLC、TLC 和 QLC 的电位及二进制值对比表如下。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200922162556.png" alt="20200922162556" />&lt;/p>
&lt;h3 id="对比机械硬盘">对比机械硬盘&lt;/h3>
&lt;h4 id="优点">优点&lt;/h4>
&lt;ul>
&lt;li>固态硬盘没有移动部件，因而随机访问时间比机械硬盘快得多，能耗更低，同时也更结实。&lt;/li>
&lt;/ul>
&lt;h4 id="缺点">缺点&lt;/h4>
&lt;ul>
&lt;li>在反复写之后，固态硬盘存储单元容易磨损&lt;/li>
&lt;li>固态硬盘成本更高，相对容量更小&lt;/li>
&lt;/ul>
&lt;h3 id="应用">应用&lt;/h3>
&lt;ul>
&lt;li>智能手机&lt;/li>
&lt;li>笔记本电脑，PC&lt;/li>
&lt;li>服务器&lt;/li>
&lt;/ul>
&lt;h1 id="发展趋势">发展趋势&lt;/h1>
&lt;p>下图以半对数为比例，画出了各类存储以及 CPU 性能的发展趋势。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200924145622.png" alt="20200924145622" />&lt;/p>
&lt;h1 id="局部性">局部性&lt;/h1>
&lt;p>一个编写良好的计算机程序常常具有良好的局部性（locality）。也就是它们倾向于引用邻近与其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。局部性通常有两种不同的形式：时间局部性（temporal locality）和空间局部性（spatial locality）。&lt;/p>
&lt;p>下面是一些量化评价程序中局部性的一些简单原则：&lt;/p>
&lt;ul>
&lt;li>重复引用相同变量的程序由良好的时间局部性&lt;/li>
&lt;li>对于具有步长为 k 的引用模式的程序，步长越小空间局部性越好。具有步长为 1 的引用模式的程序有很好的空间局部性。在内容中以大步长跳来跳去的程序空间局部性会很差&lt;/li>
&lt;li>对于取质量来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好&lt;/li>
&lt;/ul>
&lt;h1 id="存储器层次结构">存储器层次结构&lt;/h1>
&lt;p>存储器层次结构（Memory Hierarchy）如下图所示，越靠近底部的存储器速度越慢单价越低，越靠近顶部的则反之。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200924160033.png" alt="20200924160033" />&lt;/p>
&lt;h2 id="缓存">缓存&lt;/h2>
&lt;h3 id="简介">简介&lt;/h3>
&lt;p>缓存（Cache）是一种容量小但速度极快的存储设备，速度仅次于 CPU 寄存器。它充当速度较慢、容量较大的存储设备的临时存储区。&lt;/p>
&lt;h3 id="层次结构的基本思想">层次结构的基本思想&lt;/h3>
&lt;p>对于第 k 层更快更小的存储设备都充当了第 k+1 层更慢更小的存储设备的缓存。&lt;/p>
&lt;h3 id="存储结构产生的原因">存储结构产生的原因&lt;/h3>
&lt;p>由于局部性，程序通常更倾向于访问第 k 层存储器的数据，而非第 k+1 层存储器的数据。因此，第 k+1 层存储器设备可以做得速度更慢，容量更大以及单价更便宜。&lt;/p>
&lt;h3 id="存储器层次结构中的缓存示例">存储器层次结构中的缓存示例&lt;/h3>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200924155525.png" alt="20200924155525" />&lt;/p>
&lt;h1 id="参考文献">参考文献&lt;/h1>
&lt;ol>
&lt;li>&lt;a href="https://zh.wikipedia.org/wiki/%E9%97%AA%E5%AD%98">https://zh.wikipedia.org/wiki/%E9%97%AA%E5%AD%98&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.bilibili.com/video/av61437877">https://www.bilibili.com/video/av61437877&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>CMU 15-213 浮点数</title><link>https://sudrizzz.github.io/posts/cmu-15-213-lesson2/</link><pubDate>Mon, 14 Sep 2020 18:57:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/cmu-15-213-lesson2/</guid><description>&lt;h1 id="前言">前言&lt;/h1>
&lt;p>在 &lt;a class="link" href="https://sudrizzz.github.io/posts/cmu-15-213-lesson1/" target="_blank" rel="noopener"
>上一篇文章&lt;/a> 中，我们了解了二进制有符号数、无符号数以及其相关的运算方法，在本篇中，我们将进一步了解浮点数在计算机中的相关知识。&lt;/p>
&lt;h1 id="二进制小数">二进制小数&lt;/h1>
&lt;h2 id="表示方法">表示方法&lt;/h2>
&lt;p>二进制小数表达方式：在“二进制小数点”左侧的位表示 2 的 n 次幂，而在“二进制小数点”右侧的位则表示 2 的 -n 次幂。如下图：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200914190724.png" alt="20200914190724" />&lt;/p>
&lt;p>用公式表达如下：&lt;/p>
&lt;p>$$ a = \sum_{k=-j}^{i}b_{k} \times 2^{k} $$&lt;/p>
&lt;h2 id="示例">示例&lt;/h2>
&lt;p>例如，将十进制小数转换为二进制小数，有以下例子：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">十进制小数&lt;/th>
&lt;th style="text-align:left">二进制小数&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">$ 5\frac{3}{4} $&lt;/td>
&lt;td style="text-align:left">101.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">$ 2\frac{7}{8} $&lt;/td>
&lt;td style="text-align:left">10.111&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">$ 1\frac{7}{16} $&lt;/td>
&lt;td style="text-align:left">1.0111&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>以第一个为例，我们可以注意到二进制小数按位进行求和的结果是：&lt;/p>
&lt;p>$$ 5\frac{3}{4} = 2^{2}+2^{0}+2^{-1}+2^{-2} $$&lt;/p>
&lt;p>通过上面三个例子，我们可以注意到，当二进制小数整体右移一位，即相当于将十进制小数除以 2（仅针对无符号数）。相应的，当二进制小数整体左移一位，即相当于将十进制小数乘以 2。&lt;/p>
&lt;p>同时我们应特别注意到，形如 $ 0.11111&amp;hellip;_{2} $ 的二进制小数，表示略比 1 小的十进制数。用公式表示如下：&lt;/p>
&lt;p>$$ 1/2 + 1/4 + 1/8 + \dots + 1/2^{i} + \dots \to 1.0 $$&lt;/p>
&lt;p>记为：&lt;/p>
&lt;p>$$ 1.0-\varepsilon $$&lt;/p>
&lt;p>其中，$ \varepsilon $ 取决于二进制小数点右边的 1 有多少位，因此，$ \varepsilon $ 越小，则二进制小数越接近 1。&lt;/p>
&lt;h2 id="局限性">局限性&lt;/h2>
&lt;h3 id="不精确">不精确&lt;/h3>
&lt;p>二进制小数仅能准确表示形如 $ x/2^{k} $ 的十进制小数，其他形式的小数则需要采用重复位的方式来表示。例如：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">十进制小数&lt;/th>
&lt;th style="text-align:left">二进制小数&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">1/3&lt;/td>
&lt;td style="text-align:left">$ 0.0101010101[01]\dots $&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">1/5&lt;/td>
&lt;td style="text-align:left">$ 0.001100110011[0011]\dots $&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">1/10&lt;/td>
&lt;td style="text-align:left">$ 0.0001100110011[0011]\dots $&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="位数限制">位数限制&lt;/h3>
&lt;p>由于浮点数位数有限，将浮点数向左移，则可以表示更大的数，但是会损失精度。将浮点数向右移动，精度得到了提高，但是大数又不能进行表示。&lt;/p>
&lt;h1 id="ieee-浮点数">IEEE 浮点数&lt;/h1>
&lt;h2 id="位表示">位表示&lt;/h2>
&lt;p>所有的浮点数均可以写成如下形式：&lt;/p>
&lt;p>$$ V = (-1)^{s} \times M \times 2^{E} $$&lt;/p>
&lt;p>其中，各个字母含义如下：&lt;/p>
&lt;ul>
&lt;li>符号（sign）s 决定这是负数（s=1）还是正数（s=0）&lt;/li>
&lt;li>尾数（significand） M 是一个二进制小数，它的范围是 $ 1 \sim 2 - \varepsilon $，或者是 $ 0 \sim 1 - \varepsilon $&lt;/li>
&lt;li>阶码（exponent）E 的作用是对浮点数进行加权，这个权重是 2 的 E 次幂&lt;/li>
&lt;/ul>
&lt;p>32 位或 64 位的浮点数位表示形式如下：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200914210832.png" alt="20200914210832" />&lt;/p>
&lt;p>单精度浮点数各个部分所占的位：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200914211851.png" alt="20200914211851" />&lt;/p>
&lt;p>双精度浮点数各个部分所占的位：
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200914211953.png" alt="20200914211953" />&lt;/p>
&lt;p>将浮点数的位表示划分为三个字段，分别对这些值进行编码：&lt;/p>
&lt;ul>
&lt;li>一个单独的符号位 s 直接编码符号 s&lt;/li>
&lt;li>k 位的阶码字段 $ exp = e_{k-1} \dots e_{1}e_{0} $ 编码阶码 E&lt;/li>
&lt;li>n 位小数字段 $ frac = f_{n-1} \dots f_{1}f_{0} $ 编码尾数 M，但是编码出来的值也依赖于阶码字段的值是否等于 0&lt;/li>
&lt;/ul>
&lt;h2 id="三种情况">三种情况&lt;/h2>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200917101541.png" alt="20200917101541" />&lt;/p>
&lt;h3 id="规格化的值">规格化的值&lt;/h3>
&lt;p>当 exp 所有位即不全为 0，也不全为 1 时，我们称之为规格化的值。在这种情况下，阶码字段被解释为以偏置（biased）形式表示的有符号整数。即&lt;/p>
&lt;p>$$ E = e - Bias $$&lt;/p>
&lt;p>其中 e 是无符号数，其位表示为 $ e_{k-1} \dots e_{1}e_{0} $，而偏置值 $ Bias = 2^{k-1} - 1 $，也即单精度时等于 127，双精度时等于 1023。&lt;/p>
&lt;p>由此编码得到的阶码的取值范围是：&lt;/p>
&lt;ul>
&lt;li>单精度：$ -126 \sim +127 $&lt;/li>
&lt;li>双精度：$ -1022 \sim +1023 $&lt;/li>
&lt;/ul>
&lt;p>小数字段 frac 被解释为描述小数值 f，其中 $ 0 \le f &amp;lt; 1 $，其二进制表示为 $ 0.f_{n-1} \dots f_{1}f_{0} $，也就是小数点在最高有效位的左边。&lt;/p>
&lt;p>尾数定义为 $ M = 1 + f $，因此我们可以将 M 看成一个二进制表达式为 $ 1.f_{n-1} \dots f_{1}f_{0} $ 的数字。此时 $ 1 \le M &amp;lt; 2 $。&lt;/p>
&lt;h3 id="非规格化的值">非规格化的值&lt;/h3>
&lt;p>当阶码全为 0 时，所表示的数是非规格化形式。在这种情况下，$ E = 1-Bias $，$ M = f $，也就是小数部分的值，不包含隐含的开头的 1。&lt;/p>
&lt;p>非规格化数主要有两个作用：用来表示 0 或者表示接近于 0 的数。&lt;/p>
&lt;p>当浮点数二进制位全为 0 时：符号位为 0，阶码全为 0，小数域全为 0，即 $ s = M = f = 0 $，此时表示得到的浮点数是 +0.0。但当符号位为 1 且其他域全为 0 时，可以得到浮点数 -0.0。根据 IEEE 的浮点格式，值 +0.0 和 -0.0 在某些方面被认为是不同的，而在其他方面是相同的。&lt;/p>
&lt;p>非规格化数提供一种称为逐渐溢出（gradually underflow）的属性，可以用来表示接近于 0 的数值。&lt;/p>
&lt;h3 id="特殊情况">特殊情况&lt;/h3>
&lt;p>在阶码全为 1 的前提下，如果小数域全为 0 时，结果为无穷大或无穷小；如果小数域非 0 时，结果为 NaN（Not a Number）。&lt;/p>
&lt;p>其中小数域全为 0 时，当 $ s = 0 $ 时是 $ +\infty $，当 $ s = 1 $ 时是 $ -\infty $。&lt;/p>
&lt;p>一些运算的结果不是实数或者是无穷时，这样就会返回 NaN，例如计算 $ \sqrt{-1} $ 或者 $ \infty - \infty $ 时。&lt;/p>
&lt;h1 id="舍入">舍入&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">舍入方式&lt;/th>
&lt;th style="text-align:center">1.40&lt;/th>
&lt;th style="text-align:center"> 1.60&lt;/th>
&lt;th style="text-align:center"> 1.50&lt;/th>
&lt;th style="text-align:center"> 2.50&lt;/th>
&lt;th style="text-align:center"> –1.50&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">向 0 舍入&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">–1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">向下舍入（−∞）&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">–2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">向上舍入（+∞）&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">–1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">向偶数舍入（默认）&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">–2&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>上述的向偶数舍入实际上就是四舍五入，但需要注意的是，在舍入时优先考虑向偶数舍入。例如上述的 1.50 向上舍入到 2，而 2.5 按照四舍五入应该舍入到 3，由于 3 并不是偶数，故应该向下舍入到 2。&lt;/p>
&lt;p>在现实情况中，向偶数舍入（也称为向最接近的整数）避在大多数情况下避免了统计误差，在 50% 的时间里它将向上取整，而在另外的 50% 时间里它将向下取整，所以它是默认的舍入方式。&lt;/p>
&lt;p>例如我们要对以下数字进行针对百分位的舍入，结果如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">数据&lt;/th>
&lt;th style="text-align:center">结果&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">7.8949999&lt;/td>
&lt;td style="text-align:center">7.89&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">7.8950001&lt;/td>
&lt;td style="text-align:center">7.90&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">7.8950000&lt;/td>
&lt;td style="text-align:center">7.90&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">7.8850000&lt;/td>
&lt;td style="text-align:center">7.88&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="浮点运算">浮点运算&lt;/h1>
&lt;h2 id="乘法">乘法&lt;/h2>
&lt;p>定义：&lt;/p>
&lt;p>$$ a = (-1)^{s_{1}} \times M_{1} \times 2^{E_{1}} $$&lt;/p>
&lt;p>$$ b = (-1)^{s_{2}} \times M_{2} \times 2^{E_{2}} $$&lt;/p>
&lt;p>$$ c = a \times b = (-1)^{s} \times M \times 2^{E} $$&lt;/p>
&lt;p>其中：&lt;/p>
&lt;ul>
&lt;li>$ s = s_{1} \land s_{2} $&lt;/li>
&lt;li>$ M = M_{1} \times M_{2} $&lt;/li>
&lt;li>$ E = E_{1} + E_{2} $&lt;/li>
&lt;/ul>
&lt;p>特殊情况处理：&lt;/p>
&lt;ul>
&lt;li>如果 M ≥ 2，将 M 右移，增大 E&lt;/li>
&lt;li>如果 E 超出范围，则溢出到 $ \infty $&lt;/li>
&lt;li>如果 M 位数过多，则舍入到有限位能表示为止&lt;/li>
&lt;/ul>
&lt;h2 id="加法">加法&lt;/h2>
&lt;p>定义：&lt;/p>
&lt;p>$$ a = (-1)^{s_{1}} \times M_{1} \times 2^{E_{1}} $$&lt;/p>
&lt;p>$$ b = (-1)^{s_{2}} \times M_{2} \times 2^{E_{2}} $$&lt;/p>
&lt;p>假定 $ E_{1} \gt E_{2} $，则：&lt;/p>
&lt;p>$$ c = a + b = [(-1)^{s_{1}} \times M_{1} \times 2^{E_{1}-E_{2}} + (-1)^{s_{2}} \times M_{2}] \times 2^{E_{2}} $$&lt;/p>
&lt;p>浮点数加法的一般步骤如下：&lt;/p>
&lt;ol>
&lt;li>对阶：将指数较小的浮点数（b）进行尾数向右移位，指数同步增大，直到两个操作数的指数等&lt;/li>
&lt;li>求和：对尾数进行求和&lt;/li>
&lt;li>规格化：对指数和尾数做规格化，并对尾数进行舍入&lt;/li>
&lt;/ol>
&lt;p>特殊情况处理：&lt;/p>
&lt;ul>
&lt;li>如果 M ≥ 2，将 M 右移，增大 E&lt;/li>
&lt;li>如果 M &amp;lt; 1，将 M 左移，同步减小 E&lt;/li>
&lt;li>如果 E 超出范围，则溢出到 $ \infty $&lt;/li>
&lt;li>如果 M 位数过多，则舍入到有限位能表示为止&lt;/li>
&lt;/ul>
&lt;h1 id="参考文献">参考文献&lt;/h1>
&lt;ol>
&lt;li>&lt;a href="https://qiankun214.github.io/2019/05/28/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%A4%84%E7%90%86/">https://qiankun214.github.io/2019/05/28/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%A4%84%E7%90%86/&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>初识 Nginx（二）</title><link>https://sudrizzz.github.io/posts/getting-to-know-nginx-2/</link><pubDate>Fri, 11 Sep 2020 19:51:07 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-nginx-2/</guid><description>&lt;h1 id="应用示例">应用示例&lt;/h1>
&lt;blockquote>
&lt;p>本篇文章中所使用的 Nginx 是通过下载软件包手动编译安装的，详见 &lt;a class="link" href="https://sudrizzz.github.io/posts/getting-to-know-nginx" target="_blank" rel="noopener"
>上一篇文章&lt;/a> 离线安装部分。&lt;/p>
&lt;/blockquote>
&lt;p>在上一篇文章中，我们初步接触了 Nginx 的安装以及使用方法。在本篇文章中我们将以具体的静态网页作为例子，来详细介绍 Nginx 的部分细节。&lt;/p>
&lt;h2 id="文件准备">文件准备&lt;/h2>
&lt;p>我们以 C++ 文档 dlib 为例做介绍，官网 &lt;a href="http://dlib.net">http://dlib.net&lt;/a>，点击左下角的 Download 按钮并将下载好的文件解压。将文件夹中的 docs 目录内容复制到 Nginx 安装目录中的 dlib 目录中。相关的目录结构如下。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="ln"> 1&lt;/span>drwxr-xr-x. 9 root root 258 9月 11 16:54 blog
&lt;span class="ln"> 2&lt;/span>drwx------. 2 nobody root 6 9月 6 15:26 client_body_temp
&lt;span class="ln"> 3&lt;/span>drwxr-xr-x. 2 root root 4096 9月 11 19:48 conf
&lt;span class="ln"> 4&lt;/span>drwxrwxrwx. 10 root root 8192 8月 9 03:30 dlib
&lt;span class="ln"> 5&lt;/span>drwx------. 2 nobody root 6 9月 6 15:26 fastcgi_temp
&lt;span class="ln"> 6&lt;/span>drwxr-xr-x. 2 root root 40 9月 6 15:24 html
&lt;span class="ln"> 7&lt;/span>drwxr-xr-x. 2 root root 58 9月 11 16:20 logs
&lt;span class="ln"> 8&lt;/span>drwx------. 2 nobody root 6 9月 6 15:26 proxy_temp
&lt;span class="ln"> 9&lt;/span>drwxr-xr-x. 2 root root 19 9月 6 15:24 sbin
&lt;span class="ln">10&lt;/span>drwx------. 2 nobody root 6 9月 6 15:26 scgi_temp
&lt;span class="ln">11&lt;/span>drwx------. 2 nobody root 6 9月 6 15:26 uwsgi_temp
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="修改配置">修改配置&lt;/h2>
&lt;p>编辑 &lt;code>conf/nginx.conf&lt;/code>，将 &lt;code>server&lt;/code> 中的 &lt;code>location&lt;/code> 部分修改为如下配置。&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">location / {
alias dlib/;
#...
}
&lt;/code>&lt;/pre>&lt;p>其中，&lt;code>location&lt;/code> 后的 &lt;code>/&lt;/code> 代表根域名指向括号中的目录配置，&lt;code>alias&lt;/code> 指定一个目录替代默认目录。&lt;/p>
&lt;blockquote>
&lt;p>更多信息可以查看官方文档&lt;br>
&lt;a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#alias">http://nginx.org/en/docs/http/ngx_http_core_module.html#alias&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="重新加载">重新加载&lt;/h2>
&lt;p>执行以下命令，以新加载 Nginx 服务。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>nginx -s reload
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="访问">访问&lt;/h2>
&lt;p>执行完以上步骤后，访问 Nginx 的地址，即可看到 dlib 下的静态文件已经被正常加载了。如下图。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200911201740.png" alt="20200911201740" />&lt;/p>
&lt;h1 id="常用配置">常用配置&lt;/h1>
&lt;p>以下内容均在 nginx.conf 文件中进行配置。&lt;/p>
&lt;h2 id="数据压缩">数据压缩&lt;/h2>
&lt;p>根据以上的配置，我们已经可以正常访问部署好的静态网页，但是根据开发者工具我们可以看到，首页的大小是 26.4 kB。我们还可以进一步进行优化，将所需要加载的数据进行压缩，使其所需数据量大大减少。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200911203709.png" alt="优化前" />&lt;/p>
&lt;p>在 http 部分中添加以下配置。&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">gzip on;
gzip_min_length 1;
gzip_comp_level 2;
gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x- httpd- php image/jpeg image/gif image/png;
&lt;/code>&lt;/pre>&lt;p>本例中所涉及到的配置释义如下。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>配置&lt;/th>
&lt;th>释义&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>gzip on | off&lt;/td>
&lt;td>是否启用数据压缩&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>gzip_min_length&lt;/td>
&lt;td>会被压缩的响应的最小长度（单位 kB），即返回内容大于此配置时才会被压缩&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>gzip_comp_level&lt;/td>
&lt;td>设置 gzip 压缩等级，等级越小压缩速度越快、文件压缩比越小。压缩等级范围是 1-9，压缩等级越高对性能要求越高。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>gzip_types&lt;/td>
&lt;td>设置需要压缩的 MIME 类型，非设置值不进行压缩，即匹配压缩类型&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;blockquote>
&lt;p>更多信息可以查看官方文档&lt;br>
&lt;a href="http://nginx.org/en/docs/http/ngx_http_gzip_module.html">http://nginx.org/en/docs/http/ngx_http_gzip_module.html&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>可以看到，开启 gzip 压缩后，加载的数据量大幅减少。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200911203017.png" alt="优化后" />&lt;/p>
&lt;h2 id="加载速度">加载速度&lt;/h2>
&lt;p>使用 limit_rate 可以对网页加载速度进行控制，详细如下。&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">server {
#...
set $limit_rate 1k;
#...
}
&lt;/code>&lt;/pre>&lt;p>其中，&lt;code>$limit_rate&lt;/code> 是控制访问速度的变量。后面紧跟的 &lt;code>1k&lt;/code> 是需要限制的速度，此例中的单位为 &lt;code>kB&lt;/code>，也可以设置其他单位，例如 &lt;code>1M&lt;/code>。&lt;/p>
&lt;blockquote>
&lt;p>更多信息可以查看官方文档&lt;br>
&lt;a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#var_limit_rate">http://nginx.org/en/docs/http/ngx_http_core_module.html#var_limit_rate&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="记录日志">记录日志&lt;/h2>
&lt;p>在 &lt;code>http&lt;/code> 模块中，可以配置日志记录的格式，以及日志记录的位置和文件名等等，配置如下。&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">http {
#...
log_format main '$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; '
'$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; '
'&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;';
access_log logs/sample.log main;
#...
}
&lt;/code>&lt;/pre>&lt;blockquote>
&lt;p>更多信息可以查看官方文档&lt;br>
&lt;a href="http://nginx.org/en/docs/http/ngx_http_log_module.html#access_log">http://nginx.org/en/docs/http/ngx_http_log_module.html#access_log&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h1 id="反向代理">反向代理&lt;/h1>
&lt;p>在此部分，我们使用两台 Nginx 服务器作为示例，分别是 &lt;code>192.168.61.128&lt;/code> 和 &lt;code>192.168.61.129&lt;/code>，简记为 CentOS_1 与 CentOS_2。&lt;/p>
&lt;p>修改 CentOS_1 的 Nginx 配置文件，修改部分如下，此时直接访问 &lt;code>192.168.61.128&lt;/code> 已经不能正常进行加载。&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">server {
listen 127.0.0.1:80;
server_name localhost;
#...
}
&lt;/code>&lt;/pre>&lt;p>修改 CentOS_2 的 Nginx 配置文件，修改部分如下，我们将 &lt;code>192.168.61.129:80&lt;/code> 指向了 &lt;code>192.168.61.128:80&lt;/code>。&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">upstream local {
server 192.168.61.128:80;
}
server {
listen 80;
server_name 192.168.61.129;
location / {
proxy_set_header Host $host:$server_port;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_pass http://local/;
}
#...
}
&lt;/code>&lt;/pre>&lt;p>分别在两台机器上重新加载 Nginx 配置文件，并访问 &lt;code>192.168.61.129:80&lt;/code>，此时可以正常打开 &lt;code>192.168.61.128:80&lt;/code> 上所配置的静态文件。&lt;/p>
&lt;blockquote>
&lt;p>上述配置可以参考官方文档&lt;br>
&lt;a href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_set_header">http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_set_header&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h1 id="日志可视化">日志可视化&lt;/h1>
&lt;p>在本例中，我们使用 GoAccess 首先日志试试可视化。&lt;/p>
&lt;h2 id="安装-goaccess">安装 GoAccess&lt;/h2>
&lt;p>由于此例中使用的系统是 CentOS 8，安装 GoAccess 之前需要先配置 epel 源。&lt;/p>
&lt;h3 id="配置-epel-源">配置 epel 源&lt;/h3>
&lt;ol>
&lt;li>安装 epel 配置包&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>yum install -y https://mirrors.aliyun.com/epel/epel-release-latest-8.noarch.rpm
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>将 repo 配置中的地址替换为阿里云镜像站地址&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>sed -i 's|^#baseurl=https://download.fedoraproject.org/pub|baseurl=https://mirrors.aliyun.com|' /etc/yum.repos.d/epel*
sed -i 's|^metalink|#metalink|' /etc/yum.repos.d/epel*
&lt;/code>&lt;/pre>&lt;h3 id="安装-geoip">安装 GeoIP&lt;/h3>
&lt;p>编译安装 GoAccess 需要用到 GeoIP。&lt;/p>
&lt;pre>&lt;code>sudo yum -y --enablerepo=epel install geoip
&lt;/code>&lt;/pre>&lt;h3 id="安装-goaccess-1">安装 GoAccess&lt;/h3>
&lt;p>根据官网的文档，我们顺序执行以下命令即可。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>wget https://tar.goaccess.io/goaccess-1.4.tar.gz
&lt;span class="ln">2&lt;/span>tar -xzvf goaccess-1.4.tar.gz
&lt;span class="ln">3&lt;/span>&lt;span class="nb">cd&lt;/span> goaccess-1.4/
&lt;span class="ln">4&lt;/span>./configure --enable-utf8 --enable-geoip&lt;span class="o">=&lt;/span>legacy
&lt;span class="ln">5&lt;/span>make
&lt;span class="ln">6&lt;/span>make install
&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装完成后，使用以下命令，若得到类似结果则表明安装成功。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>goaccess -v
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="ln">1&lt;/span>GoAccess - 1.4.
&lt;span class="ln">2&lt;/span>For more details visit: http://goaccess.io
&lt;span class="ln">3&lt;/span>Copyright (C) 2009-2020 by Gerardo Orellana
&lt;span class="ln">4&lt;/span>
&lt;span class="ln">5&lt;/span>Build configure arguments:
&lt;span class="ln">6&lt;/span> --enable-utf8
&lt;span class="ln">7&lt;/span> --enable-geoip=legacy
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="配置-goaccess">配置 GoAccess&lt;/h2>
&lt;p>在使用前，我们需要对 GoAccess 的配置文件进行一些修改，以方便后续使用。&lt;/p>
&lt;pre>&lt;code>vim /usr/local/etc/goaccess/goaccess.conf
&lt;/code>&lt;/pre>&lt;p>在此配置文件中，将以下内容取消注释，其他内容则保持不变。&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">#...
no-ip-validation true
log-format COMBINED
time-format %H:%M:%S
date-format %d/%b/%Y
real-time-html true
#...
&lt;/code>&lt;/pre>&lt;h2 id="启动监听">启动监听&lt;/h2>
&lt;p>在 Nginx 的 logs 目录中，我们以 access 为源文件，启动 GoAccess 进程后，会产生一个 websocket 长连接，持续监听客户端的请求数据，进而实时展现在 report.html 页面上。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /usr/local/nginx/logs
&lt;span class="ln">2&lt;/span>goaccess access.log -o ../html/report.html
&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时我们还需要修改 nginx.conf 使报告页面可以直接访问，在 server 部分添加如下内容。&lt;/p>
&lt;pre>&lt;code class="language-config" data-lang="config">location /report.html {
alias html/report.html;
}
&lt;/code>&lt;/pre>&lt;p>然后重新加载配置即可。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>nginx -s reload
&lt;/code>&lt;/pre>&lt;/div>&lt;p>至此，日志可视化已经配置完成，我们可以直接访问 Nginx &lt;code>服务地址/report.html&lt;/code> 查看可视化页面，如下。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200913143610.png" alt="20200913143610" />&lt;/p>
&lt;h1 id="附录">附录&lt;/h1>
&lt;p>Linux 查看端口占用状态&lt;/p>
&lt;h2 id="查看占用">查看占用&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>netstat -anp
&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中，参数 anp 分别表示：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>a：显示所有活动的 TCP 连接，以及正在监听的 TCP 和 UDP 端口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>n：以数字形式表示地址和端口号，不试图去解析其名称（number），参数 &lt;code>-n&lt;/code> 会将应用程序转为端口显示，即数字格式的地址，如：nfs-&amp;gt;2049，ftp-&amp;gt;21&lt;/p>
&lt;/li>
&lt;li>
&lt;p>p：列出与端口监听或连接相关的进程，即 pid&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="关闭占用">关闭占用&lt;/h2>
&lt;p>在本例中，若要关闭 GoAccess 建立的连接，首先执行如下命令拿到其 pid。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>netstat -anp &lt;span class="p">|&lt;/span> grep goaccess
&lt;/code>&lt;/pre>&lt;/div>&lt;p>结果如下。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="ln">1&lt;/span>tcp 0 0 0.0.0.0:7890 0.0.0.0:* LISTEN 2323/goaccess
&lt;span class="ln">2&lt;/span>tcp 0 0 192.168.61.128:7890 192.168.61.1:56503 ESTABLISHED 2323/goaccess
&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后手动 kill 其进程即可。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">kill&lt;/span> &lt;span class="m">2323&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>初识 Nginx</title><link>https://sudrizzz.github.io/posts/getting-to-know-nginx/</link><pubDate>Mon, 07 Sep 2020 15:47:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-nginx/</guid><description>&lt;h1 id="nginx-简介">Nginx 简介&lt;/h1>
&lt;blockquote>
&lt;p>简介内容来自 Nginx 官网 &lt;a href="http://nginx.org/en">http://nginx.org/en&lt;/a>&lt;/p>
&lt;p>nginx [engine x] is an HTTP and reverse proxy server, a mail proxy server, and a generic TCP/UDP proxy server, originally written by Igor Sysoev. For a long time, it has been running on many heavily loaded Russian sites including Yandex, Mail.Ru, VK, and Rambler. According to Netcraft, nginx served or proxied 25.75% busiest sites in August 2020. Here are some of the success stories: Dropbox, Netflix, Wordpress.com, FastMail.FM.&lt;/p>
&lt;p>The sources and documentation are distributed under the 2-clause BSD-like license.&lt;br>
Commercial support is available from Nginx, Inc.&lt;/p>
&lt;/blockquote>
&lt;p>简而言之，Nginx 是一个高性能的 HTTP 和反向代理服务器，特点是占有内存少，并发能力强。详细信息请查看 &lt;a class="link" href="http://nginx.org/en" target="_blank" rel="noopener"
>Nginx 官网介绍页面&lt;/a>。&lt;/p>
&lt;blockquote>
&lt;p>以下两种安装方式，任意选择一种进行安装即可。&lt;/p>
&lt;/blockquote>
&lt;h1 id="在线安装-nginx">在线安装 Nginx&lt;/h1>
&lt;p>注意，本篇文章基于 CentOS 8.2 版本，如使用其他系统，操作可能有一些变化，一切以&lt;a class="link" href="http://nginx.org/en/linux_packages.html" target="_blank" rel="noopener"
>官方网站安装教程&lt;/a>为准。&lt;/p>
&lt;p>首先我们需要先安装 yum-utils 包，执行以下命令即可。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo yum install yum-utils
&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后配置 Nginx 仓库，我们需要在 &lt;code>/etc/yum.repo.d/&lt;/code> 中创建一个名为 &lt;code>nginx.repo&lt;/code> 的文件，并填入以下内容。&lt;/p>
&lt;pre>&lt;code class="language-properties" data-lang="properties">[nginx-stable]
name=nginx stable repo
baseurl=http://nginx.org/packages/centos/$releasever/$basearch/
gpgcheck=1
enabled=1
gpgkey=https://nginx.org/keys/nginx_signing.key
module_hotfixes=true
[nginx-mainline]
name=nginx mainline repo
baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/
gpgcheck=1
enabled=0
gpgkey=https://nginx.org/keys/nginx_signing.key
module_hotfixes=true
&lt;/code>&lt;/pre>&lt;p>默认情况下使用的是 Nginx 稳定版仓库，即配置中的 &lt;code>nginx-stable&lt;/code>。如果需要使用主线版仓库，可以执行下面的命令进行手动指定。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo yum-config-manager --enable nginx-mainline
&lt;/code>&lt;/pre>&lt;/div>&lt;p>上述准备工作完成后，就可以开始安装 Nginx 了，执行下面这条命令即可。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo yum install nginx
&lt;/code>&lt;/pre>&lt;/div>&lt;p>稍等片刻完成安装后，可使用下述命令来验证是否安装成功。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>nginx -v
&lt;span class="ln">2&lt;/span>whereis nginx
&lt;/code>&lt;/pre>&lt;/div>&lt;p>得到类似于下面的输出，即代表安装成功。&lt;/p>
&lt;pre>&lt;code>nginx version: nginx/1.18.0
nginx: /usr/sbin/nginx /usr/lib64/nginx /etc/nginx /usr/share/nginx /usr/share/man/man8/nginx.8.gz
&lt;/code>&lt;/pre>&lt;h1 id="离线安装-nginx">离线安装 Nginx&lt;/h1>
&lt;h2 id="下载并解压">下载并解压&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /usr/local/software
&lt;span class="ln">2&lt;/span>
&lt;span class="ln">3&lt;/span>&lt;span class="c1"># 下载&lt;/span>
&lt;span class="ln">4&lt;/span>sudo wget http://nginx.org/download/nginx-1.18.0.tar.gz
&lt;span class="ln">5&lt;/span>
&lt;span class="ln">6&lt;/span>&lt;span class="c1"># 解压&lt;/span>
&lt;span class="ln">7&lt;/span>tar -zxvf nginx-1.18.0.tar.gz -C ./
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="编译">编译&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> nginx-1.18.0
&lt;span class="ln">2&lt;/span>sudo ./configure --prefix&lt;span class="o">=&lt;/span>/usr/local/nginx
&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中 &lt;code>--prefix&lt;/code> 的作用是指定编译后的文件存放位置，可以根据实际情况自由确定。&lt;br>
编译过程中可能会遇到一些报错，详细信息和解决方案如下。&lt;/p>
&lt;blockquote>
&lt;p>此部分内容参照文章 &lt;a class="link" href="https://www.cnblogs.com/crazylqy/p/6891929.html" target="_blank" rel="noopener"
>Nginx 教程(一) Nginx 入门教程&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>
&lt;p>./configure: error: C compiler cc is not found&lt;br>
错误原因：缺少编译环境，安装编译源码所需要的工具和库：&lt;br>
执行命令：sudo yum install gcc gcc-c++ ncurses-devel perl&lt;/p>
&lt;/li>
&lt;li>
&lt;p>./configure: error: the HTTP rewrite module requires the PCRE library&lt;br>
错误原因：缺少 HTTP rewrite module 模块&lt;br>
执行命令：sudo yum install pcre pcre-devel&lt;/p>
&lt;/li>
&lt;li>
&lt;p>./configure: error: the HTTP gzip module requires the zlib library&lt;br>
错误原因：缺少 HTTP zlib 类库，我们选择安装模块：&lt;br>
执行命令：sudo yum install zlib gzip zlib-devel&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>上述报错都解决了之后，再次执行编译命令，可以得到如下输出。&lt;/p>
&lt;pre>&lt;code>Configuration summary
+ using system PCRE library
+ OpenSSL library is not used
+ using system zlib library
nginx path prefix: &amp;quot;/usr/local/nginx&amp;quot;
nginx binary file: &amp;quot;/usr/local/nginx/sbin/nginx&amp;quot;
nginx modules path: &amp;quot;/usr/local/nginx/modules&amp;quot;
nginx configuration prefix: &amp;quot;/usr/local/nginx/conf&amp;quot;
nginx configuration file: &amp;quot;/usr/local/nginx/conf/nginx.conf&amp;quot;
nginx pid file: &amp;quot;/usr/local/nginx/logs/nginx.pid&amp;quot;
nginx error log file: &amp;quot;/usr/local/nginx/logs/error.log&amp;quot;
nginx http access log file: &amp;quot;/usr/local/nginx/logs/access.log&amp;quot;
nginx http client request body temporary files: &amp;quot;client_body_temp&amp;quot;
nginx http proxy temporary files: &amp;quot;proxy_temp&amp;quot;
nginx http fastcgi temporary files: &amp;quot;fastcgi_temp&amp;quot;
nginx http uwsgi temporary files: &amp;quot;uwsgi_temp&amp;quot;
nginx http scgi temporary files: &amp;quot;scgi_temp&amp;quot;
&lt;/code>&lt;/pre>&lt;h2 id="安装">安装&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /usr/local/software/nginx-1.18.0
&lt;span class="ln">2&lt;/span>sudo make &lt;span class="p">&amp;amp;&lt;/span> make install
&lt;/code>&lt;/pre>&lt;/div>&lt;p>得到如下输出时，即表明 Nginx 已经安装成功。&lt;/p>
&lt;pre>&lt;code>...
test -d '/usr/local/nginx/logs' \
|| mkdir -p '/usr/local/nginx/logs'
make[1]: 离开目录“/usr/local/software/nginx-1.18.0”
[1]+ 已完成 make
&lt;/code>&lt;/pre>&lt;h1 id="在线安装-nginx-的启动方式">在线安装 Nginx 的启动方式&lt;/h1>
&lt;blockquote>
&lt;p>如果是采用手动编译安装 Nginx 的方式，请跳过本节查看下一节内容。&lt;/p>
&lt;/blockquote>
&lt;h2 id="配置-nginxconf">配置 nginx.conf&lt;/h2>
&lt;p>首先编辑 &lt;code>/etc/nginx/nginx.conf&lt;/code> 文件，配置 Nginx 端口与访问地址（即 server 部分）。在配置端口时，不建议设置为 &lt;code>80&lt;/code>，以免与其他服务冲突。具体配置如下。&lt;/p>
&lt;pre>&lt;code>user nginx;
worker_processes 1;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;
events {
worker_connections 1024;
}
http {
include /etc/nginx/mime.types;
default_type application/octet-stream;
log_format main '$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; '
'$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; '
'&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;';
access_log /var/log/nginx/access.log main;
sendfile on;
#tcp_nopush on;
keepalive_timeout 65;
#gzip on;
include /etc/nginx/conf.d/*.conf;
# 在这里新增 server 配置
server {
listen 8090;
server_name localhost;
location / {
root html;
index index.html index.htm;
}
}
}
&lt;/code>&lt;/pre>&lt;h2 id="系统防火墙">系统防火墙&lt;/h2>
&lt;p>由于我的 CentOS 是安装在虚拟机中，未安装图形界面，故需要在宿主机上进行测试并访问虚拟机地址，所以需要增加一步禁用 CentOS 防火墙的操作，具体命令如下。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="c1"># 关闭防火墙&lt;/span>
&lt;span class="ln">2&lt;/span>systemctl stop firewalld.service
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="c1"># 禁止防火墙开机自启&lt;/span>
&lt;span class="ln">5&lt;/span>systemctl disable firewalld.service
&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在可以正式启动 Nginx 服务了，执行下述命令即可。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo nginx
&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行之后，可以使用下面命令检查是否启动成功，以及访问地址和端口是否生效。&lt;/p>
&lt;h2 id="查看包含-nginx-关键词的进程">查看包含 nginx 关键词的进程&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>ps -ef &lt;span class="p">|&lt;/span> grep nginx
&lt;/code>&lt;/pre>&lt;/div>&lt;p>结果如下，可以看到已经成功启动了。&lt;/p>
&lt;pre>&lt;code>root 4781 1 0 14:31 ? 00:00:00 nginx: master process nginx
nginx 5055 4781 0 14:36 ? 00:00:00 nginx: worker process
&lt;/code>&lt;/pre>&lt;h2 id="查看本机所有暴露的端口">查看本机所有暴露的端口&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>netstat -ntlp
&lt;/code>&lt;/pre>&lt;/div>&lt;p>结果如下，可以看到此前配置的 &lt;code>8090&lt;/code> 端口已经是 &lt;code>listen&lt;/code> 状态，接下来就可以在浏览器中访问了。&lt;/p>
&lt;pre>&lt;code>Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name
...
tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN -
tcp 0 0 0.0.0.0:8090 0.0.0.0:* LISTEN -
tcp 0 0 127.0.0.1:6010 0.0.0.0:* LISTEN -
...
&lt;/code>&lt;/pre>&lt;p>在浏览器中访问 &lt;code>虚拟机ip:8090&lt;/code>，即可看到 Nginx 的欢迎页面。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200906154034.png" alt="20200906154034" />&lt;/p>
&lt;blockquote>
&lt;p>此时返回 404 是因为 Nginx 目录中并没有欢迎页面的 html 文件，但依然可以说明已经 Nginx 服务已经配置正确并启动成功。&lt;/p>
&lt;/blockquote>
&lt;h1 id="离线安装-nginx-的启动方式">离线安装 Nginx 的启动方式&lt;/h1>
&lt;p>首先执行下述命令来启动 Nginx。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> /usr/local/nginx/sbin
&lt;span class="ln">2&lt;/span>sudo ./nginx
&lt;/code>&lt;/pre>&lt;/div>&lt;p>同样的，我们可以按照上一节中介绍的方法，来验证 Nginx 是否启动成功，以及端口是否开放。&lt;br>
Nginx 服务默认的端口是 &lt;code>80&lt;/code>，如果需要修改端口，也可以参照上一节中的内容进行手动修改，略有不同的是，通过手动编译安装的 Nginx，配置文件地址在 &lt;code>/usr/local/nginx/conf/nginx.conf&lt;/code>，也就是编译时我们手动指定的路径下。
其余内容此处皆不再赘述。&lt;/p>
&lt;p>打开宿主机浏览器，访问 &lt;code>虚拟机ip:80&lt;/code>，就可以看到 Nginx 的欢迎页面。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200906153613.png" alt="20200906153613" />&lt;/p>
&lt;h1 id="修改-nginxconf">修改 nginx.conf&lt;/h1>
&lt;p>如果后续需要修改 &lt;code>nginx.conf&lt;/code> 中的内容，例如更改 Nginx 服务端口号，请务必在修改完成后重启服务。常用的 Nginx 命令如下。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="c1"># 检查 nginx.conf 是否配置正确&lt;/span>
&lt;span class="ln">2&lt;/span>sudo nginx -t
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="c1"># 重启 Nginx 服务&lt;/span>
&lt;span class="ln">5&lt;/span>sudo nginx -s reload
&lt;span class="ln">6&lt;/span>
&lt;span class="ln">7&lt;/span>&lt;span class="c1"># 停止 Nginx 服务&lt;/span>
&lt;span class="ln">8&lt;/span>sudo nginx -s stop
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="附录">附录&lt;/h1>
&lt;p>在 Linux 中查找某一个具体文件路径时，可以使用以下命令。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo find / -name filename
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>/&lt;/code> 代表查找的目录，此例是根目录&lt;/li>
&lt;li>&lt;code>-name&lt;/code> 代表按照文件名进行查找&lt;/li>
&lt;li>&lt;code>filename&lt;/code> 代表具体的文件名，例如 &lt;code>nginx.conf&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>以本文章为例，在根目录中查找 &lt;code>nginx.conf&lt;/code> 的结果如下。&lt;/p>
&lt;pre>&lt;code>/etc/nginx/nginx.conf
/usr/local/software/nginx-1.18.0/conf/nginx.conf
/usr/local/nginx/conf/nginx.conf
&lt;/code>&lt;/pre></description></item><item><title>CMU 15-213 位、字节与整数</title><link>https://sudrizzz.github.io/posts/cmu-15-213-lesson1/</link><pubDate>Fri, 04 Sep 2020 19:02:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/cmu-15-213-lesson1/</guid><description>&lt;h1 id="简介">简介&lt;/h1>
&lt;p>CSAPP 课程全程 Computer Systems: A Programmer’s Perspective，中文翻译为“从程序员的视角，看计算机系统！”或“深入理解计算机系统”。此课程是卡耐基梅隆大学开设的一门课程，官方网站 &lt;a href="https://www.cs.cmu.edu/~213/index.html">https://www.cs.cmu.edu/~213/index.html&lt;/a>。&lt;/p>
&lt;blockquote>
&lt;p>内容简介节选自豆瓣&lt;br>
&lt;a href="https://book.douban.com/subject/1230413">https://book.douban.com/subject/1230413&lt;/a>&lt;/p>
&lt;p>从程序员的视角，看计算机系统！&lt;/p>
&lt;p>本书适用于那些想要写出更快、更可靠程序的程序员。通过掌握程序是如何映射到系统上，以及程序是如何执行的，读者能够更好的理解程序的行为为什么是这样的，以及效率低下是如何造成的。粗略来看，计算机系统包括处理器和存储器硬件、编译器、操作系统和网络互连环境。而通过程序员的视角，读者可以清晰地明白学习计算机系统的内部工作原理会对他们今后作为计算机科学研究者和工程师的工作有进一步的帮助。它还有助于为进一步学习计算机体系结构、操作系统、编译器和网络互连做好准备。&lt;/p>
&lt;/blockquote>
&lt;h1 id="一切皆位">一切皆位&lt;/h1>
&lt;h2 id="十进制">十进制&lt;/h2>
&lt;p>在计算机发展历史上，实际上只有宾夕法尼亚大学建立的第一台计算机 ENIAC 使用了十进制进行了算术运算，他们使用 10 个电子管来表示每个数字。所以他们通过控制电子管的开关来表示 10 个数字中的其中一个。&lt;/p>
&lt;h2 id="二进制">二进制&lt;/h2>
&lt;p>随着计算机的发展，十进制逐渐演化为二进制。在计算机中，我们使用电学层面上的电压高低来存储位数据，如图所示，高电压（0.9v-1.1v）记作逻辑 1，而低电压（0.0v-0.2v）记作逻辑 0。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200904184249.png" alt="20200904184249" />&lt;/p>
&lt;p>之所以这么做，是因为通过区分高低电压，可以有效地过滤噪声和杂讯。&lt;/p>
&lt;h2 id="十六进制">十六进制&lt;/h2>
&lt;p>二进制的成功运用也带来了一个问题，由于每一个位只能存储两种信号（即 0 和 1），对于人来说基本属于不可读的，所以我们将每四个二进制在位合并为一个十六进制位，这样大大缩减了数据的展示长度。例如&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200904185017.png" alt="20200904185017" />&lt;/p>
&lt;h2 id="具体数据类型实际所占空间">具体数据类型实际所占空间&lt;/h2>
&lt;p>此处以 C 语言数据类型为例，因为在 32 位与 64 位机器上所占空间不尽相同，故列下表。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>C Data Type&lt;/th>
&lt;th>Typical 32-bit&lt;/th>
&lt;th>Typical 64-bit&lt;/th>
&lt;th>x86-64&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>char&lt;/td>
&lt;td>1&lt;/td>
&lt;td>1&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>short&lt;/td>
&lt;td>2&lt;/td>
&lt;td>2&lt;/td>
&lt;td>2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>int&lt;/td>
&lt;td>4&lt;/td>
&lt;td>4&lt;/td>
&lt;td>4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>long&lt;/td>
&lt;td>4&lt;/td>
&lt;td>8&lt;/td>
&lt;td>8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>float&lt;/td>
&lt;td>4&lt;/td>
&lt;td>4&lt;/td>
&lt;td>4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>double&lt;/td>
&lt;td>8&lt;/td>
&lt;td>8&lt;/td>
&lt;td>8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>pointer&lt;/td>
&lt;td>4&lt;/td>
&lt;td>8&lt;/td>
&lt;td>8&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="位操作">位操作&lt;/h1>
&lt;h2 id="与或非异或">与、或、非、异或&lt;/h2>
&lt;p>通俗的解释如下：&lt;/p>
&lt;ol>
&lt;li>与（&amp;amp;）：两者都为真时，结果为真，否则为假；&lt;/li>
&lt;li>或（|）：任意一者为真时，结果为真，否则为假；&lt;/li>
&lt;li>非（~）：对元素取反；&lt;/li>
&lt;li>异或（^）：两者性质相同时，结果为假，否则为真。&lt;/li>
&lt;/ol>
&lt;p>详细示例见下图。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200904185942.png" alt="20200904185942" />&lt;/p>
&lt;h2 id="与集合的关系">与集合的关系&lt;/h2>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200904190420.png" alt="20200904190420" />&lt;/p>
&lt;p>我们将二进制数据从右往左标记位置，红色数字位置代表该为值为 1，右侧集合中数据代表该二进制数据中所有位值为 1 的位置。例如第一个数据 01101001，从右往左计数，第 0、3、5、6 位对应值为 1。对第二个数进行同样的处理。&lt;/p>
&lt;p>此时我们对两个数据进行与、或、非、异或操作时，可以得出下述结论。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>数据操作&lt;/th>
&lt;th>对应集合操作&lt;/th>
&lt;th>结果数据&lt;/th>
&lt;th>结果集合&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&amp;amp;&lt;/td>
&lt;td>交集&lt;/td>
&lt;td>1000001&lt;/td>
&lt;td>{0, 6}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>|&lt;/td>
&lt;td>并集&lt;/td>
&lt;td>1111101&lt;/td>
&lt;td>{0, 2, 3, 4, 5, 6}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>^&lt;/td>
&lt;td>差集&lt;/td>
&lt;td>111100&lt;/td>
&lt;td>{2, 3, 4, 5}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>~&lt;/td>
&lt;td>补集&lt;/td>
&lt;td>10101010&lt;/td>
&lt;td>{1, 3, 5, 7}&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="移位">移位&lt;/h2>
&lt;h3 id="左移-x--y">左移 x &amp;laquo; y&lt;/h3>
&lt;p>左移即将二进数据 x 整体向左移动 y 个位置，并在其右侧补 0。例如&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>结果&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>元素 x&lt;/td>
&lt;td>01100010&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;laquo; 3&lt;/td>
&lt;td>00010&lt;em>000&lt;/em>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="右移-x--y">右移 x &amp;raquo; y&lt;/h3>
&lt;p>与左移一样，右移即将二进数据 x 整体向右移动 y 个位置，并在其空缺位填充相应数据。而右移又分为逻辑右移和算数右移，具体区别如下。&lt;/p>
&lt;h4 id="逻辑右移">逻辑右移&lt;/h4>
&lt;p>在逻辑右移过程中，需要在其左侧空缺位置补 0。例如&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>结果&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>元素 x&lt;/td>
&lt;td>01100010&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;raquo; 2&lt;/td>
&lt;td>&lt;em>00&lt;/em>101000&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="算术右移">算术右移&lt;/h4>
&lt;p>在算术右移过程中，需要在其左侧空缺位置补 1。例如&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>结果&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>元素 x&lt;/td>
&lt;td>01100010&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;raquo; 2&lt;/td>
&lt;td>&lt;em>11&lt;/em>101000&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="无符号数与补码">无符号数与补码&lt;/h1>
&lt;p>无符号数的表达形式：&lt;br>
$$ B2U(X) = \sum_{i=0}^{w-1}x_{i} \cdot 2^{i} $$&lt;/p>
&lt;p>补码的表达形式：&lt;br>
$$ B2T(X) = -x_{w-1}\cdot 2^{w-1}+\sum_{i=0}^{w-2}x_{i}\cdot 2^{i} $$&lt;/p>
&lt;p>在补码中，最高值为 1 时，始终代表 -1，例如：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200904192825.png" alt="20200904192825" />&lt;/p>
&lt;p>有了补码，计算机就可正常表示负数。例如：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>十进制&lt;/th>
&lt;th>十六进制&lt;/th>
&lt;th>二进制&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>x&lt;/td>
&lt;td>15213&lt;/td>
&lt;td>3B 6D&lt;/td>
&lt;td>00111011 01101101&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>y&lt;/td>
&lt;td>-15213&lt;/td>
&lt;td>C4 93&lt;/td>
&lt;td>11000100 10010011&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="数据范围">数据范围&lt;/h2>
&lt;p>此处我们以 16 位二进制数（即 w=16）来探讨无符号数和补码的范围，如下表。
其中，UMax 代表无符号数最大值，TMax 代表补码最大值，TMin 代表补码最小值。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>十进制&lt;/th>
&lt;th>十六进制&lt;/th>
&lt;th>二进制&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>UMax&lt;/td>
&lt;td>65535&lt;/td>
&lt;td>FF FF&lt;/td>
&lt;td>11111111 11111111&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TMax&lt;/td>
&lt;td>32767&lt;/td>
&lt;td>7F FF&lt;/td>
&lt;td>01111111 11111111&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TMin&lt;/td>
&lt;td>-32768&lt;/td>
&lt;td>80 00&lt;/td>
&lt;td>10000000 00000000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>-1&lt;/td>
&lt;td>-1&lt;/td>
&lt;td>FF FF&lt;/td>
&lt;td>11111111 11111111&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>0&lt;/td>
&lt;td>0&lt;/td>
&lt;td>00 00&lt;/td>
&lt;td>00000000 00000000&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>当数据的位宽 w 发生变化时，代表的数据最值也会发生相应的变化，如下表。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>8 位&lt;/th>
&lt;th>16 位&lt;/th>
&lt;th>32 位&lt;/th>
&lt;th>64 位&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>UMax&lt;/td>
&lt;td>255&lt;/td>
&lt;td>65,535&lt;/td>
&lt;td>4,294,967,295&lt;/td>
&lt;td>18,446,744,073,709,551,615&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TMax&lt;/td>
&lt;td>127&lt;/td>
&lt;td>32,767&lt;/td>
&lt;td>2,147,483,647&lt;/td>
&lt;td>9,223,372,036,854,775,807&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TMin&lt;/td>
&lt;td>-128&lt;/td>
&lt;td>-32,768&lt;/td>
&lt;td>-2,147,483,648&lt;/td>
&lt;td>-9,223,372,036,854,775,808&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>根据以上性质，我们可以得出以下结论：&lt;/p>
&lt;p>$$ |TMin| = TMax + 1 $$&lt;/p>
&lt;p>$$ UMax = 2 * TMax + 1 $$&lt;/p>
&lt;h2 id="补码形式转换为无符号数">补码形式转换为无符号数&lt;/h2>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200905104914.png" alt="20200905104914" />&lt;/p>
&lt;h1 id="有符号数扩充">有符号数扩充&lt;/h1>
&lt;p>已知一个 w 位的有符号数 X，现在需要将其转换为 w+k 位相同值的有符号数，可以按照下述步骤进行操作。&lt;/p>
&lt;ol>
&lt;li>将符号标识位（sign bit）拷贝 k 份，填充到扩充的 k 个位置上；&lt;/li>
&lt;li>此时 X 就可以按位表示为&lt;/li>
&lt;/ol>
&lt;p>$$ X^{'} = \underbrace{X_{w-1},&amp;hellip;, X_{w-1}}_{k 个符号位拷贝}, X_{w-1}, X_{w-2},&amp;hellip;, X_{0} $$&lt;/p>
&lt;p>详细信息如下图所示：&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200905110036.png" alt="20200905110036" />&lt;/p>
&lt;h2 id="示例">示例&lt;/h2>
&lt;p>定义两个 &lt;code>short&lt;/code> 变量 x 与 y，将其分别扩充为 &lt;code>int&lt;/code> 变量，得到 ix 与 iy，详细结果如下。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="ln">1&lt;/span>&lt;span class="kt">short&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">15213&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">2&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">ix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">3&lt;/span>&lt;span class="kt">short&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">15213&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">iy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th style="text-align:right">十进制&lt;/th>
&lt;th style="text-align:right">十六进制&lt;/th>
&lt;th style="text-align:right">二进制&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>x&lt;/td>
&lt;td style="text-align:right">15213&lt;/td>
&lt;td style="text-align:right">3B 6D&lt;/td>
&lt;td style="text-align:right">00111011 01101101&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ix&lt;/td>
&lt;td style="text-align:right">15213&lt;/td>
&lt;td style="text-align:right">00 00 3B 6D&lt;/td>
&lt;td style="text-align:right">00000000 00000000 00111011 01101101&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>y&lt;/td>
&lt;td style="text-align:right">-15213&lt;/td>
&lt;td style="text-align:right">C4 93&lt;/td>
&lt;td style="text-align:right">11000100 10010011&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>iy&lt;/td>
&lt;td style="text-align:right">-15213&lt;/td>
&lt;td style="text-align:right">FF FF C4 93&lt;/td>
&lt;td style="text-align:right">11111111 11111111 11000100 10010011&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="移位实现-2-的次方倍算术操作">移位实现 2 的次方倍算术操作&lt;/h1>
&lt;h2 id="乘法">乘法&lt;/h2>
&lt;p>给定一个整数 u，其 2 的次方倍乘法操作相对简单，且对于无符号数和有符号数都是统一的操作，即将数据的二进制位向左移动，再将移动产生的多余位进行舍弃，剩余位即最终结果。也即&lt;/p>
&lt;p>$$ u &amp;laquo; k = u * 2^{k} $$&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200905111913.png" alt="20200905111913" />&lt;/p>
&lt;h2 id="除法">除法&lt;/h2>
&lt;h3 id="无符号数">无符号数&lt;/h3>
&lt;p>给定一个无符号数 u，对其做 2 的次方倍除法，相当于将其二进制位向右进行逻辑移位，再将小数部分进行舍弃（向下取整），剩余位即最终结果。也即&lt;/p>
&lt;p>$$ u &amp;raquo; k = \lfloor u / 2^{k} \rfloor $$&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200905112056.png" alt="20200905112056" />&lt;/p>
&lt;p>例如：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th style="text-align:right">算术除法&lt;/th>
&lt;th style="text-align:right">计算结果&lt;/th>
&lt;th style="text-align:right">十六进制&lt;/th>
&lt;th>二进制&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>x&lt;/td>
&lt;td style="text-align:right">15213&lt;/td>
&lt;td style="text-align:right">15213&lt;/td>
&lt;td style="text-align:right">3B 6D&lt;/td>
&lt;td>00111011 01101101&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>x &amp;raquo; 1&lt;/td>
&lt;td style="text-align:right">7606.5&lt;/td>
&lt;td style="text-align:right">7606&lt;/td>
&lt;td style="text-align:right">1D B6&lt;/td>
&lt;td>00011101 10110110&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>x &amp;raquo; 4&lt;/td>
&lt;td style="text-align:right">950.8125&lt;/td>
&lt;td style="text-align:right">950&lt;/td>
&lt;td style="text-align:right">03 B6&lt;/td>
&lt;td>00000011 10110110&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>x &amp;raquo; 8&lt;/td>
&lt;td style="text-align:right">59.4257813&lt;/td>
&lt;td style="text-align:right">59&lt;/td>
&lt;td style="text-align:right">00 3B&lt;/td>
&lt;td>00000000 00111011&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="有符号数">有符号数&lt;/h3>
&lt;p>给定一个有符号数 x，对其做 2 的次方倍除法，相当于将其二进制位向右进行算术移位，再将小数部分进行舍弃（向下取整），剩余位即最终结果。也即&lt;/p>
&lt;p>$$ x &amp;raquo; k = \lfloor x / 2^{k} \rfloor $$&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200905112700.png" alt="20200905112700" />&lt;/p>
&lt;p>例如：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th style="text-align:right">算术除法&lt;/th>
&lt;th style="text-align:right">计算结果&lt;/th>
&lt;th style="text-align:right">十六进制&lt;/th>
&lt;th>二进制&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>y&lt;/td>
&lt;td style="text-align:right">-15213&lt;/td>
&lt;td style="text-align:right">-15213&lt;/td>
&lt;td style="text-align:right">C4 93&lt;/td>
&lt;td>11000100 10010011&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>y &amp;raquo; 1&lt;/td>
&lt;td style="text-align:right">-7606.5&lt;/td>
&lt;td style="text-align:right">-7607&lt;/td>
&lt;td style="text-align:right">E2 49&lt;/td>
&lt;td>&lt;em>1&lt;/em>1100010 01001001&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>y &amp;raquo; 4&lt;/td>
&lt;td style="text-align:right">-950.8125&lt;/td>
&lt;td style="text-align:right">-951&lt;/td>
&lt;td style="text-align:right">FC 49&lt;/td>
&lt;td>&lt;em>1111&lt;/em>1100 01001001&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>y &amp;raquo; 8&lt;/td>
&lt;td style="text-align:right">-59.4257813&lt;/td>
&lt;td style="text-align:right">-60&lt;/td>
&lt;td style="text-align:right">FF C4&lt;/td>
&lt;td>&lt;em>11111111&lt;/em> 11000100&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>初识 Docker</title><link>https://sudrizzz.github.io/posts/getting-to-know-docker/</link><pubDate>Wed, 02 Sep 2020 18:37:11 +0800</pubDate><guid>https://sudrizzz.github.io/posts/getting-to-know-docker/</guid><description>&lt;h1 id="docker-简介">Docker 简介&lt;/h1>
&lt;p>简介来自于 &lt;a class="link" href="http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html" target="_blank" rel="noopener"
>Docker 入门教程 - 阮一峰的网络日志&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。&lt;/p>
&lt;p>Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。&lt;/p>
&lt;p>总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。&lt;/p>
&lt;/blockquote>
&lt;h1 id="安装-docker">安装 Docker&lt;/h1>
&lt;p>在此部分，作者使用的是 Centos 8.2 进行的操作，下述的安装命令仅保证在该环境下运行。&lt;/p>
&lt;h2 id="设置-docker-仓库">设置 Docker 仓库&lt;/h2>
&lt;p>根据官方教程，执行以下两条命令：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo yum install -y yum-utils
&lt;span class="ln">2&lt;/span>
&lt;span class="ln">3&lt;/span>sudo yum-config-manager &lt;span class="se">\
&lt;/span>&lt;span class="ln">4&lt;/span>&lt;span class="se">&lt;/span> --add-repo &lt;span class="se">\
&lt;/span>&lt;span class="ln">5&lt;/span>&lt;span class="se">&lt;/span> http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code>&lt;/pre>&lt;/div>&lt;p>由于国内直接连接 Docker 官方镜像源十分缓慢，所以在第二个命令中将官方镜像源替换为阿里云镜像源。&lt;/p>
&lt;h2 id="安装-docker-引擎">安装 Docker 引擎&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo yum install docker-ce docker-ce-cli containerd.io
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在执行这条命令时，极有可能会报错。比如作者遇到的报错如下：&lt;/p>
&lt;pre>&lt;code>Error:
Problem: package docker-ce-3:19.03.8-3.el7.x86_64 requires containerd.io &amp;gt;= 1.2.2-3, but none of the providers can be installed
- cannot install the best candidate for the job
- package containerd.io-1.2.10-3.2.el7.x86_64 is excluded
- package containerd.io-1.2.13-3.1.el7.x86_64 is excluded
- package containerd.io-1.2.2-3.3.el7.x86_64 is excluded
- package containerd.io-1.2.2-3.el7.x86_64 is excluded
- package containerd.io-1.2.4-3.1.el7.x86_64 is excluded
- package containerd.io-1.2.5-3.1.el7.x86_64 is excluded
- package containerd.io-1.2.6-3.3.el7.x86_64 is excluded
&lt;/code>&lt;/pre>&lt;p>为了解决这个报错，需要先执行下述命令安装好 containerd.io 组件。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo yum install -y &lt;span class="se">\
&lt;/span>&lt;span class="ln">2&lt;/span>&lt;span class="se">&lt;/span> https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/edge/Packages/containerd.io-1.2.13-3.2.el7.x86_64.rpm
&lt;span class="ln">3&lt;/span>
&lt;span class="ln">4&lt;/span>sudo yum -y install ./containerd.io-1.2.13-3.1.el7.x86_64.rpm
&lt;/code>&lt;/pre>&lt;/div>&lt;p>至于为什么安装的 containerd.io 组件是 centos 7 目录下的，有两个原因：&lt;/p>
&lt;ol>
&lt;li>此版本在 centos 8 环境下也可以正常使用；&lt;/li>
&lt;li>阿里云官方只提供了适配 centos 7 的 containerd.io 组件。&lt;/li>
&lt;/ol>
&lt;p>然后重新执行上述命令即可完成 Docker 的安装。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo yum install docker-ce docker-ce-cli
&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们可以通过两个命令来验证 Docker 是否安装成功。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>docker version
&lt;span class="ln">2&lt;/span>&lt;span class="c1"># 或&lt;/span>
&lt;span class="ln">3&lt;/span>docker info
&lt;/code>&lt;/pre>&lt;/div>&lt;p>若输出类似于以下的内容，则配置正确。&lt;/p>
&lt;pre>&lt;code>[root@localhost ~]# docker version
Client: Docker Engine - Community
Version: 19.03.12
API version: 1.40
Go version: go1.13.10
Git commit: 48a66213fe
Built: Mon Jun 22 15:46:54 2020
OS/Arch: linux/amd64
Experimental: false
Server: Docker Engine - Community
Engine:
Version: 19.03.12
API version: 1.40 (minimum version 1.12)
Go version: go1.13.10
Git commit: 48a66213fe
Built: Mon Jun 22 15:45:28 2020
OS/Arch: linux/amd64
Experimental: false
containerd:
Version: 1.2.6
GitCommit: 894b81a4b802e4eb2a91d1ce216b8817763c29fb
runc:
Version: 1.0.0-rc8
GitCommit: 425e105d5a03fabd737a126ad93d62a9eeede87f
docker-init:
Version: 0.18.0
GitCommit: fec3683
&lt;/code>&lt;/pre>&lt;h1 id="配置-docker-仓库">配置 Docker 仓库&lt;/h1>
&lt;p>由于在国内连接 Docker 官方仓库 &lt;a href="https://hub.docker.com">https://hub.docker.com&lt;/a> 十分缓慢，故我们可以将仓库地址更换为国内的各种源，详细步骤如下。&lt;/p>
&lt;ol>
&lt;li>在 &lt;code>/etc/docker&lt;/code> 目录中新增一个名为 &lt;code>daemon.json&lt;/code> 的配置文件，如果已经存在这个文件，则只需要进行修改。&lt;/li>
&lt;li>将该文件中的 &lt;code>registry-mirrors&lt;/code> 项修改为如下形式。&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="ln">1&lt;/span>&lt;span class="p">{&lt;/span>
&lt;span class="ln">2&lt;/span> &lt;span class="nt">&amp;#34;registry-mirrors&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="ln">3&lt;/span> &lt;span class="s2">&amp;#34;https://kuamavit.mirror.aliyuncs.com&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="s2">&amp;#34;https://docker.mirrors.ustc.edu.cn&amp;#34;&lt;/span>
&lt;span class="ln">5&lt;/span> &lt;span class="p">]&lt;/span>
&lt;span class="ln">6&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>到此就配置完毕了。&lt;/p>
&lt;h1 id="启动并运行-docker">启动并运行 Docker&lt;/h1>
&lt;h2 id="启动">启动&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>$ sudo service docker start
&lt;span class="ln">2&lt;/span>&lt;span class="c1"># 或&lt;/span>
&lt;span class="ln">3&lt;/span>$ sudo systemctl start docker
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="运行-hello-world">运行 hello-world&lt;/h2>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo docker run hello-world
&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时，由于本地尚未安装 hello-world 实例，Docker 会自动从上文中配置的镜像中拉取 hello-world 实例，然后运行这个实例。具体输出如下。&lt;/p>
&lt;pre>&lt;code>[root@localhost docker]# docker run hello-world
# 这里提示未在本地找到 hello-world 实例，将从镜像中拉取最新版。
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
0e03bdcc26d7: Pull complete
Digest: sha256:7f0a9f93b4aa3022c3a4c147a449bf11e0941a1fd0bf4a8e6c9408b2600777c5
Status: Downloaded newer image for hello-world:latest
# 开始运行
Hello from Docker!
This message shows that your installation appears to be working correctly.
To generate this message, Docker took the following steps:
1. The Docker client contacted the Docker daemon.
2. The Docker daemon pulled the &amp;quot;hello-world&amp;quot; image from the Docker Hub.
(amd64)
3. The Docker daemon created a new container from that image which runs the
executable that produces the output you are currently reading.
4. The Docker daemon streamed that output to the Docker client, which sent it
to your terminal.
To try something more ambitious, you can run an Ubuntu container with:
$ docker run -it ubuntu bash
Share images, automate workflows, and more with a free Docker ID:
https://hub.docker.com/
For more examples and ideas, visit:
https://docs.docker.com/get-started/
&lt;/code>&lt;/pre>&lt;h1 id="容器管理">容器管理&lt;/h1>
&lt;p>当 image 文件开始运行之后，就会生成一个容器实例，容器实例实际上也是一个文件，故也称为实例文件。当容器实例停止运行时，容器文件并不会被删除。&lt;/p>
&lt;ol>
&lt;li>列出本机正在运行的容器&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo docker container ls
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>列出本机所有容器（包括已停止运行的）&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo docker container ls -all
&lt;/code>&lt;/pre>&lt;/div>&lt;p>输出结果如下。&lt;/p>
&lt;pre>&lt;code>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
d3a382fde773 hello-world &amp;quot;/hello&amp;quot; 8 minutes ago Exited (0) 8 minutes ago romantic_proskuriakova
&lt;/code>&lt;/pre>&lt;p>其中 &lt;code>CONTAINER ID&lt;/code> 就是该容器的唯一标识符，在后续的终止容器运行时需要用到。&lt;/p>
&lt;ol start="3">
&lt;li>终止容器运行&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo docker container &lt;span class="nb">kill&lt;/span> d3a382fde773
&lt;/code>&lt;/pre>&lt;/div>&lt;p>当然本例中 hello-world 容器已经停止运行了，所以不能再次停止，此处仅做示例。
即使一个容器文件已经停止运行，但是其依然会占据磁盘空间，可以使用下述命令进行删除。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo docker container rm d3a382fde773
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="镜像管理">镜像管理&lt;/h1>
&lt;p>当我们拉取了多个镜像，其中某些又不需要使用了，则需要对镜像进行手动管理，详细操作如下。&lt;/p>
&lt;ol>
&lt;li>罗列所有本地已经安装的镜像&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo docker image ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>输出如下&lt;/p>
&lt;pre>&lt;code>REPOSITORY TAG IMAGE ID CREATED SIZE
hello-world latest bf756fb1ae65 8 months ago 13.3kB
&lt;/code>&lt;/pre>&lt;ol start="2">
&lt;li>移除不需要的镜像&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>sudo docker image rm hello-world
&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意，如果 image 在运行，或者已经生成了实例文件，是不能直接删除的，需要先将实例容器停止并删除实例文件，才可以正常删除。执行结果如下。&lt;/p>
&lt;pre>&lt;code>Untagged: hello-world:latest
Untagged: hello-world@sha256:7f0a9f93b4aa3022c3a4c147a449bf11e0941a1fd0bf4a8e6c9408b2600777c5
Deleted: sha256:bf756fb1ae65adf866bd8c456593cd24beb6a0a061dedf42b26a993176745f6b
Deleted: sha256:9c27e219663c25e0f28493790cc0b88bc973ba3b1686355f221c38a36978ac63
&lt;/code>&lt;/pre></description></item><item><title>Github 自动部署与图床</title><link>https://sudrizzz.github.io/posts/integrating-with-github-action/</link><pubDate>Sun, 09 Aug 2020 15:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/integrating-with-github-action/</guid><description>&lt;h1 id="前情提要">前情提要&lt;/h1>
&lt;p>在前文中我们实现了在 Github 中部署博客，此文将简化发文操作步骤，并实现文章图片管理。&lt;/p>
&lt;h1 id="创建仓库">创建仓库&lt;/h1>
&lt;blockquote>
&lt;p>注意：&lt;br>
由于 &lt;code>username&lt;/code> 不方便叙述，故下文中均以 &lt;code>sudrizzz&lt;/code> 为例替代 &lt;code>username&lt;/code>，&lt;br>
请读者根据实际情况进行更改。&lt;/p>
&lt;/blockquote>
&lt;p>在上文中我们已经创建了一个名为 &lt;code>&amp;lt;username&amp;gt;.github.io&lt;/code> 的仓库，现在还需要创建另一个仓库来存放文章管理文件。仓库名任意，公有与私有均可。另外，还需要创建一个仓库来存储文章中涉及到的图片，仓库名任意，但必须是&lt;strong>公有&lt;/strong>的。本例中，我们所用到的仓库名如下。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>仓库名&lt;/th>
&lt;th>用途&lt;/th>
&lt;th>公有或私有&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>blog_workflow&lt;/td>
&lt;td>存储博客中文章或者主题等原始文件&lt;/td>
&lt;td>私有&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>sudrizzz.github.io&lt;/td>
&lt;td>存储 Hugo 生成的静态文件&lt;/td>
&lt;td>公有&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>blog_images&lt;/td>
&lt;td>存储图片文件&lt;/td>
&lt;td>公有&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="拆分文件">拆分文件&lt;/h1>
&lt;p>上文中我们只是将 &lt;code>/public&lt;/code> 文件夹提交到了 &lt;code>sudrizzz.github.io&lt;/code> 仓库，现在我们还需要将除了 &lt;code>/public&lt;/code> 以外的文件全部提交到 &lt;code>blog_workflow&lt;/code>，实现这一步可以再本地建立两个对应的文件夹，分别进行提交，操作步骤不再赘述。拆分后的目录结构如下。&lt;/p>
&lt;pre>&lt;code>blog_workflow 仓库
├─archetypes
├─content
│ └─cn
│ └─posts
├─layouts
├─resources
│ └─_gen
└─themes
└─yinyang
├─...
sudrizzz.github.io 仓库
├─categories
│ └─test
├─css
│ └─highlight
├─fonts
├─images
├─js
├─posts
│ └─test
└─tags
&lt;/code>&lt;/pre>&lt;h1 id="配置公私密钥">配置公私密钥&lt;/h1>
&lt;h2 id="生成密钥">生成密钥&lt;/h2>
&lt;p>打开 Git Bash，执行如下命令&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>ssh-keygen -t rsa -b &lt;span class="m">4096&lt;/span> -C &lt;span class="s2">&amp;#34;sudrizzz.github.io&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>设置密钥存储位置，按照提示进行操作，不需要自定义一路回车即可。&lt;/p>
&lt;pre>&lt;code>Generating public/private rsa key pair.
Enter file in which to save the key (/c/Users/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /c/Users/.ssh/deploy.
Your public key has been saved in /c/Users/.ssh/deploy.pub.
The key fingerprint is:
SHA256:MpU2IEDuvNADO1AVWrQx/3HMAECYw+C3taw+5Fyy2F4 sudrizzz.github.io
The key's randomart image is:
+---[RSA 4096]----+
|.++B@oo.. |
|.o=o * . = |
|o.oo... * + |
|.*. + .+ + |
|+ =. oo S |
| o =.. o |
| B.+E |
| ..*. |
| .o. |
+----[SHA256]-----+
&lt;/code>&lt;/pre>&lt;p>生成的密钥文件放置在 &lt;code>c/Users/&amp;lt;user&amp;gt;/.ssh/&lt;/code> 文件夹中，分别是&lt;/p>
&lt;ul>
&lt;li>id_rsa&lt;/li>
&lt;li>id_rsa.pub&lt;/li>
&lt;/ul>
&lt;p>其中后缀为 .pub 的文件为公钥，另一个则为私钥。&lt;/p>
&lt;h2 id="配置密钥">配置密钥&lt;/h2>
&lt;h3 id="配置私钥">配置私钥&lt;/h3>
&lt;p>打开 &lt;code>blog_workflow&lt;/code> 仓库，进入 &lt;code>Settings&lt;/code> -&amp;gt; &lt;code>Secrets&lt;/code>，选择 &lt;code>New secret&lt;/code>，名称填写为 &lt;strong>ACTIONS_DEPLOY_KEY&lt;/strong>，后续需要用到该名称。&lt;br>
打开 &lt;strong>id_rsa&lt;/strong>，并复制其全部内容，粘贴到 &lt;code>Value&lt;/code> 中，点击添加。&lt;/p>
&lt;h3 id="配置公钥">配置公钥&lt;/h3>
&lt;p>打开 &lt;code>sudrizzz.github.io&lt;/code> 仓库，进入 &lt;code>Settings&lt;/code> -&amp;gt; &lt;code>Deploy keys&lt;/code>，选择 &lt;code>Add deploy key&lt;/code>，名字可以任意写。&lt;br>
打开 &lt;strong>id_rsa.pub&lt;/strong>，并复制其全部内容，粘贴到 &lt;code>Key&lt;/code> 中，勾选 &lt;code>Allow write access&lt;/code>，点击添加。
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200809154958.png" alt="20200809154958" />&lt;/p>
&lt;h1 id="配置-action-脚本">配置 Action 脚本&lt;/h1>
&lt;p>打开 &lt;code>blog_workflow&lt;/code> 仓库，进入 &lt;code>Action&lt;/code>，初始化左侧界面，选择 &lt;code>set up a workflow yourself&lt;/code>，在编辑框中粘贴如下配置&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln"> 1&lt;/span>name: CI
&lt;span class="ln"> 2&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="c1"># 持续发布的分支&lt;/span>
&lt;span class="ln"> 4&lt;/span>on:
&lt;span class="ln"> 5&lt;/span> push:
&lt;span class="ln"> 6&lt;/span> branches: master
&lt;span class="ln"> 7&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="c1"># 执行的 jobs&lt;/span>
&lt;span class="ln"> 9&lt;/span>jobs:
&lt;span class="ln">10&lt;/span> &lt;span class="c1"># 编译环境&lt;/span>
&lt;span class="ln">11&lt;/span> build:
&lt;span class="ln">12&lt;/span> runs-on: ubuntu-latest
&lt;span class="ln">13&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="c1"># 执行的步骤&lt;/span>
&lt;span class="ln">15&lt;/span> steps:
&lt;span class="ln">16&lt;/span> &lt;span class="c1"># 检出 sudrizzz/blog_workflow 工程，固定写法&lt;/span>
&lt;span class="ln">17&lt;/span> - uses: actions/checkout@v1
&lt;span class="ln">18&lt;/span>
&lt;span class="ln">19&lt;/span> - name: Setup Hugo
&lt;span class="ln">20&lt;/span> uses: peaceiris/actions-hugo@v2
&lt;span class="ln">21&lt;/span> with:
&lt;span class="ln">22&lt;/span> hugo-version: latest
&lt;span class="ln">23&lt;/span>
&lt;span class="ln">24&lt;/span> &lt;span class="c1"># 执行 hugo，编译出源文件&lt;/span>
&lt;span class="ln">25&lt;/span> - name: Build
&lt;span class="ln">26&lt;/span> run: hugo --gc --minify --cleanDestinationDir
&lt;span class="ln">27&lt;/span>
&lt;span class="ln">28&lt;/span> &lt;span class="c1"># 部署&lt;/span>
&lt;span class="ln">29&lt;/span> - name: Deploy
&lt;span class="ln">30&lt;/span> uses: peaceiris/actions-gh-pages@v3
&lt;span class="ln">31&lt;/span> with:
&lt;span class="ln">32&lt;/span> deploy_key: &lt;span class="si">${&lt;/span>&lt;span class="p">{ secrets.ACTIONS_DEPLOY_KEY &lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="o">}&lt;/span> &lt;span class="c1"># 上面配置的私钥名称&lt;/span>
&lt;span class="ln">33&lt;/span> external_repository: sudrizzz/sudrizzz.github.io &lt;span class="c1"># Pages 发布到远程仓库&lt;/span>
&lt;span class="ln">34&lt;/span> publish_dir: ./public &lt;span class="c1"># hugo 编译生成的 public 目录下的文件&lt;/span>
&lt;span class="ln">35&lt;/span> keep_files: &lt;span class="nb">false&lt;/span> &lt;span class="c1"># 不保留 *.github.io 仓库中已有的文件&lt;/span>
&lt;span class="ln">36&lt;/span> publish_branch: master &lt;span class="c1"># 远程仓库分支&lt;/span>
&lt;span class="ln">37&lt;/span> commit_message: &lt;span class="si">${&lt;/span>&lt;span class="p">{ github.event.head_commit.message &lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意修改第 33 行 &lt;code>external_repository&lt;/code> 中的用户名。
该配置的文件名任意，例如 &lt;code>main.yml&lt;/code>。保存后即可在 Actions 界面查看脚本执行情况。每当 &lt;code>blog_workflow&lt;/code> 仓库有新的 push 操作时，就会自动执行该脚本，然后将执行后生成的文件自动提交到 &lt;code>sudrizzz.github.io&lt;/code>。&lt;/p>
&lt;p>至此，利用 Github Actions 实现自动部署就已经完成了，写作步骤简化为：&lt;/p>
&lt;ol>
&lt;li>在 &lt;code>content/posts/cn/&lt;/code> 目录中新增文章，修改相关头信息，完成内容创作并保存；&lt;/li>
&lt;li>执行 &lt;code>hugo server&lt;/code> 并访问 &lt;code>localhost:1313&lt;/code> 查看文章显示效果；&lt;/li>
&lt;li>提交新文章到 &lt;code>blog_workflow&lt;/code>；&lt;/li>
&lt;li>上述 Action 自动编译并将生成的静态文件部署到 &lt;code>sudrizzz.github.io&lt;/code>。&lt;/li>
&lt;/ol>
&lt;p>创作流程得到了极大的简化。下面将介绍使用 Github 作为图床的相关配置。&lt;/p>
&lt;h1 id="安装并配置-picgo">安装并配置 PicGo&lt;/h1>
&lt;p>本文使用的方案是 VSCode + PicGo 扩展，所以首先打开 VSCode 安装好 PicGo，此处不再赘述。&lt;/p>
&lt;p>如果需要使用 PicGo Windows 客户端，请点击 &lt;a href="https://github.com/Molunerfinn/PicGo/releases">https://github.com/Molunerfinn/PicGo/releases&lt;/a> 下载，并跳过本节配置说明。&lt;/p>
&lt;h2 id="生成-token">生成 Token&lt;/h2>
&lt;p>点击 Github 右上角个人头像，进入 &lt;code>Settings&lt;/code> -&amp;gt; &lt;code>Developer settings&lt;/code> -&amp;gt; &lt;code>Personal access tokens&lt;/code>，点击 &lt;code>Generate new token&lt;/code>。&lt;br>
Note 中可以任意填写，勾选下方的 &lt;code>repo&lt;/code> 复选框，点击页面最下方的 &lt;code>Generate token&lt;/code>，复制生成的 token 字符串。
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200809161038.png" alt="20200809161038" />&lt;/p>
&lt;h2 id="配置-picgo">配置 PicGo&lt;/h2>
&lt;p>在 VSCode 中打开 PicGo 的设置界面，将复制的 token 字符串填到 &lt;code>picgo.picBed.github.token&lt;/code> 中，具体配置见下图。
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201221163830.png" alt="20201221163830" />&lt;/p>
&lt;ul>
&lt;li>&lt;code>picgo.picBed.github.customUrl&lt;/code>&lt;br>
此项是利用 jsDelivr CDN 为图片进行加速服务，填写时只需将 &lt;code>sudrizzz/blog_images&lt;/code> 更改为自己的用户名与仓库即可，具体如下。&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;code>picgo.picBed.github.path&lt;/code>&lt;br>
此项是配置图片的存储路径，根目录为 &lt;code>picgo.picBed.github.repo&lt;/code> 中设置的仓库。&lt;/li>
&lt;/ul>
&lt;p>当然你可以新建一个仓库专门用来存储图片，只需要调整上述相关设置，使其保持一致即可。&lt;/p>
&lt;h1 id="使用-picgo-写作">使用 PicGo 写作&lt;/h1>
&lt;p>在编写 markdown 文件需要插入图片时，只需要使用相应的快捷键即可完成上传图片操作，具体如下。&lt;/p>
&lt;pre>&lt;code>从剪贴板上传图像
Windows / Unix：Ctrl + Alt + U
OSX：Cmd + Opt + U
从资源管理器上传图像
Windows / Unix：Ctrl + Alt + E
OSX：Cmd + Opt + E
&lt;/code>&lt;/pre>&lt;h1 id="结语">结语&lt;/h1>
&lt;p>至此，搭建 Github Pages 系列文章就到此结束了，作者的需求基本得到了满足，感谢您的阅读。&lt;/p></description></item><item><title>从零搭建 Github Pages</title><link>https://sudrizzz.github.io/posts/build-blog-from-scratch/</link><pubDate>Sun, 09 Aug 2020 12:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/build-blog-from-scratch/</guid><description>&lt;h1 id="创建仓库">创建仓库&lt;/h1>
&lt;p>首先需要在 Github 中创建一个名为 &lt;code>&amp;lt;username&amp;gt;.github.io&lt;/code> 的仓库，其中 &lt;code>&amp;lt;username&amp;gt;&lt;/code> 为你的 Github 用户名。&lt;/p>
&lt;blockquote>
&lt;p>注意：&lt;br>
由于 &lt;code>username&lt;/code> 不方便叙述，故下文中均以 &lt;code>sudrizzz&lt;/code> 为例替代 &lt;code>username&lt;/code>，&lt;br>
请根据实际情况进行更改。&lt;/p>
&lt;/blockquote>
&lt;p>例如我的 Github 用户名是 &lt;code>sudrizzz&lt;/code>，于是创建的仓库名就是 &lt;code>sudrizzz.github.io&lt;/code>。&lt;/p>
&lt;p>&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200809134438.png" alt="20200809134438" />&lt;/p>
&lt;h1 id="初始化-hugo">初始化 Hugo&lt;/h1>
&lt;h2 id="安装-hugo-应用">安装 Hugo 应用&lt;/h2>
&lt;p>&lt;a href="https://github.com/gohugoio/hugo/releases">https://github.com/gohugoio/hugo/releases&lt;/a>&lt;/p>
&lt;h2 id="配置环境变量">配置环境变量&lt;/h2>
&lt;p>将安装 Hugo 的目录路径配置到用户环境变量 &lt;code>PATH&lt;/code> 中，如图
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200809135128.png" alt="20200809135128" />&lt;/p>
&lt;h2 id="检验配置">检验配置&lt;/h2>
&lt;p>在命令行窗口中输入以下内容&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>hugo version
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果得到类似以下的结果则说明配置正确。&lt;/p>
&lt;pre>&lt;code>Hugo Static Site Generator v0.74.3-DA0437B4 windows/amd64 BuildDate: 2020-07-23T16:23:30Z
&lt;/code>&lt;/pre>&lt;h1 id="创建博客">创建博客&lt;/h1>
&lt;p>在命令行中输入以下命令&lt;/p>
&lt;pre>&lt;code>hugo new site &amp;lt;blog_name&amp;gt;
&lt;/code>&lt;/pre>&lt;p>上述命令将会创建一个名为 blog_name 的文件夹，请按照个人喜好取名。按照我的博客为例，取名为 &lt;code>sudrizzz.github.io&lt;/code>，这样也方便后续进行代码提交&lt;/p>
&lt;h2 id="添加主题">添加主题&lt;/h2>
&lt;p>以 &lt;a class="link" href="https://github.com/joway/hugo-theme-yinyang" target="_blank" rel="noopener"
>yinyang&lt;/a> 主题为例，按照文档中的安装步骤，执行以下命令&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="nb">cd&lt;/span> sudrizzz.github.io
&lt;span class="ln">2&lt;/span>git clone git@github.com:joway/hugo-theme-yinyang.git themes/yinyang
&lt;/code>&lt;/pre>&lt;/div>&lt;p>进入 &lt;code>sudrizzz.github.io/themes/yinyang/exampleSite&lt;/code> 目录，将 &lt;code>content&lt;/code> 文件夹和 &lt;code>config.toml&lt;/code> 文件拷贝到 &lt;code>sudrizzz.github.io&lt;/code> 目录。&lt;/p>
&lt;h2 id="自定义主题">自定义主题&lt;/h2>
&lt;p>根据 &lt;a class="link" href="https://github.com/joway/hugo-theme-yinyang#configuration" target="_blank" rel="noopener"
>yinyang 主题配置文档&lt;/a>，我们可以按需修改其中的内容即可，以下贴出我自定义的配置内容。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-toml" data-lang="toml">&lt;span class="ln"> 1&lt;/span>&lt;span class="nx">baseURL&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;https://sudrizzz.github.com&amp;#34;&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="nx">languageCode&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;zh-cn&amp;#34;&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="nx">title&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;Anthony&amp;#39;s Blog&amp;#34;&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="nx">theme&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;yinyang&amp;#34;&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="nx">DefaultContentLanguage&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;cn&amp;#34;&lt;/span>
&lt;span class="ln"> 6&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nx">author&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="nx">name&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;Anthony Qu&amp;#34;&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="nx">homepage&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;https://github.com/sudrizzz/&amp;#34;&lt;/span>
&lt;span class="ln">10&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nx">languages&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="c"># [languages.en]&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="c"># contentDir = &amp;#34;content/en&amp;#34;&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="c"># languageName = &amp;#34;English&amp;#34;&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="c"># weight = 1&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nx">languages&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">cn&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="ln">17&lt;/span> &lt;span class="nx">contentDir&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;content/cn&amp;#34;&lt;/span>
&lt;span class="ln">18&lt;/span> &lt;span class="nx">languageName&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;Chinese&amp;#34;&lt;/span>
&lt;span class="ln">19&lt;/span> &lt;span class="nx">weight&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;span class="ln">20&lt;/span>
&lt;span class="ln">21&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nx">params&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="ln">22&lt;/span>&lt;span class="nx">disqus&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;sudri&amp;#34;&lt;/span> &lt;span class="c"># disqus account name&lt;/span>
&lt;span class="ln">23&lt;/span>&lt;span class="nx">extraHead&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s1">&amp;#39;&amp;#39;&lt;/span>
&lt;span class="ln">24&lt;/span>&lt;span class="nx">mainSections&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;posts&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="ln">25&lt;/span>&lt;span class="c"># googleAnalytics = &amp;#34;&amp;#34;&lt;/span>
&lt;span class="ln">26&lt;/span>&lt;span class="c"># description = &amp;#34;&amp;#34;&lt;/span>
&lt;span class="ln">27&lt;/span>
&lt;span class="ln">28&lt;/span>&lt;span class="p">[[&lt;/span>&lt;span class="nx">params&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">socials&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;span class="ln">29&lt;/span>&lt;span class="nx">name&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;Github&amp;#34;&lt;/span>
&lt;span class="ln">30&lt;/span>&lt;span class="nx">link&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;https://github.com/sudrizzz/&amp;#34;&lt;/span>
&lt;span class="ln">31&lt;/span>
&lt;span class="ln">32&lt;/span>&lt;span class="p">[[&lt;/span>&lt;span class="nx">params&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">socials&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;span class="ln">33&lt;/span>&lt;span class="nx">name&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;RSS&amp;#34;&lt;/span>
&lt;span class="ln">34&lt;/span>&lt;span class="nx">link&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;/index.xml&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="添加文章">添加文章&lt;/h1>
&lt;p>在 &lt;code>sudrizzz.github.io&lt;/code> 文件夹中执行以下命令以新增文章&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>hugo new content/cn/posts/my-first-post.md
&lt;/code>&lt;/pre>&lt;/div>&lt;p>但是我个人不建议这么操作，原因有两点&lt;/p>
&lt;ol>
&lt;li>此主题的 posts 目录分为 cn 和 en，也就是中文和英语目录，路径较长，敲命令不是很方便；&lt;/li>
&lt;li>md 文件中需要包含特定格式的头信息（如下），才能被正常渲染，而通过上述命令生成的 md 文件是空白文件，自己添加头信息也不太现实。&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>md 头信息
title: &amp;quot;从零搭建 Github Pages&amp;quot;
date: 2020-08-09T00:00:00+08:00
draft: false
categories: [&amp;quot;blog&amp;quot;]
slug: &amp;quot;build-blog-from-scratch&amp;quot;
其中各项含义如下
title: 文章显示标题
date: 文章创建日期与时间
draft: 是否为草稿状态
categories: 分类信息，可添多个关键词，用半角逗号分隔
slug: 文章渲染后的 url
&lt;/code>&lt;/pre>&lt;p>所以我更推荐直接拷贝已有的文章，然后修改其中的内容（包括头信息）即可。
在此我创建了名为 TestFile.md 的测试文件以作演示，完整内容如下。&lt;/p>
&lt;pre>&lt;code>---
title: &amp;quot;这是一个测试文件&amp;quot;
date: 2020-01-01T00:00:00+08:00
draft: false
categories: [&amp;quot;test&amp;quot;]
slug: &amp;quot;this-is-a-test-file&amp;quot;
---
This is a test file.
Nothing special here.
&lt;/code>&lt;/pre>&lt;h1 id="启动服务">启动服务&lt;/h1>
&lt;p>在 &lt;code>sudrizzz.github.io&lt;/code> 目录执行以下命令&lt;/p>
&lt;pre>&lt;code>hugo server
&lt;/code>&lt;/pre>&lt;p>会得到类似于如下的信息&lt;/p>
&lt;pre>&lt;code>Building sites …
| CN
-------------------+-----
Pages | 17
Paginator pages | 0
Non-page files | 0
Static files | 13
Processed images | 0
Aliases | 0
Sitemaps | 1
Cleaned | 0
Built in 28 ms
Watching for changes in D:\Blog\sudrizzz.github.io\{archetypes,content,layouts,themes}
Watching for config changes in D:\Blog\sudrizzz.github.io\config.toml
Environment: &amp;quot;development&amp;quot;
Serving pages from memory
Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender
Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)
Press Ctrl+C to stop
&lt;/code>&lt;/pre>&lt;p>可以看到最后一行显示已经启动成功，页面地址是 http://localhost:1313/ ，访问这个地址即可看到如下效果。&lt;br>
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200809143708.png" alt="20200809143708" />
点击标题进入文章即可看到全部内容。&lt;br>
&lt;img src="https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20200809144430.png" alt="20200809144430" />&lt;/p>
&lt;h1 id="编译文章">编译文章&lt;/h1>
&lt;blockquote>
&lt;p>说明：&lt;br>
下述命令中的参数可以根据 Hugo 官方文档按需添加&lt;br>
&lt;a href="https://gohugo.io/commands/hugo/#options">https://gohugo.io/commands/hugo/#options&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;pre>&lt;code>hugo --minify --cleanDestinationDir
&lt;/code>&lt;/pre>&lt;p>可以得到如下结果&lt;/p>
&lt;pre>&lt;code>Building sites …
| CN
-------------------+-----
Pages | 14
Paginator pages | 0
Non-page files | 0
Static files | 13
Processed images | 0
Aliases | 0
Sitemaps | 1
Cleaned | 0
Total in 29 ms
&lt;/code>&lt;/pre>&lt;p>这样就编译完成了，编译后生成的静态文件放在 &lt;code>sudrizzz.github.io/public&lt;/code> 目录下。结构如下：&lt;/p>
&lt;pre>&lt;code>├─categories
│ └─test
├─css
│ └─highlight
├─fonts
├─images
├─js
├─posts
│ └─this-is-a-test-file
└─tags
&lt;/code>&lt;/pre>&lt;p>至此博客就基本搭建完成了。接下来要做的就是与前文中提到的 Github Pages 仓库结合起来。&lt;/p>
&lt;h1 id="推送到-github">推送到 Github&lt;/h1>
&lt;blockquote>
&lt;p>说明 1：&lt;br>
此处涉及到 Git 的相关操作，请先根据其他教程配置好 Git 环境再执行命令；&lt;br>
或者也可以安装一些 Git 可视化工具来简化操作，例如 TortoiseGit。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>说明 2:&lt;br>
我们只需要将 Hugo 生成的静态文件托管到 Github，&lt;br>
所以请确保下述命令是在 &lt;code>/pulic&lt;/code> 目录中执行的。&lt;/p>
&lt;/blockquote>
&lt;p>在 &lt;code>sudrizzz.github.io/pulic&lt;/code> 目录中执行以下命令&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>git clone https://github.com/sudrizzz/sudrizzz.github.io.git
&lt;span class="ln">2&lt;/span>git add .
&lt;span class="ln">3&lt;/span>git commit -m &lt;span class="s2">&amp;#34;&amp;lt;commit_info&amp;gt;&amp;#34;&lt;/span>
&lt;span class="ln">4&lt;/span>git push origin master
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样博客的所有内容就都已经推送到了 Github，稍等片刻，即可访问 sudrizzz.github.io 查看部署结果。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>前文搭建的博客是由 Github Pages + Hugo 实现的，具体的新增文章步骤可以总结为以下几点。&lt;/p>
&lt;ol>
&lt;li>在 &lt;code>content/posts/cn/&lt;/code> 目录中新增文章，修改相关头信息，完成内容创作并保存；&lt;/li>
&lt;li>执行 &lt;code>hugo server&lt;/code> 并访问 &lt;code>localhost:1313&lt;/code> 查看文章显示效果，酌情修改；&lt;/li>
&lt;li>执行 &lt;code>hugo --minify --cleanDestinationDir&lt;/code>；&lt;/li>
&lt;li>进入 &lt;code>/public&lt;/code> 目录，将新生成或编辑过的内容推送到 Github，此处不再赘述。&lt;/li>
&lt;/ol>
&lt;p>此时我们的博客就创建好了，但是创建文章内容的操作有一些复杂和繁琐，且本文中并未讲解关于 markdown 中插入图片的相关问题。所以在下文中，我们将简化操作步骤，并实现将图片也托管到 Github 的操作。&lt;/p></description></item><item><title>The meaning of life</title><link>https://sudrizzz.github.io/posts/the-meaning-of-life/</link><pubDate>Fri, 21 Jun 2019 00:00:00 +0800</pubDate><guid>https://sudrizzz.github.io/posts/the-meaning-of-life/</guid><description>&lt;p>  ……我细读来书，终觉得你不免作茧自缚。你自己去寻出一个本不成问题的问题，“人生有何意义？”其实这个问题是容易解答的。人生的意义全是各人自己寻出来、造出来的：高尚、卑劣、清贵、污浊、有用、无用，……全靠自己的作为。&lt;/p>
&lt;p>  生命本身不过是一件生物学的事实，有什么意义可说？一个人与一只猎，一只狗，有什么分别？人生的意义不在于何以有生，而在自己怎样生活。你若情愿把这六尺之躯葬送在白昼作梦之上二那就是你这一生的意义。你若发愤振作起来，决心去寻求生命的意义，去创造自己的生命的意义，那么，你活一日便有一日的意义，作一事便添一事的意义，生命无穷，生命的意义也无穷了。&lt;/p>
&lt;p>  总之，生命本没有意义，你要能给他什么意义，他就有什么意义。与其终日冥想人生有何意义，不如试用此生作点有意义的事……&lt;/p>
&lt;p>  &lt;em>节选自《答某君书》—— 胡适&lt;/em>&lt;/p></description></item></channel></rss>