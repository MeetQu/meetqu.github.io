<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="1. 概念 1.1 摩尔定律（Moore&amp;rsquo;s law） 摩尔定律是由英特尔（Intel）创始人之一戈登·摩尔提出的。其内容为：集成电路上可容纳的晶体管数目，约每隔两年便会增加一倍；经常被引用的“18 个月”，是由英特尔首席执行官大卫·豪斯（David House）提出：预计 18 个月会将芯片的性能提高一倍（即更多的晶体管使其更快），是一种以倍数增长的观测。
通常认为摩尔定律具体的内容：每 18 个月，芯片的性能将提高一倍。
1.2 新摩尔定律（存疑） 由于单个核心性能提升有着严重的瓶颈问题，未来的计算机硬件不会更快，但会更“宽”。
1.3 常见并行模式   进程 + 线程 硬件组织通常是多机+多核，编程环境 MPI+OpenMP
  线程 + GPU 线程 硬件组织通常是多核+多 GPU，编程环境 OpenMP+CUDA/OpenCL
  进程 + 线程 + GPU 线程 硬件组织通常是多机+多核+多 GPU，编程环境 MPI+OpenMP+CUDA/OpenCL
  1.4 CPU 与 GPU 区别 上图中，绿色的是计算单元，橙红色的是存储单元，橙黄色的是控制单元。其中，各个部件详细释义：
 ALU：算术逻辑单元（Arithmetic Logic Unit），是一种可对二进制整数执行算术运算或位运算的组合逻辑数字电路； Control：控制单元，负责指挥 CPU 工作，控制其他设备的活动； Cache：用于减少处理器访问内存所需平均时间的部件； DRAM：动态随机存取存储器（Dynamic Random Access Memory），即内存。  简而言之，CPU 擅长于复杂逻辑控制，GPU 擅长于简单重复运算。
2. CUDA 简介及架构 CUDA（Compute Unified Device Architecture）是 NVIDIA 推出的的通用并行计算架构，该架构使 GPU 能够解决大量重复性的计算问题。"><title>并行计算总结</title><link rel=canonical href=https://sudrizzz.github.io/posts/parallel-computing-summary/><link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="并行计算总结"><meta property="og:description" content="1. 概念 1.1 摩尔定律（Moore&amp;rsquo;s law） 摩尔定律是由英特尔（Intel）创始人之一戈登·摩尔提出的。其内容为：集成电路上可容纳的晶体管数目，约每隔两年便会增加一倍；经常被引用的“18 个月”，是由英特尔首席执行官大卫·豪斯（David House）提出：预计 18 个月会将芯片的性能提高一倍（即更多的晶体管使其更快），是一种以倍数增长的观测。
通常认为摩尔定律具体的内容：每 18 个月，芯片的性能将提高一倍。
1.2 新摩尔定律（存疑） 由于单个核心性能提升有着严重的瓶颈问题，未来的计算机硬件不会更快，但会更“宽”。
1.3 常见并行模式   进程 + 线程 硬件组织通常是多机+多核，编程环境 MPI+OpenMP
  线程 + GPU 线程 硬件组织通常是多核+多 GPU，编程环境 OpenMP+CUDA/OpenCL
  进程 + 线程 + GPU 线程 硬件组织通常是多机+多核+多 GPU，编程环境 MPI+OpenMP+CUDA/OpenCL
  1.4 CPU 与 GPU 区别 上图中，绿色的是计算单元，橙红色的是存储单元，橙黄色的是控制单元。其中，各个部件详细释义：
 ALU：算术逻辑单元（Arithmetic Logic Unit），是一种可对二进制整数执行算术运算或位运算的组合逻辑数字电路； Control：控制单元，负责指挥 CPU 工作，控制其他设备的活动； Cache：用于减少处理器访问内存所需平均时间的部件； DRAM：动态随机存取存储器（Dynamic Random Access Memory），即内存。  简而言之，CPU 擅长于复杂逻辑控制，GPU 擅长于简单重复运算。
2. CUDA 简介及架构 CUDA（Compute Unified Device Architecture）是 NVIDIA 推出的的通用并行计算架构，该架构使 GPU 能够解决大量重复性的计算问题。"><meta property="og:url" content="https://sudrizzz.github.io/posts/parallel-computing-summary/"><meta property="og:site_name" content="Anthony's blog"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:published_time" content="2021-01-11T15:00:00+08:00"><meta property="article:modified_time" content="2021-01-11T15:00:00+08:00"><meta name=twitter:title content="并行计算总结"><meta name=twitter:description content="1. 概念 1.1 摩尔定律（Moore&amp;rsquo;s law） 摩尔定律是由英特尔（Intel）创始人之一戈登·摩尔提出的。其内容为：集成电路上可容纳的晶体管数目，约每隔两年便会增加一倍；经常被引用的“18 个月”，是由英特尔首席执行官大卫·豪斯（David House）提出：预计 18 个月会将芯片的性能提高一倍（即更多的晶体管使其更快），是一种以倍数增长的观测。
通常认为摩尔定律具体的内容：每 18 个月，芯片的性能将提高一倍。
1.2 新摩尔定律（存疑） 由于单个核心性能提升有着严重的瓶颈问题，未来的计算机硬件不会更快，但会更“宽”。
1.3 常见并行模式   进程 + 线程 硬件组织通常是多机+多核，编程环境 MPI+OpenMP
  线程 + GPU 线程 硬件组织通常是多核+多 GPU，编程环境 OpenMP+CUDA/OpenCL
  进程 + 线程 + GPU 线程 硬件组织通常是多机+多核+多 GPU，编程环境 MPI+OpenMP+CUDA/OpenCL
  1.4 CPU 与 GPU 区别 上图中，绿色的是计算单元，橙红色的是存储单元，橙黄色的是控制单元。其中，各个部件详细释义：
 ALU：算术逻辑单元（Arithmetic Logic Unit），是一种可对二进制整数执行算术运算或位运算的组合逻辑数字电路； Control：控制单元，负责指挥 CPU 工作，控制其他设备的活动； Cache：用于减少处理器访问内存所需平均时间的部件； DRAM：动态随机存取存储器（Dynamic Random Access Memory），即内存。  简而言之，CPU 擅长于复杂逻辑控制，GPU 擅长于简单重复运算。
2. CUDA 简介及架构 CUDA（Compute Unified Device Architecture）是 NVIDIA 推出的的通用并行计算架构，该架构使 GPU 能够解决大量重复性的计算问题。"></head><body><script>(function(){const colorSchemeKey='StackColorScheme';if(!localStorage.getItem(colorSchemeKey)){localStorage.setItem(colorSchemeKey,"auto");}})();</script><script>(function(){const colorSchemeKey='StackColorScheme';const colorSchemeItem=localStorage.getItem(colorSchemeKey);const supportDarkMode=window.matchMedia('(prefers-color-scheme: dark)').matches===true;if(colorSchemeItem=='dark'||colorSchemeItem==='auto'&&supportDarkMode){document.body.dataset.scheme='dark';}else{document.body.dataset.scheme='light';}})();</script><div class="container main-container flex on-phone--column extended article-page with-toolbar"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><img src=/img/avatar_hu275e4bab890ad53f8b467a21c6984a95_383962_300x0_resize_box_2.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></figure><h1 class=site-name><a href=https://sudrizzz.github.io/>Anthony's blog</a></h1><h2 class=site-description>I'm doing good, I’m on some new shit. Been saying "Yes" instead of "No".</h2></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></ol></aside><main class="main full-width"><div id=article-toolbar><a href=https://sudrizzz.github.io/ class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg><span>Back</span></a></div><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/parallel-computing/>parallel computing</a></header><h2 class=article-title><a href=/posts/parallel-computing-summary/>并行计算总结</a></h2><footer class=article-time><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--published>Jan 11, 2021</time></footer></div></header><section class=article-content><h1 id=1-概念>1. 概念</h1><h2 id=11-摩尔定律moores-law>1.1 摩尔定律（Moore&rsquo;s law）</h2><p>摩尔定律是由英特尔（Intel）创始人之一戈登·摩尔提出的。其内容为：集成电路上可容纳的晶体管数目，约每隔两年便会增加一倍；经常被引用的“18 个月”，是由英特尔首席执行官大卫·豪斯（David House）提出：预计 18 个月会将芯片的性能提高一倍（即更多的晶体管使其更快），是一种以倍数增长的观测。</p><p><strong>通常认为摩尔定律具体的内容：每 18 个月，芯片的性能将提高一倍</strong>。</p><h2 id=12-新摩尔定律存疑>1.2 新摩尔定律（存疑）</h2><p>由于单个核心性能提升有着严重的瓶颈问题，未来的计算机硬件不会更快，但会更“宽”。</p><h2 id=13-常见并行模式>1.3 常见并行模式</h2><ol><li><p>进程 + 线程
硬件组织通常是多机+多核，编程环境 MPI+OpenMP</p></li><li><p>线程 + GPU 线程
硬件组织通常是多核+多 GPU，编程环境 OpenMP+CUDA/OpenCL</p></li><li><p>进程 + 线程 + GPU 线程
硬件组织通常是多机+多核+多 GPU，编程环境 MPI+OpenMP+CUDA/OpenCL</p></li></ol><h2 id=14-cpu-与-gpu-区别>1.4 CPU 与 GPU 区别</h2><p><img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210111155959.png alt=20210111155959></p><p>上图中，绿色的是计算单元，橙红色的是存储单元，橙黄色的是控制单元。其中，各个部件详细释义：</p><ul><li>ALU：算术逻辑单元（<strong>A</strong>rithmetic <strong>L</strong>ogic <strong>U</strong>nit），是一种可对二进制整数执行算术运算或位运算的组合逻辑数字电路；</li><li>Control：控制单元，负责指挥 CPU 工作，控制其他设备的活动；</li><li>Cache：用于减少处理器访问内存所需平均时间的部件；</li><li>DRAM：动态随机存取存储器（<strong>D</strong>ynamic <strong>R</strong>andom <strong>A</strong>ccess <strong>M</strong>emory），即内存。</li></ul><p>简而言之，CPU 擅长于复杂逻辑控制，GPU 擅长于简单重复运算。</p><h1 id=2-cuda-简介及架构>2. CUDA 简介及架构</h1><p>CUDA（<strong>C</strong>ompute <strong>U</strong>nified <strong>D</strong>evice <strong>A</strong>rchitecture）是 NVIDIA 推出的的通用并行计算架构，该架构使 GPU 能够解决大量重复性的计算问题。</p><h2 id=21-物理架构>2.1 物理架构</h2><p><img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210111162222.png alt=20210111162222></p><h2 id=22-kernel-函数启动参数>2.2 kernel 函数启动参数</h2><h3 id=221-blockspergrid>2.2.1 blocksPerGrid</h3><p>用于定义 kernel 函数使用的 block 数量，可以定义为一、二与三维结构，示例如下；</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=c1>// 使用 8 个 block
</span><span class=ln>2</span><span class=c1></span><span class=kt>int</span> <span class=n>blocksPerGrid</span> <span class=o>=</span> <span class=mi>8</span><span class=p>;</span>
<span class=ln>3</span>
<span class=ln>4</span><span class=c1>// 使用 2 * 2 个 block
</span><span class=ln>5</span><span class=c1></span><span class=n>dim3</span> <span class=nf>blocksPerGrid</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span>
<span class=ln>6</span>
<span class=ln>7</span><span class=c1>// 使用 2 * 2 * 2 个 block
</span><span class=ln>8</span><span class=c1></span><span class=n>dim3</span> <span class=nf>blocksPerGrid</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span>
</code></pre></div><h3 id=222-threadsperblock>2.2.2 threadsPerBlock</h3><p>用于定义每个 block 中使用的线程数量，与 block 类似，同样可以定义为一、二与三维结构。在目前的 GPU 上，一个线程块可以包含多达 <strong>1024</strong> 个线程。示例如下；</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=c1>// 使用 1024 个线程
</span><span class=ln>2</span><span class=c1></span><span class=kt>int</span> <span class=n>threadsPerBlock</span> <span class=o>=</span> <span class=mi>1024</span><span class=p>;</span>
<span class=ln>3</span>
<span class=ln>4</span><span class=c1>// 使用 32 * 32 个线程
</span><span class=ln>5</span><span class=c1></span><span class=n>dim3</span> <span class=nf>threadsPerBlock</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>32</span><span class=p>);</span>
<span class=ln>6</span>
<span class=ln>7</span><span class=c1>// 使用 8 * 8 * 8 个线程
</span><span class=ln>8</span><span class=c1></span><span class=n>dim3</span> <span class=nf>threadsPerBlock</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>);</span>
</code></pre></div><h3 id=223-调用-kernel-函数>2.2.3 调用 kernel 函数</h3><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=c1>// 官方示例，sharedMemBytes 表示指定共享内存大小，单位为字节
</span><span class=ln>2</span><span class=c1></span><span class=n>kernelFunction</span> <span class=o>&lt;&lt;&lt;</span> <span class=n>dimGrid</span><span class=p>,</span> <span class=n>dimBlock</span><span class=p>,</span> <span class=n>sharedMemBytes</span> <span class=o>&gt;&gt;&gt;</span> <span class=p>(...);</span>
<span class=ln>3</span>
<span class=ln>4</span><span class=c1>// 实际调用示例，sharedMemBytes 参数可省略
</span><span class=ln>5</span><span class=c1></span><span class=n>kernelFunction</span> <span class=o>&lt;&lt;&lt;</span> <span class=n>blocksPerGrid</span><span class=p>,</span> <span class=n>threadsPerBlock</span> <span class=o>&gt;&gt;&gt;</span> <span class=p>(...);</span>
</code></pre></div><h2 id=23-常用-cuda-关键字>2.3 常用 CUDA 关键字</h2><table><thead><tr><th>函数定义方式</th><th>执行方</th><th>调用方</th></tr></thead><tbody><tr><td><strong>__device__</strong> float DeviceFunc()</td><td>GPU</td><td>GPU</td></tr><tr><td><strong>__global__</strong> void KernelFunc()</td><td>GPU</td><td>CPU</td></tr><tr><td><strong>__host__</strong> float HostFunc()</td><td>CPU</td><td>CPU</td></tr></tbody></table><p>__device__函数没有函数地址，也没有指向它的函数指针。在 device 端执行的函数有下面的限制:</p><ol><li>没有递归；</li><li>函数内部没有静态变量；</li><li>参数的数量是固定的。</li></ol><h3 id=231-__shared__>2.3.1 __shared__</h3><ul><li>存储于 GPU 上的 thread block 内的共享存储器；</li><li>和 thread block 具有相同的生命期；</li><li>只能被 thread block 内的线程存取。</li></ul><p>常用于声明变量，声明后的变量将会存储在 shared memory 中，例如</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=c1>// 存储在 shared memory 中
</span><span class=ln>2</span><span class=c1></span><span class=n>__shared__</span> <span class=kt>float</span> <span class=n>array</span><span class=p>[</span><span class=n>N</span><span class=p>];</span>
<span class=ln>3</span>
<span class=ln>4</span><span class=c1>// 存储在 global memory 中
</span><span class=ln>5</span><span class=c1></span><span class=kt>float</span> <span class=n>array</span><span class=p>[</span><span class=n>N</span><span class=p>];</span>
</code></pre></div><h2 id=24-内存类型>2.4 内存类型</h2><h3 id=241-register-与-local-memory>2.4.1 Register 与 Local Memory</h3><ul><li>对每个线程来说，寄存器都是线程私有的；</li><li>如果寄存器被消耗完，数据将被存储在 local memory。Local memory 是私有的，但是 local memory 中的数据是被保存在显存中，速度很慢；</li><li>输入和中间输出变量将被保存在 register 或者 local memory 中。</li></ul><h3 id=242-shared-memory>2.4.2 Shared Memory</h3><ul><li>用于线程间通信的 shared memory。shared memory 是一块可以被同一 block 中的所有 thread 访问的可读写存储器；</li><li>访问 shared memory 几乎和访问 register 一样快，是实现线程间通信的延迟最小的方法；</li><li>shared memory 可以实现许多不同的功能，如用于保存公用的计数器或者 block 的公用结构。</li></ul><h2 id=25-内存分配>2.5 内存分配</h2><p>通过如下语句可以实现 CUDA 内存分配，分配显存中的 global memory。</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>cudaMalloc</span><span class=p>(</span><span class=kt>void</span><span class=o>**</span> <span class=n>devPtr</span><span class=p>,</span> <span class=n>size_t</span> <span class=n>size</span><span class=p>)</span>
</code></pre></div><p>其中</p><ul><li>devPtr：对象指针；</li><li>size：分配的内存大小。</li></ul><p>例如</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span> <span class=o>&amp;</span><span class=n>device_array</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</code></pre></div><p>通过如下语句可以实现 CUDA 释放 global memory 中分配出的内存。</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>cudaFree</span><span class=p>(</span><span class=kt>void</span><span class=o>*</span> <span class=n>devPtr</span><span class=p>)</span>
</code></pre></div><h2 id=26-数据交换>2.6 数据交换</h2><p>通过如下语句可以实现 CUDA 显存中数据与 CPU 内存端数据的交换。</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=kt>void</span> <span class=o>*</span><span class=n>dst</span><span class=p>,</span> <span class=k>const</span> <span class=kt>void</span> <span class=o>*</span><span class=n>src</span><span class=p>,</span> <span class=n>size_t</span> <span class=n>count</span><span class=p>,</span> <span class=k>enum</span> <span class=n>cudaMemcpyKind</span> <span class=n>kind</span><span class=p>)</span>
</code></pre></div><p>其中</p><ul><li>dst：目的存储器地址；</li><li>src：源存储器地址；</li><li>count：拷贝数据的大小；</li><li>kind：数据传输类型，常用的包括以下两种：
cudaMemcpyDeviceToHost：将显存中的数据拷贝到内存中；
cudaMemcpyHostToDevice：将内存中的数据拷贝到显存中。</li></ul><p>例如</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>device_array</span><span class=p>,</span> <span class=n>host_array</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span>
</code></pre></div><h2 id=27-线程同步>2.7 线程同步</h2><h3 id=271-block-内线程同步>2.7.1 block 内线程同步</h3><p>通过调用以下方法，实现同一个 block 内所有线程同步。</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>__syncthreads</span><span class=p>();</span>
</code></pre></div><p>例如</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>function</span><span class=p>(...)</span> <span class=p>{</span>
<span class=ln>2</span>    <span class=p>...</span>
<span class=ln>3</span>    <span class=n>__syncthreads</span><span class=p>();</span>
<span class=ln>4</span>    <span class=p>...</span>
<span class=ln>5</span><span class=p>}</span>
</code></pre></div><h3 id=272-cpu-与-gpu-线程同步>2.7.2 CPU 与 GPU 线程同步</h3><p>通常情况下，CPU 端调用 kernel 函数，并不会阻塞后续 CPU 端的代码执行，也即调用 kernel 函数是<strong>异步</strong>的。若要实现同步的效果，只需在调用 kernel 函数后调用以下方法，进行线程同步即可。</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>cudaDeviceSynchronize</span><span class=p>()</span>
<span class=ln>2</span><span class=n>cudaThreadSynchronize</span><span class=p>()</span> <span class=c1>// 已过时，应避免使用
</span></code></pre></div><p>例如</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=ln>1</span><span class=n>kernel</span> <span class=o>&lt;&lt;&lt;</span> <span class=n>blocksPerGrid</span><span class=p>,</span> <span class=n>threadsPerBlock</span> <span class=o>&gt;&gt;&gt;</span> <span class=p>(...);</span>
<span class=ln>2</span><span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</code></pre></div><h1 id=3-cuda-编程>3 CUDA 编程</h1><h2 id=31-矩阵相加>3.1 矩阵相加</h2><p><a href=https://github.com/sudrizzz/ParallelComputing/blob/main/classwork/01/matrix_addition.cu>https://github.com/sudrizzz/ParallelComputing/blob/main/classwork/01/matrix_addition.cu</a></p><h2 id=32-矩阵相乘>3.2 矩阵相乘</h2><p><a href=https://github.com/sudrizzz/ParallelComputing/blob/main/classwork/02/matrix_multiplication.cu>https://github.com/sudrizzz/ParallelComputing/blob/main/classwork/02/matrix_multiplication.cu</a></p><h2 id=33-并行规约>3.3 并行规约</h2><p><a href=https://github.com/sudrizzz/ParallelComputing#%E4%BA%8C%E8%8E%B7%E5%8F%96%E7%9F%A9%E9%98%B5%E6%AF%8F%E4%B8%80%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%BC>https://github.com/sudrizzz/ParallelComputing#%E4%BA%8C%E8%8E%B7%E5%8F%96%E7%9F%A9%E9%98%B5%E6%AF%8F%E4%B8%80%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%BC</a></p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=StackLaTeX()></script><script>function StackLaTeX(){renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]});}</script></article><aside class=related-contents--wrapper><h2 class=section-title>Related contents</h2><div class=related-contents><div class="flex article-list--tile"><article><a href=/posts/parallel-computing/><div class=article-details><h2 class=article-title>并行计算课程实践</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2018 -
2021 Anthony's blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=2.0.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const customFont=document.createElement('link');customFont.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";customFont.type="text/css";customFont.rel="stylesheet";document.head.appendChild(customFont);}());</script></body></html>