<!doctype html><html lang=en><head><meta charset=utf-8><meta name=generator content="Hugo 0.76.5"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Anthony"><meta property="og:url" content="https://sudrizzz.github.com/posts/spark-distributed-programming/"><link rel=canonical href=https://sudrizzz.github.com/posts/spark-distributed-programming/><link rel=alternate type=application/atom+xml href=https://sudrizzz.github.comindex.xml title="Anthony's Blog"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/sudrizzz.github.com"},"articleSection":"posts","name":"Spark 分布式内存计算框架","headline":"Spark 分布式内存计算框架","description":"Spark 简介 Spark 是一种基于内存的、用以实现高效集群计算的平台。准确地讲，Spark 是一个大数据并行计算框架，是对广泛使用的 MapReduce 计算模型的扩展。Spark 有着自己的生态系统，但同时兼容 HDFS、Hive 等分布式存储系统，可以完美融入 Hadoop 的生态圈中，代替 MapReduce 去执行更为高效的分布式计算。两者的区别在于：基于 MapReduce 的计算引擎通常会将中间结果输出到磁盘上进行存储和容错；而 Spark 则是将中间结果尽量保存在内存中以减少底层存储系统的 I\/O，以提高计算速度。\nSpark 编程模型 核心数据结构 RDD Spark 将数据抽象成弹性分布式数据集（Resilient Distributed Dataset, RDD），RDD 实际是分布在集群多个节点上数据的集合，通过操作 RDD 对象来并行化操作集群上的分布式数据。\nRDD 有两种创建方式:\n 并行化驱动程序中已有的原生集合; 引用 HDFS、HBase 等外部存储系统上的数据集。  RDD 可以缓存在内存中，每次对 RDD 操作的结果都可以放到内存中，下一次操作时可直接从内存中读取，相对于 MapReduce,它省去了大量的磁盘 I\/O 操作。另外，持久化的 RDD 能够在错误中自动恢复，如果某部分 RDD 丢失，Spark 会自动重算丢失的部分。\nRDD 上的操作 从相关数据源获取初始数据形成初始 RDD 后，需要根据应用的需求对得到的初始 RDD 进行必要的处理，来获取满足需求的数据内容，从而对中间数据进行计算加工，得到最终的数据。\nRDD 支持两种操作，一种是转换（Transformation）操作，另一种是行动（Action）操作。\n转换（Transformation）操作 转换操作即将一个 RDD 转换为一个新的 RDD。值得注意的是，转换操作是惰性的，这就意味着对 RDD 调用某种转换操作时，操作并不会立即执行，而是 Spark 在内部记录下所要求执行的操作的相关信息，当在行动操作中需要用到这些转换出来的 RDD 时才会被计算，下表所示为基本的转换操作。通过转换操作，可以从已有的 RDD 生成出新的 RDD, Spark 使用谱系（Lineage）记录新旧 RDD 之间的依赖关系，一旦持久化的 RDD 丢失部分数据时，Spark 能通过谱系图重新计算丢失的数据。","inLanguage":"en-US","author":"Anthony","creator":"Anthony","publisher":"Anthony","accountablePerson":"Anthony","copyrightHolder":"Anthony","copyrightYear":"2020","datePublished":"2020-10-19 20:00:00 \u002b0800 \u002b0800","dateModified":"2020-10-19 20:00:00 \u002b0800 \u002b0800","url":"https:\/\/sudrizzz.github.com\/posts\/spark-distributed-programming\/","keywords":[]}</script><title>Spark 分布式内存计算框架 - Anthony's Blog</title><meta property="og:title" content="Spark 分布式内存计算框架 - Anthony's Blog"><meta property="og:type" content="article"><meta property="og:description" content="Spark 简介 Spark 是一种基于内存的、用以实现高效集群计算的平台。准确地讲，Spark 是一个大数据并行计算框架，是对广泛使用的 MapReduce 计算模型的扩展。Spark 有着自己的生态系统，但同时兼容 HDFS、Hive 等分布式存储系统，可以完美融入 Hadoop 的生态圈中，代替 MapReduce 去执行更为高效的分布式计算。两者的区别在于：基于 MapReduce 的计算引擎通常会将中间结果输出到磁盘上进行存储和容错；而 Spark 则是将中间结果尽量保存在内存中以减少底层存储系统的 I/O，以提高计算速度。
Spark 编程模型 核心数据结构 RDD Spark 将数据抽象成弹性分布式数据集（Resilient Distributed Dataset, RDD），RDD 实际是分布在集群多个节点上数据的集合，通过操作 RDD 对象来并行化操作集群上的分布式数据。
RDD 有两种创建方式:
 并行化驱动程序中已有的原生集合; 引用 HDFS、HBase 等外部存储系统上的数据集。  RDD 可以缓存在内存中，每次对 RDD 操作的结果都可以放到内存中，下一次操作时可直接从内存中读取，相对于 MapReduce,它省去了大量的磁盘 I/O 操作。另外，持久化的 RDD 能够在错误中自动恢复，如果某部分 RDD 丢失，Spark 会自动重算丢失的部分。
RDD 上的操作 从相关数据源获取初始数据形成初始 RDD 后，需要根据应用的需求对得到的初始 RDD 进行必要的处理，来获取满足需求的数据内容，从而对中间数据进行计算加工，得到最终的数据。
RDD 支持两种操作，一种是转换（Transformation）操作，另一种是行动（Action）操作。
转换（Transformation）操作 转换操作即将一个 RDD 转换为一个新的 RDD。值得注意的是，转换操作是惰性的，这就意味着对 RDD 调用某种转换操作时，操作并不会立即执行，而是 Spark 在内部记录下所要求执行的操作的相关信息，当在行动操作中需要用到这些转换出来的 RDD 时才会被计算，下表所示为基本的转换操作。通过转换操作，可以从已有的 RDD 生成出新的 RDD, Spark 使用谱系（Lineage）记录新旧 RDD 之间的依赖关系，一旦持久化的 RDD 丢失部分数据时，Spark 能通过谱系图重新计算丢失的数据。"><meta name=description content="Spark 简介 Spark 是一种基于内存的、用以实现高效集群计算的平台。准确地讲，Spark 是一个大数据并行计算框架，是对广泛使用的 MapReduce 计算模型的扩展。Spark 有着自己的生态系统，但同时兼容 HDFS、Hive 等分布式存储系统，可以完美融入 Hadoop 的生态圈中，代替 MapReduce 去执行更为高效的分布式计算。两者的区别在于：基于 MapReduce 的计算引擎通常会将中间结果输出到磁盘上进行存储和容错；而 Spark 则是将中间结果尽量保存在内存中以减少底层存储系统的 I/O，以提高计算速度。
Spark 编程模型 核心数据结构 RDD Spark 将数据抽象成弹性分布式数据集（Resilient Distributed Dataset, RDD），RDD 实际是分布在集群多个节点上数据的集合，通过操作 RDD 对象来并行化操作集群上的分布式数据。
RDD 有两种创建方式:
 并行化驱动程序中已有的原生集合; 引用 HDFS、HBase 等外部存储系统上的数据集。  RDD 可以缓存在内存中，每次对 RDD 操作的结果都可以放到内存中，下一次操作时可直接从内存中读取，相对于 MapReduce,它省去了大量的磁盘 I/O 操作。另外，持久化的 RDD 能够在错误中自动恢复，如果某部分 RDD 丢失，Spark 会自动重算丢失的部分。
RDD 上的操作 从相关数据源获取初始数据形成初始 RDD 后，需要根据应用的需求对得到的初始 RDD 进行必要的处理，来获取满足需求的数据内容，从而对中间数据进行计算加工，得到最终的数据。
RDD 支持两种操作，一种是转换（Transformation）操作，另一种是行动（Action）操作。
转换（Transformation）操作 转换操作即将一个 RDD 转换为一个新的 RDD。值得注意的是，转换操作是惰性的，这就意味着对 RDD 调用某种转换操作时，操作并不会立即执行，而是 Spark 在内部记录下所要求执行的操作的相关信息，当在行动操作中需要用到这些转换出来的 RDD 时才会被计算，下表所示为基本的转换操作。通过转换操作，可以从已有的 RDD 生成出新的 RDD, Spark 使用谱系（Lineage）记录新旧 RDD 之间的依赖关系，一旦持久化的 RDD 丢失部分数据时，Spark 能通过谱系图重新计算丢失的数据。"><meta property="og:locale" content="zh-cn"><link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css><link rel=stylesheet href=/css/github-markdown.css><link rel=stylesheet href=/css/highlight/tomorrow.min.css><link rel=stylesheet href=/css/index.css><link href=/index.xml rel=alternate type=application/rss+xml title="Anthony's Blog"><link href="https://fonts.loli.net/css?family=Arvo|Permanent+Marker|Bree+Serif" rel=stylesheet></head><body><article class="post Chinese" id=article><div class=row><div class=col-xs-12><div class=site-header><header><div class="signatures site-title"><a href=/>Anthony</a></div></header><div class="row end-xs"></div><div class=header-line></div></div><header class=post-header><h1 class=post-title>Spark 分布式内存计算框架</h1><div class="row post-desc"><div class=col-xs-6><time class=post-date datetime="2020-10-19 20:00:00 +0800">2020.10.19</time></div><div class=col-xs-6><div class=post-author><a target=_blank href=https://github.com/sudrizzz/>@Anthony</a></div></div></div></header><div class="post-content markdown-body"><h1 id=spark-简介>Spark 简介</h1><p>Spark 是一种基于内存的、用以实现高效集群计算的平台。准确地讲，Spark 是一个大数据并行计算框架，是对广泛使用的 MapReduce 计算模型的扩展。Spark 有着自己的生态系统，但同时兼容
HDFS、Hive 等分布式存储系统，可以完美融入 Hadoop 的生态圈中，代替 MapReduce 去执行更为高效的分布式计算。两者的区别在于：基于 MapReduce 的计算引擎通常会将中间结果输出到磁盘上进行存储和容错；而 Spark 则是将中间结果尽量保存在内存中以减少底层存储系统的 I/O，以提高计算速度。</p><h1 id=spark-编程模型>Spark 编程模型</h1><h2 id=核心数据结构-rdd>核心数据结构 RDD</h2><p>Spark 将数据抽象成弹性分布式数据集（Resilient Distributed Dataset, RDD），RDD 实际是分布在集群多个节点上数据的集合，通过操作 RDD 对象来并行化操作集群上的分布式数据。</p><p>RDD 有两种创建方式:</p><ol><li>并行化驱动程序中已有的原生集合;</li><li>引用 HDFS、HBase 等外部存储系统上的数据集。</li></ol><p>RDD 可以缓存在内存中，每次对 RDD 操作的结果都可以放到内存中，下一次操作时可直接从内存中读取，相对于 MapReduce,它省去了大量的磁盘 I/O 操作。另外，持久化的 RDD 能够在错误中自动恢复，如果某部分 RDD 丢失，Spark 会自动重算丢失的部分。</p><h2 id=rdd-上的操作>RDD 上的操作</h2><p>从相关数据源获取初始数据形成初始 RDD 后，需要根据应用的需求对得到的初始 RDD 进行必要的处理，来获取满足需求的数据内容，从而对中间数据进行计算加工，得到最终的数据。</p><p>RDD 支持两种操作，一种是转换（Transformation）操作，另一种是行动（Action）操作。</p><h3 id=转换transformation操作>转换（Transformation）操作</h3><p>转换操作即将一个 RDD 转换为一个新的 RDD。值得注意的是，转换操作是惰性的，这就意味着对 RDD 调用某种转换操作时，操作并不会立即执行，而是 Spark 在内部记录下所要求执行的操作的相关信息，当在行动操作中需要用到这些转换出来的 RDD 时才会被计算，下表所示为基本的转换操作。通过转换操作，可以从已有的 RDD 生成出新的 RDD, Spark 使用谱系（Lineage）记录新旧 RDD 之间的依赖关系，一旦持久化的 RDD 丢失部分数据时，Spark 能通过谱系图重新计算丢失的数据。</p><blockquote><p>输入数据为 {1, 2, 3, 3}</p></blockquote><table><thead><tr><th>函数名</th><th>目的</th><th>示例</th><th style=text-align:center>结果</th></tr></thead><tbody><tr><td>map()</td><td>将数据集中的每个元素经过用户自定义的函数转换形成一个新的 RDD</td><td>rdd.map(x => x * 2)</td><td style=text-align:center>{2, 4, 6, 6}</td></tr><tr><td>flatMap()</td><td>与 map() 类似，但每个元素输入项都可以被映射到 0 个或多个的输出项，最终将结果“扁平化“后输出</td><td>rdd.flatMap(x => (1 to x))</td><td style=text-align:center>{1, 1, 2, 1, 2, 3, 1, 2, 3, 3}</td></tr><tr><td>filter()</td><td>对 RDD 元素进行过滤，把经过指定函数后返回值为 true 的元素组成一个新的 RDD</td><td>rdd.filter(x => (x != 3))</td><td style=text-align:center>{1, 2}</td></tr><tr><td>distinct()</td><td>对数据进行去重，返回一个新的 RDD</td><td>rdd.distinct()</td><td style=text-align:center>{1, 2, 3}</td></tr><tr><td>sample(withReplacement, fraction, seed)</td><td>以指定的随机种子随机抽样出数量为 fraction 的数据，withReplacement 表示是抽出的数据是否放回，true 为有放回的抽样，false 为无放回的抽样</td><td>rdd.sample(true,0.5,3)</td><td style=text-align:center>非确定的</td></tr></tbody></table><h3 id=行动action操作>行动（Action）操作</h3><p>行动操作会触发 Spark 提交作业，对 RDD 进行实际的计算，并将最终求得的结果返回到驱动器程序，或者写入外部存储系统中。由于行动操作会得到一个结果，所以 Spark 会强制对 RDD 的转换操作进行求值，下表所示为基本的行动操作。</p><blockquote><p>输入数据为 {1, 2, 3, 3}</p></blockquote><table><thead><tr><th>函数名</th><th>目的</th><th>示例</th><th style=text-align:center>结果 <em>输入{1,2,3,3}</em></th></tr></thead><tbody><tr><td>collect()</td><td></td><td></td><td style=text-align:center></td></tr><tr><td>count()</td><td></td><td></td><td style=text-align:center></td></tr><tr><td>countByValue()</td><td></td><td></td><td style=text-align:center></td></tr><tr><td>take()</td><td></td><td></td><td style=text-align:center></td></tr><tr><td>top()</td><td></td><td></td><td style=text-align:center></td></tr><tr><td>reduce()</td><td></td><td></td><td style=text-align:center></td></tr><tr><td>fold()</td><td></td><td></td><td style=text-align:center></td></tr><tr><td>aggregate()</td><td></td><td></td><td style=text-align:center></td></tr><tr><td>foreach()</td><td></td><td></td><td style=text-align:center></td></tr></tbody></table><h1 id=参考文章>参考文章</h1><ol><li><a href=http://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations>http://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations</a></li><li><a href=https://www.cnblogs.com/MOBIN/p/5373256.html>https://www.cnblogs.com/MOBIN/p/5373256.html</a></li><li><a href=https://juejin.im/post/6844904147502759943>https://juejin.im/post/6844904147502759943</a></li><li><a href=https://yxnchen.github.io/technique/Spark%E7%AC%94%E8%AE%B0-%E7%8E%A9%E8%BD%ACRDD%E6%93%8D%E4%BD%9C/>https://yxnchen.github.io/technique/Spark%E7%AC%94%E8%AE%B0-%E7%8E%A9%E8%BD%ACRDD%E6%93%8D%E4%BD%9C/</a></li></ol></div><div class="row middle-xs"><div class=col-xs-12><div class=post-category><a href=/categories/hadoop>hadoop</a></div></div></div><div class=row><div class=col-xs-12></div></div><div style=height:50px></div><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"],],},};</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><div class=site-footer><div class=site-footer-item><a href=https://github.com/sudrizzz/ target=_blank>Github</a></div><div class=site-footer-item><a href=mailto:sudrizzz@google.com target=_blank>Email</a></div><div class=site-footer-item><a href="https://music.163.com/song?id=356827" target=_blank>~</a></div></div></div></div></article><script src=/js/highlight.pack.js></script><script src=/js/lazyload.min.js></script><script>var lazyImage=new LazyLoad({container:document.getElementById('article')});</script><script>hljs.initHighlightingOnLoad();</script></body></html>