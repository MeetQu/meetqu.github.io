<!doctype html><html lang=en><head><meta charset=utf-8><meta name=generator content="Hugo 0.75.1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Anthony"><meta property="og:url" content="https://sudrizzz.github.com/posts/summary-of-hdfs/"><link rel=canonical href=https://sudrizzz.github.com/posts/summary-of-hdfs/><link rel=alternate type=application/atom+xml href=https://sudrizzz.github.comindex.xml title="Anthony's Blog"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/sudrizzz.github.com"},"articleSection":"posts","name":"HDFS 小结","headline":"HDFS 小结","description":"HDFS 组成部分  HDFS 是一个分布式文件存储系统 Client 提交读写请求（拆分 blocksize） NameNode 全局把控（存储数据位置） DataNode 存储数据（将数据存储进去，且以 Pipeline 的方式把数据写完）  HDFS 数据交互 写入数据  使用 HDFS 提供的客户端 Client，向远程的 NameNode 发起 RPC 请求 NameNode 会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件创建一个记录，否则会让客户端抛出异常 当客户端开始写入文件的时候，客户端会将文件切分成多个 packets，并在内部以数据队列 data queue（数据队列） 的形式管理这些 packets，并向 NameNode 申请 blocks，获取用来存储 replicas 的合适的 DataNode 列表，列表的大小根据 NameNode 中 replication（副本份数）的设定而定 开始以 pipeline（管道）的形式将 packet 写入所有的 replicas 中。客户端把 packet 以流的方式写入第一个 DataNode，该 DataNode 把该 packet 存储之后，再将其传递给在此 pipeline 中的下一个 DataNode，直到最后一个 DataNode，这种写数据的方式呈流水线的形式 最后一个 DataNode 成功存储之后会返回一个 ack packet（确认队列），在 pipeline 里传递至客户端，在客户端的开发库内部维护着 \u0026ldquo;ack queue\u0026rdquo;，成功收到 DataNode 返回的 ack packet 后会从 \u0026ldquo;data queue\u0026rdquo; 移除相应的 packet 如果传输过程中，有某个 DataNode 出现了故障，那么当前的 pipeline 会被关闭，出现故障的 DataNode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 DataNode 中继续以 pipeline 的形式传输，同时 NameNode 会分配一个新的 DataNode，保持 replicas 设定的数量。 客户端完成数据的写入后，会对数据流调用 close() 方法，关闭数据流 只要写入了 dfs.","inLanguage":"en-US","author":"Anthony","creator":"Anthony","publisher":"Anthony","accountablePerson":"Anthony","copyrightHolder":"Anthony","copyrightYear":"2020","datePublished":"2020-10-01 15:20:11 \u002b0800 \u002b0800","dateModified":"2020-10-01 15:20:11 \u002b0800 \u002b0800","url":"https:\/\/sudrizzz.github.com\/posts\/summary-of-hdfs\/","keywords":[]}</script><title>HDFS 小结 - Anthony's Blog</title><meta property="og:title" content="HDFS 小结 - Anthony's Blog"><meta property="og:type" content="article"><meta property="og:description" content="HDFS 组成部分  HDFS 是一个分布式文件存储系统 Client 提交读写请求（拆分 blocksize） NameNode 全局把控（存储数据位置） DataNode 存储数据（将数据存储进去，且以 Pipeline 的方式把数据写完）  HDFS 数据交互 写入数据  使用 HDFS 提供的客户端 Client，向远程的 NameNode 发起 RPC 请求 NameNode 会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件创建一个记录，否则会让客户端抛出异常 当客户端开始写入文件的时候，客户端会将文件切分成多个 packets，并在内部以数据队列 data queue（数据队列） 的形式管理这些 packets，并向 NameNode 申请 blocks，获取用来存储 replicas 的合适的 DataNode 列表，列表的大小根据 NameNode 中 replication（副本份数）的设定而定 开始以 pipeline（管道）的形式将 packet 写入所有的 replicas 中。客户端把 packet 以流的方式写入第一个 DataNode，该 DataNode 把该 packet 存储之后，再将其传递给在此 pipeline 中的下一个 DataNode，直到最后一个 DataNode，这种写数据的方式呈流水线的形式 最后一个 DataNode 成功存储之后会返回一个 ack packet（确认队列），在 pipeline 里传递至客户端，在客户端的开发库内部维护着 &ldquo;ack queue&rdquo;，成功收到 DataNode 返回的 ack packet 后会从 &ldquo;data queue&rdquo; 移除相应的 packet 如果传输过程中，有某个 DataNode 出现了故障，那么当前的 pipeline 会被关闭，出现故障的 DataNode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 DataNode 中继续以 pipeline 的形式传输，同时 NameNode 会分配一个新的 DataNode，保持 replicas 设定的数量。 客户端完成数据的写入后，会对数据流调用 close() 方法，关闭数据流 只要写入了 dfs."><meta name=description content="HDFS 组成部分  HDFS 是一个分布式文件存储系统 Client 提交读写请求（拆分 blocksize） NameNode 全局把控（存储数据位置） DataNode 存储数据（将数据存储进去，且以 Pipeline 的方式把数据写完）  HDFS 数据交互 写入数据  使用 HDFS 提供的客户端 Client，向远程的 NameNode 发起 RPC 请求 NameNode 会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件创建一个记录，否则会让客户端抛出异常 当客户端开始写入文件的时候，客户端会将文件切分成多个 packets，并在内部以数据队列 data queue（数据队列） 的形式管理这些 packets，并向 NameNode 申请 blocks，获取用来存储 replicas 的合适的 DataNode 列表，列表的大小根据 NameNode 中 replication（副本份数）的设定而定 开始以 pipeline（管道）的形式将 packet 写入所有的 replicas 中。客户端把 packet 以流的方式写入第一个 DataNode，该 DataNode 把该 packet 存储之后，再将其传递给在此 pipeline 中的下一个 DataNode，直到最后一个 DataNode，这种写数据的方式呈流水线的形式 最后一个 DataNode 成功存储之后会返回一个 ack packet（确认队列），在 pipeline 里传递至客户端，在客户端的开发库内部维护着 &ldquo;ack queue&rdquo;，成功收到 DataNode 返回的 ack packet 后会从 &ldquo;data queue&rdquo; 移除相应的 packet 如果传输过程中，有某个 DataNode 出现了故障，那么当前的 pipeline 会被关闭，出现故障的 DataNode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 DataNode 中继续以 pipeline 的形式传输，同时 NameNode 会分配一个新的 DataNode，保持 replicas 设定的数量。 客户端完成数据的写入后，会对数据流调用 close() 方法，关闭数据流 只要写入了 dfs."><meta property="og:locale" content="zh-cn"><link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css><link rel=stylesheet href=/css/github-markdown.css><link rel=stylesheet href=/css/highlight/tomorrow.min.css><link rel=stylesheet href=/css/index.css><link href=/index.xml rel=alternate type=application/rss+xml title="Anthony's Blog"><link href="https://fonts.googleapis.com/css?family=Arvo|Permanent+Marker|Bree+Serif" rel=stylesheet></head><body><article class="post Chinese" id=article><div class=row><div class=col-xs-12><div class=site-header><header><div class="signatures site-title"><a href=/>Anthony</a></div></header><div class="row end-xs"></div><div class=header-line></div></div><header class=post-header><h1 class=post-title>HDFS 小结</h1><div class="row post-desc"><div class=col-xs-6><time class=post-date datetime="2020-10-01 15:20:11 +0800">2020.10.01</time></div><div class=col-xs-6><div class=post-author><a target=_blank href=https://github.com/sudrizzz/>@Anthony</a></div></div></div></header><div class="post-content markdown-body"><h1 id=hdfs-组成部分>HDFS 组成部分</h1><ul><li>HDFS 是一个分布式文件存储系统</li><li>Client 提交读写请求（拆分 blocksize）</li><li>NameNode 全局把控（存储数据位置）</li><li>DataNode 存储数据（将数据存储进去，且以 Pipeline 的方式把数据写完）</li></ul><h1 id=hdfs-数据交互>HDFS 数据交互</h1><h2 id=写入数据>写入数据</h2><ol><li>使用 HDFS 提供的客户端 Client，向远程的 NameNode 发起 RPC 请求</li><li>NameNode 会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件创建一个记录，否则会让客户端抛出异常</li><li>当客户端开始写入文件的时候，客户端会将文件切分成多个 packets，并在内部以数据队列 data queue（数据队列） 的形式管理这些 packets，并向 NameNode 申请 blocks，获取用来存储 replicas 的合适的 DataNode 列表，列表的大小根据 NameNode 中 replication（副本份数）的设定而定</li><li>开始以 pipeline（管道）的形式将 packet 写入所有的 replicas 中。客户端把 packet 以流的方式写入第一个 DataNode，该 DataNode 把该 packet 存储之后，再将其传递给在此 pipeline 中的下一个 DataNode，直到最后一个 DataNode，这种写数据的方式呈流水线的形式</li><li>最后一个 DataNode 成功存储之后会返回一个 ack packet（确认队列），在 pipeline 里传递至客户端，在客户端的开发库内部维护着 &ldquo;ack queue&rdquo;，成功收到 DataNode 返回的 ack packet 后会从 &ldquo;data queue&rdquo; 移除相应的 packet</li><li>如果传输过程中，有某个 DataNode 出现了故障，那么当前的 pipeline 会被关闭，出现故障的 DataNode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 DataNode 中继续以 pipeline 的形式传输，同时 NameNode 会分配一个新的 DataNode，保持 replicas 设定的数量。</li><li>客户端完成数据的写入后，会对数据流调用 close() 方法，关闭数据流</li><li>只要写入了 dfs.replication.min（最小写入成功的副本数）的复本数（默认为 1），写操作就会成功，并且这个块可以在集群中异步复制，直到达到其目标复本数（dfs.replication 的默认值为 3），因为 NameNode 已经知道文件由哪些块组成，所以它在返回成功前只需要等待数据块进行最小量的复制</li></ol><h2 id=读取数据>读取数据</h2><ol><li>客户端调用 FileSystem 实例的 open 方法，获得这个文件对应的输入流 InputStream</li><li>通过 RPC 远程调用 NameNode，获得 NameNode 中此文件对应的数据块保存位置，包括这个文件的副本的保存位置（主要是各 DataNode 的地址）</li><li>获得输入流之后，客户端调用 read 方法读取数据。选择最近的 DataNode 建立连接并读取数据</li><li>如果客户端和其中一个 DataNode 位于同一机器（比如 MapReduce 过程中的 mapper 和reducer)，那么就会直接从本地读取数据</li><li>到达数据块末端，关闭与这个 DataNode 的连接，然后重新查找下一个数据块</li><li>不断执行第 2~5 步直到数据全部读完</li><li>客户端调用 close，关闭输入流 DFS InputStream</li></ol></div><div class="row middle-xs"><div class=col-xs-12><div class=post-category><a href=/categories/hadoop>hadoop</a></div></div></div><div class=row><div class=col-xs-12></div></div><div style=height:50px></div><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"],],},};</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><div class=site-footer><div class=site-footer-item><a href=/ target=_self>Home</a></div><div class=site-footer-item><a href=mailto:sudrizzz@google.com target=_blank>Mail</a></div><div class=site-footer-item><a href="https://music.163.com/song?id=356827" target=_blank>~</a></div></div></div></div></article><script src=/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>