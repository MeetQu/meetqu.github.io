<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。
1 绪论 1.2 基本术语    术语 英语原意 释义     数据集 data set 一组关于一个事件或对象的描述的集合   样本 / 示例 sample / instance 数据集中的每条记录   属性 / 特征 attribute / feature 反映样本在某方面的表现或性质的事项   训练数据 training data 用于训练的数据   训练样本 training sample 训练数据中的每个样本   假设 hypothesis 通过训练学得数据的某种规律   真实 ground-truth 潜在规律本身   预测 prediction 训练结果生成的模型   分类 classification 预测离散值   二分类 binary classification 只涉及两个特征的分类   多分类 multi-class classification 涉及多个特征的分类   回归 regression 预测连续纸   聚类 clustering 对训练样本进行分组   簇 cluster 聚类后的每一个组   监督学习 supervised learning 训练数据有标记信息的训练（分类与回归）   无监督学习 unsupervised learning 训练数据没有标记信息的训练（聚类）    2 模型评估与选择 2."><title>《机器学习》笔记（一）</title><link rel=canonical href=https://sudrizzz.github.io/posts/machine-learning-note-1/><link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="《机器学习》笔记（一）"><meta property="og:description" content="《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。
1 绪论 1.2 基本术语    术语 英语原意 释义     数据集 data set 一组关于一个事件或对象的描述的集合   样本 / 示例 sample / instance 数据集中的每条记录   属性 / 特征 attribute / feature 反映样本在某方面的表现或性质的事项   训练数据 training data 用于训练的数据   训练样本 training sample 训练数据中的每个样本   假设 hypothesis 通过训练学得数据的某种规律   真实 ground-truth 潜在规律本身   预测 prediction 训练结果生成的模型   分类 classification 预测离散值   二分类 binary classification 只涉及两个特征的分类   多分类 multi-class classification 涉及多个特征的分类   回归 regression 预测连续纸   聚类 clustering 对训练样本进行分组   簇 cluster 聚类后的每一个组   监督学习 supervised learning 训练数据有标记信息的训练（分类与回归）   无监督学习 unsupervised learning 训练数据没有标记信息的训练（聚类）    2 模型评估与选择 2."><meta property="og:url" content="https://sudrizzz.github.io/posts/machine-learning-note-1/"><meta property="og:site_name" content="Anthony's blog"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:published_time" content="2020-12-22T09:00:00+08:00"><meta property="article:modified_time" content="2020-12-22T09:00:00+08:00"><meta name=twitter:title content="《机器学习》笔记（一）"><meta name=twitter:description content="《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。
1 绪论 1.2 基本术语    术语 英语原意 释义     数据集 data set 一组关于一个事件或对象的描述的集合   样本 / 示例 sample / instance 数据集中的每条记录   属性 / 特征 attribute / feature 反映样本在某方面的表现或性质的事项   训练数据 training data 用于训练的数据   训练样本 training sample 训练数据中的每个样本   假设 hypothesis 通过训练学得数据的某种规律   真实 ground-truth 潜在规律本身   预测 prediction 训练结果生成的模型   分类 classification 预测离散值   二分类 binary classification 只涉及两个特征的分类   多分类 multi-class classification 涉及多个特征的分类   回归 regression 预测连续纸   聚类 clustering 对训练样本进行分组   簇 cluster 聚类后的每一个组   监督学习 supervised learning 训练数据有标记信息的训练（分类与回归）   无监督学习 unsupervised learning 训练数据没有标记信息的训练（聚类）    2 模型评估与选择 2."></head><body><div class="container flex on-phone--column align-items--flex-start extended article-page with-toolbar"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><img src=/img/avatar_hu275e4bab890ad53f8b467a21c6984a95_383962_300x300_resize_box_2.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></figure><h1 class=site-name><a href=https://sudrizzz.github.io>Anthony's blog</a></h1><h2 class=site-description>I'm doing good, I’m on some new shit. Been saying "Yes" instead of "No".</h2></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li></ol></aside><main class="main full-width"><div id=article-toolbar><a href=https://sudrizzz.github.io class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg><span>Back</span></a></div><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"],],},};</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/machine-learning/>machine learning</a></header><h2 class=article-title><a href=/posts/machine-learning-note-1/>《机器学习》笔记（一）</a></h2><footer class=article-time><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--published>Dec 22, 2020</time></footer></div></header><section class=article-content><p>《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。</p><h1 id=1-绪论>1 绪论</h1><h2 id=12-基本术语>1.2 基本术语</h2><table><thead><tr><th>术语</th><th>英语原意</th><th>释义</th></tr></thead><tbody><tr><td>数据集</td><td>data set</td><td>一组关于一个事件或对象的描述的集合</td></tr><tr><td>样本 / 示例</td><td>sample / instance</td><td>数据集中的每条记录</td></tr><tr><td>属性 / 特征</td><td>attribute / feature</td><td>反映样本在某方面的表现或性质的事项</td></tr><tr><td>训练数据</td><td>training data</td><td>用于训练的数据</td></tr><tr><td>训练样本</td><td>training sample</td><td>训练数据中的每个样本</td></tr><tr><td>假设</td><td>hypothesis</td><td>通过训练学得数据的某种规律</td></tr><tr><td>真实</td><td>ground-truth</td><td>潜在规律本身</td></tr><tr><td>预测</td><td>prediction</td><td>训练结果生成的模型</td></tr><tr><td>分类</td><td>classification</td><td>预测离散值</td></tr><tr><td>二分类</td><td>binary classification</td><td>只涉及两个特征的分类</td></tr><tr><td>多分类</td><td>multi-class classification</td><td>涉及多个特征的分类</td></tr><tr><td>回归</td><td>regression</td><td>预测连续纸</td></tr><tr><td>聚类</td><td>clustering</td><td>对训练样本进行分组</td></tr><tr><td>簇</td><td>cluster</td><td>聚类后的每一个组</td></tr><tr><td>监督学习</td><td>supervised learning</td><td>训练数据有标记信息的训练（分类与回归）</td></tr><tr><td>无监督学习</td><td>unsupervised learning</td><td>训练数据没有标记信息的训练（聚类）</td></tr></tbody></table><h1 id=2-模型评估与选择>2 模型评估与选择</h1><h2 id=21-经验误差与过拟合>2.1 经验误差与过拟合</h2><h3 id=误差>误差</h3><p>通常我们把分类错误的样本数占样本总数的比例称为“错误率”（error rate），即如果在 m 个样本中有 a 个样本分类错误，则错误率 $ E = \frac{a}{m} $； 相应的，$ 1 - \frac{a}{m} $ 称为“精度”（accuracy），即“精度 = 1 - 错误率”。</p><p>更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”（error），学习器在训练集上的误差称为”训练误差“（training error） 或“经验误差”（empirical error）, 在新样本上的误差称为“泛化误差”（generalization errorr）。</p><h3 id=过拟合与欠拟合>过拟合与欠拟合</h3><p>为了达到更好的学习效果，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”，这样才能在遇到新样本时做出正确的判别。然而，当学习器把训练样本学得“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。这种现象在机器学习中称为“过拟合”（overfitting）。 与“过拟合”相对的是“欠拟合”（underfitting），这是指对训练样本的一般性质尚未学好。</p><p>下图展示了欠拟合与过拟合，蓝色点为训练数据，橙色点为测试数据，红色曲线为拟合曲线。</p><p>最优拟合
<img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222151854.png alt=20201222151854></p><p>欠拟合（underfitting）
<img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222153133.png alt=20201222153133></p><p>过拟合（overfitting）
<img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222152022.png alt=20201222152022></p><p>过拟合的训练误差（蓝色）与泛化误差（红色）
<img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222152706.png alt=20201222152706></p><h2 id=22-评估方法>2.2 评估方法</h2><h3 id=221-留出法>2.2.1 留出法</h3><p>留出法（hold-out）直接将数据集 $D$ 划分为两个互斥的集合，其中一个集合作为训练集 $S$，另一个作为测试集 $T$，即</p><p>$$ D = S \cup T , S \cap T=\varnothing $$</p><p>需要注意的是训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。</p><h3 id=222-交叉验证法>2.2.2 交叉验证法</h3><p>交叉验证法（cross validation）先将数据集 $D$ 划分为 $k$ 个大小相似的互斥子集，即</p><p>$$ D = D_1 \cup D_2 \cup \dots \cup D_k , D_i \cap D_j = \varnothing (i \ne j)$$</p><p>每个子集 $D_{i}$ 都尽可能保持数据分布的一致性，即从 $D$ 中通过分层采样得到。然后每次用 $k - 1$ 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可以获得 $k$ 组训练/测试集，从而可进行 $k$ 次训练和测试，最终返回的是这 $k$ 个测试结果得得得均值。显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于 $k$ 的取值，为强调这一点，通常把交叉验证法称为 ”$k$ 折交叉验证“（$k$-fold cross validation）。$k$ 最常用的取值是 10，此时成为 10 折交叉验证。下图为 10 折交叉验证的示意图。</p><p><img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20201222174250.png alt=20201222174250></p><h2 id=23-性能度量>2.3 性能度量</h2><p>在预测任务中，给定样例集 $D = {(x_1, y_1), (x_2, y_2), \dots , (x_m, y_m)}$ ，其中 $y_i$ 是 $x_i$ 的真实标记。要评估学习器 $f$ 的性能，就要把学习器预测结果 $f(x)$ 与真实标记 $y$ 进行比较。</p><p>回归任务最常用的性能度量是”均方误差“（mean squared error），即 Loss function</p><p>$$ L(f) = E(f; D) = \frac{1}{m} \sum_{i=1}^{m}(f(x_i) - y_i)^2 $$</p><p>则最优学习器 $f^*$ 可以表示为</p><p>$$ f^* = arg \min_f L(f) $$</p><h1 id=参考文献>参考文献</h1><ol><li><a class=link href=https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9 target=_blank rel=noopener>过拟合-维基百科</a></li><li><a class=link href=https://zh.wikipedia.org/wiki/%E5%88%86%E5%B1%82%E6%8A%BD%E6%A0%B7 target=_blank rel=noopener>分层抽样</a></li><li><a class=link href=https://datawhalechina.github.io/leeml-notes/ target=_blank rel=noopener>李宏毅机器学习笔记(LeeML-Notes)</a></li></ol></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload="renderMathInElement(document.querySelector(`.article-content`));"></script></article><aside class=related-contents--wrapper></aside><footer class=site-footer><section class=copyright>&copy; 2020 Anthony's blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=1.1.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true style=display:none><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const customFont=document.createElement('link');customFont.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";customFont.type="text/css";customFont.rel="stylesheet";document.head.appendChild(customFont);}());</script><link rel=stylesheet href=/css/highlight/light.min.css media="(prefers-color-scheme: light)"><link rel=stylesheet href=/css/highlight/dark.min.css media="(prefers-color-scheme: dark)"></body></html>