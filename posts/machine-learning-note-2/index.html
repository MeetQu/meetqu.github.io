<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="3 线性模型 3.1 基本形式 给定由 $d$ 个属性描述的示例 $\boldsymbol{x}={x_1; x_2;\cdots;x_d}$，其中 $x_i$ 是 $\boldsymbol{x}$ 在第 $i$ 个属性上的取值，线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数，即
$$ f(\boldsymbol{x}) = w_1x_1 + w_2x_2 + \cdots + w_dx_d + b $$
一般用向量形式写成
$$ f(\boldsymbol{x}) = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $$
其中 $\boldsymbol{w} = (w_1; w_2; \cdots; w_d)$，$\boldsymbol{w}$ 和 $b$ 学得之后，模型就得以确定。
3.2 线性回归 给定数据集 $D={(x_1, y_1,), (x_2, y_2), \cdots, (x_m, y_m)}$，其中 $\boldsymbol{x}_i = (x_{i1}; x_{i2}, \cdots, x_{id})$，$y_i \in \mathbb{R}$。“线性回归（linear regression）”试图学得一个线性模型以尽可能准确地预测实值输出标记。
线性回归试图学得 $f(x_i) = wx_i + b$，使得 $f(x_i) \simeq y_i$。"><title>《机器学习》笔记（二）</title><link rel=canonical href=https://example.com/posts/machine-learning-note-2/><link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="《机器学习》笔记（二）"><meta property="og:description" content="3 线性模型 3.1 基本形式 给定由 $d$ 个属性描述的示例 $\boldsymbol{x}={x_1; x_2;\cdots;x_d}$，其中 $x_i$ 是 $\boldsymbol{x}$ 在第 $i$ 个属性上的取值，线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数，即
$$ f(\boldsymbol{x}) = w_1x_1 + w_2x_2 + \cdots + w_dx_d + b $$
一般用向量形式写成
$$ f(\boldsymbol{x}) = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $$
其中 $\boldsymbol{w} = (w_1; w_2; \cdots; w_d)$，$\boldsymbol{w}$ 和 $b$ 学得之后，模型就得以确定。
3.2 线性回归 给定数据集 $D={(x_1, y_1,), (x_2, y_2), \cdots, (x_m, y_m)}$，其中 $\boldsymbol{x}_i = (x_{i1}; x_{i2}, \cdots, x_{id})$，$y_i \in \mathbb{R}$。“线性回归（linear regression）”试图学得一个线性模型以尽可能准确地预测实值输出标记。
线性回归试图学得 $f(x_i) = wx_i + b$，使得 $f(x_i) \simeq y_i$。"><meta property="og:url" content="https://example.com/posts/machine-learning-note-2/"><meta property="og:site_name" content="Anthony's blog"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:published_time" content="2020-12-30T17:00:00+08:00"><meta property="article:modified_time" content="2020-12-30T17:00:00+08:00"><meta name=twitter:title content="《机器学习》笔记（二）"><meta name=twitter:description content="3 线性模型 3.1 基本形式 给定由 $d$ 个属性描述的示例 $\boldsymbol{x}={x_1; x_2;\cdots;x_d}$，其中 $x_i$ 是 $\boldsymbol{x}$ 在第 $i$ 个属性上的取值，线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数，即
$$ f(\boldsymbol{x}) = w_1x_1 + w_2x_2 + \cdots + w_dx_d + b $$
一般用向量形式写成
$$ f(\boldsymbol{x}) = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $$
其中 $\boldsymbol{w} = (w_1; w_2; \cdots; w_d)$，$\boldsymbol{w}$ 和 $b$ 学得之后，模型就得以确定。
3.2 线性回归 给定数据集 $D={(x_1, y_1,), (x_2, y_2), \cdots, (x_m, y_m)}$，其中 $\boldsymbol{x}_i = (x_{i1}; x_{i2}, \cdots, x_{id})$，$y_i \in \mathbb{R}$。“线性回归（linear regression）”试图学得一个线性模型以尽可能准确地预测实值输出标记。
线性回归试图学得 $f(x_i) = wx_i + b$，使得 $f(x_i) \simeq y_i$。"></head><body><script>(function(){const colorSchemeKey='StackColorScheme';if(!localStorage.getItem(colorSchemeKey)){localStorage.setItem(colorSchemeKey,"auto");}})();</script><script>(function(){const colorSchemeKey='StackColorScheme';const colorSchemeItem=localStorage.getItem(colorSchemeKey);const supportDarkMode=window.matchMedia('(prefers-color-scheme: dark)').matches===true;if(colorSchemeItem=='dark'||colorSchemeItem==='auto'&&supportDarkMode){document.body.dataset.scheme='dark';}else{document.body.dataset.scheme='light';}})();</script><div class="container main-container flex on-phone--column extended article-page with-toolbar"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><img src=/img/avatar_hu275e4bab890ad53f8b467a21c6984a95_383962_300x0_resize_box_2.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></figure><h1 class=site-name><a href=https://example.com>Anthony's blog</a></h1><h2 class=site-description>I'm doing good, I’m on some new shit. Been saying "Yes" instead of "No".</h2></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></ol></aside><main class="main full-width"><div id=article-toolbar><a href=https://example.com class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg><span>Back</span></a></div><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/machine-learning/>machine learning</a></header><h2 class=article-title><a href=/posts/machine-learning-note-2/>《机器学习》笔记（二）</a></h2><footer class=article-time><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--published>Dec 30, 2020</time></footer></div></header><section class=article-content><h1 id=3-线性模型>3 线性模型</h1><h2 id=31-基本形式>3.1 基本形式</h2><p>给定由 $d$ 个属性描述的示例 $\boldsymbol{x}={x_1; x_2;\cdots;x_d}$，其中 $x_i$ 是 $\boldsymbol{x}$ 在第 $i$ 个属性上的取值，线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数，即</p><p>$$ f(\boldsymbol{x}) = w_1x_1 + w_2x_2 + \cdots + w_dx_d + b $$</p><p>一般用向量形式写成</p><p>$$ f(\boldsymbol{x}) = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $$</p><p>其中 $\boldsymbol{w} = (w_1; w_2; \cdots; w_d)$，$\boldsymbol{w}$ 和 $b$ 学得之后，模型就得以确定。</p><h2 id=32-线性回归>3.2 线性回归</h2><p>给定数据集 $D={(x_1, y_1,), (x_2, y_2), \cdots, (x_m, y_m)}$，其中 $\boldsymbol{x}_i = (x_{i1}; x_{i2}, \cdots, x_{id})$，$y_i \in \mathbb{R}$。“线性回归（linear regression）”试图学得一个线性模型以尽可能准确地预测实值输出标记。</p><p>线性回归试图学得 $f(x_i) = wx_i + b$，使得 $f(x_i) \simeq y_i$。</p><p>2.3 节中的均方误差是回归任务中最常用的性能度量，因此我们可试图让均方误差最小化，即</p><p>$$
(w^*, b^*) = arg \min_{(w, b)} \sum_{i = 1}^{m} (f(x_i) - y_i)^2 \\ = arg \min_{(w, b)} \sum_{i = 1}^{m} (y_i - wx_i - y_i)^2
$$</p><p>均方误差有非常好的几何意义，它对应了常用的欧几里得距离或简称“欧氏距离”（Euclidean distance）。基于均方误差最小化来进行模型求解的方法称为“最小二乘法”（least square method）。在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小。
求解 $w$ 和 $b$ 使 $E_{(w, b)} = \sum_{i = 1}^m(y_i - wx_i - b)^2$ 最小化的过程，称为线性回归模型的最小二乘“参数估计”（parameter estimation）。我们可将 $E_{(w, b)}$ 分别对 $w$ 和 $b$ 求导，得到</p><p>$$
\frac{\partial E_{(w, b)}}{\partial w} =2\left(w \sum_{i=1}^{m} x_{i}^{2}-\sum_{i=1}^{m}\left(y_{i}-b\right) x_{i}\right) \\ \frac{\partial E_{(w, b)}}{\partial b} =2\left(m b-\sum_{i=1}^{m}\left(y_{i}-w x_{i}\right)\right)
$$</p><p>然后令上述两式为零可得到 $w$ 和 $b$ 最优解的闭式（closed-form）解</p><p>$$
w=\frac{\sum_{i=1}^{m} y_{i}\left(x_{i}-\bar{x}\right)}{\sum_{i=1}^{m} x_{i}^{2}-\frac{1}{m}\left(\sum_{i=1}^{m} x_{i}\right)^{2}}
$$</p><p>$$ b=\frac{1}{m}\sum_{i=1}^m(y_i-wx_i) $$</p><p>其中，$\bar{x}=\frac{1}{m}\sum_{i=1}^mx_i$ 为 $x$ 均值。</p><h2 id=33-对数几率回归>3.3 对数几率回归</h2><p>考虑二分类任务，其输出标记 $y\in\{0,1\}$，而线性回归模型产生的预测值 $z = \boldsymbol{w}^\mathbf{T}\boldsymbol{x} + b $ 是实值，于是我们需将实值 $z$ 转换为 0/1 值。最理想的是“单位阶跃函数”（unit-step function）</p><p>$$
x = \begin{cases}
a &\text{if } b \<br>c &\text{if } d
\end{cases}
$$</p><h1 id=参考文献>参考文献</h1></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=StackLaTeX()></script><script>function StackLaTeX(){renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]});}</script></article><aside class=related-contents--wrapper><h2 class=section-title>Related contents</h2><div class=related-contents><div class="flex article-list--tile"><article><a href=/posts/machine-learning-note-1/><div class=article-details><h2 class=article-title>《机器学习》笔记（一）</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2018 -
2020 Anthony's blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=2.0.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const customFont=document.createElement('link');customFont.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";customFont.type="text/css";customFont.rel="stylesheet";document.head.appendChild(customFont);}());</script></body></html>