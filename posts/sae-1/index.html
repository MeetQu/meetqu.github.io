<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Autoencoder 简介 自编码器（Autoencoder，AE），是一种利用反向传播（backpropagation，BP）算法使得输出值等于输入值的神经网络，它先将输入压缩成潜在空间表征，然后通过这种表征来重构输出。其中，空间表征可以看作是输入数据的高级抽象，通常是将高维度的数据抽象为低维度的数据。
自编码器由两部分组成：
编码器：这部分能将输入压缩成潜在空间表征，可以用编码函数 $h=f(x)$ 表示;
解码器：这部分能重构来自潜在空间表征的输入，可以用解码函数 $r=g(h)$ 表示。
因此，整个自编码器可以用函数 $g(f(x)) = r$ 来描述，其中输出 $r$ 与原始输入 $x$ 相近。
自动编码器的目标是最大程度地减少输入和输出之间的重构误差。这有助于自动编码器学习数据中存在的重要功能。当表征很好地重建其输入时，则表示这个表征很好地保留了输入中存在的许多信息。整个过程如下图。
Stacked Autoencoder 简介 Stacked Autoencoder 简写作 SAE。SAE 与 AE 的主要区别在于编码器与解码器的层数，栈式自编码器包含多层隐藏层。具体网络结构如下图所示，图中有两层编码层，两层解码层。
代码实现  代码环境配置，请参考 GAN 网络之手写数字生成 第一小节——环境搭建。
 自编码器只是一种思想，在具体实现中，编码器和解码器可以由多种深度学习模型构成，例如全连接层、卷积层和 LSTM 等，以下使用 Keras 来实现栈式自编码器。
1from keras.datasets import mnist 2from keras.layers import Input, Dense 3from keras.models import Model 4import numpy as np 5import matplotlib.pyplot as plt 6 7EPOCHS = 50 8BATCH_SIZE = 256 9 10 11def train(x_train, x_test): 12 input_img = Input(shape=(784,)) 13 14 # 三个编码层，将数据从 784 维向量编码为 128、64、32 维向量 15 encoded = Dense(units=128, activation=&amp;#39;relu&amp;#39;)(input_img) 16 encoded = Dense(units=64, activation=&amp;#39;relu&amp;#39;)(encoded) 17 encoded = Dense(units=32, activation=&amp;#39;relu&amp;#39;)(encoded) 18 19 # 三个解码层，将数据从 32 维向量解码成 64、128、784 维向量 20 decoded = Dense(units=64, activation=&amp;#39;relu&amp;#39;)(encoded) 21 decoded = Dense(units=128, activation=&amp;#39;relu&amp;#39;)(decoded) 22 decoded = Dense(units=784, activation=&amp;#39;sigmoid&amp;#39;)(decoded) 23 autoencoder = Model(input_img, decoded) 24 encoder = Model(input_img, encoded) 25 26 autoencoder."><title>SAE 入门（一）</title><link rel=canonical href=https://sudrizzz.github.io/posts/sae-1/><link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="SAE 入门（一）"><meta property="og:description" content="Autoencoder 简介 自编码器（Autoencoder，AE），是一种利用反向传播（backpropagation，BP）算法使得输出值等于输入值的神经网络，它先将输入压缩成潜在空间表征，然后通过这种表征来重构输出。其中，空间表征可以看作是输入数据的高级抽象，通常是将高维度的数据抽象为低维度的数据。
自编码器由两部分组成：
编码器：这部分能将输入压缩成潜在空间表征，可以用编码函数 $h=f(x)$ 表示;
解码器：这部分能重构来自潜在空间表征的输入，可以用解码函数 $r=g(h)$ 表示。
因此，整个自编码器可以用函数 $g(f(x)) = r$ 来描述，其中输出 $r$ 与原始输入 $x$ 相近。
自动编码器的目标是最大程度地减少输入和输出之间的重构误差。这有助于自动编码器学习数据中存在的重要功能。当表征很好地重建其输入时，则表示这个表征很好地保留了输入中存在的许多信息。整个过程如下图。
Stacked Autoencoder 简介 Stacked Autoencoder 简写作 SAE。SAE 与 AE 的主要区别在于编码器与解码器的层数，栈式自编码器包含多层隐藏层。具体网络结构如下图所示，图中有两层编码层，两层解码层。
代码实现  代码环境配置，请参考 GAN 网络之手写数字生成 第一小节——环境搭建。
 自编码器只是一种思想，在具体实现中，编码器和解码器可以由多种深度学习模型构成，例如全连接层、卷积层和 LSTM 等，以下使用 Keras 来实现栈式自编码器。
1from keras.datasets import mnist 2from keras.layers import Input, Dense 3from keras.models import Model 4import numpy as np 5import matplotlib.pyplot as plt 6 7EPOCHS = 50 8BATCH_SIZE = 256 9 10 11def train(x_train, x_test): 12 input_img = Input(shape=(784,)) 13 14 # 三个编码层，将数据从 784 维向量编码为 128、64、32 维向量 15 encoded = Dense(units=128, activation=&amp;#39;relu&amp;#39;)(input_img) 16 encoded = Dense(units=64, activation=&amp;#39;relu&amp;#39;)(encoded) 17 encoded = Dense(units=32, activation=&amp;#39;relu&amp;#39;)(encoded) 18 19 # 三个解码层，将数据从 32 维向量解码成 64、128、784 维向量 20 decoded = Dense(units=64, activation=&amp;#39;relu&amp;#39;)(encoded) 21 decoded = Dense(units=128, activation=&amp;#39;relu&amp;#39;)(decoded) 22 decoded = Dense(units=784, activation=&amp;#39;sigmoid&amp;#39;)(decoded) 23 autoencoder = Model(input_img, decoded) 24 encoder = Model(input_img, encoded) 25 26 autoencoder."><meta property="og:url" content="https://sudrizzz.github.io/posts/sae-1/"><meta property="og:site_name" content="Anthony's blog"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:published_time" content="2021-01-20T18:00:00+08:00"><meta property="article:modified_time" content="2021-01-20T18:00:00+08:00"><meta name=twitter:title content="SAE 入门（一）"><meta name=twitter:description content="Autoencoder 简介 自编码器（Autoencoder，AE），是一种利用反向传播（backpropagation，BP）算法使得输出值等于输入值的神经网络，它先将输入压缩成潜在空间表征，然后通过这种表征来重构输出。其中，空间表征可以看作是输入数据的高级抽象，通常是将高维度的数据抽象为低维度的数据。
自编码器由两部分组成：
编码器：这部分能将输入压缩成潜在空间表征，可以用编码函数 $h=f(x)$ 表示;
解码器：这部分能重构来自潜在空间表征的输入，可以用解码函数 $r=g(h)$ 表示。
因此，整个自编码器可以用函数 $g(f(x)) = r$ 来描述，其中输出 $r$ 与原始输入 $x$ 相近。
自动编码器的目标是最大程度地减少输入和输出之间的重构误差。这有助于自动编码器学习数据中存在的重要功能。当表征很好地重建其输入时，则表示这个表征很好地保留了输入中存在的许多信息。整个过程如下图。
Stacked Autoencoder 简介 Stacked Autoencoder 简写作 SAE。SAE 与 AE 的主要区别在于编码器与解码器的层数，栈式自编码器包含多层隐藏层。具体网络结构如下图所示，图中有两层编码层，两层解码层。
代码实现  代码环境配置，请参考 GAN 网络之手写数字生成 第一小节——环境搭建。
 自编码器只是一种思想，在具体实现中，编码器和解码器可以由多种深度学习模型构成，例如全连接层、卷积层和 LSTM 等，以下使用 Keras 来实现栈式自编码器。
1from keras.datasets import mnist 2from keras.layers import Input, Dense 3from keras.models import Model 4import numpy as np 5import matplotlib.pyplot as plt 6 7EPOCHS = 50 8BATCH_SIZE = 256 9 10 11def train(x_train, x_test): 12 input_img = Input(shape=(784,)) 13 14 # 三个编码层，将数据从 784 维向量编码为 128、64、32 维向量 15 encoded = Dense(units=128, activation=&amp;#39;relu&amp;#39;)(input_img) 16 encoded = Dense(units=64, activation=&amp;#39;relu&amp;#39;)(encoded) 17 encoded = Dense(units=32, activation=&amp;#39;relu&amp;#39;)(encoded) 18 19 # 三个解码层，将数据从 32 维向量解码成 64、128、784 维向量 20 decoded = Dense(units=64, activation=&amp;#39;relu&amp;#39;)(encoded) 21 decoded = Dense(units=128, activation=&amp;#39;relu&amp;#39;)(decoded) 22 decoded = Dense(units=784, activation=&amp;#39;sigmoid&amp;#39;)(decoded) 23 autoencoder = Model(input_img, decoded) 24 encoder = Model(input_img, encoded) 25 26 autoencoder."></head><body><script>(function(){const colorSchemeKey='StackColorScheme';if(!localStorage.getItem(colorSchemeKey)){localStorage.setItem(colorSchemeKey,"auto");}})();</script><script>(function(){const colorSchemeKey='StackColorScheme';const colorSchemeItem=localStorage.getItem(colorSchemeKey);const supportDarkMode=window.matchMedia('(prefers-color-scheme: dark)').matches===true;if(colorSchemeItem=='dark'||colorSchemeItem==='auto'&&supportDarkMode){document.body.dataset.scheme='dark';}else{document.body.dataset.scheme='light';}})();</script><div class="container main-container flex on-phone--column extended article-page with-toolbar"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><img src=/img/avatar_hu275e4bab890ad53f8b467a21c6984a95_383962_300x0_resize_box_2.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></figure><h1 class=site-name><a href=https://sudrizzz.github.io/>Anthony's blog</a></h1><h2 class=site-description>I'm doing good, I’m on some new shit. Been saying "Yes" instead of "No".</h2></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></ol></aside><main class="main full-width"><div id=article-toolbar><a href=https://sudrizzz.github.io/ class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg><span>Back</span></a></div><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/stacked-autoencoder/>Stacked-Autoencoder</a>
<a href=/categories/machine-learning/>Machine-Learning</a></header><h2 class=article-title><a href=/posts/sae-1/>SAE 入门（一）</a></h2><footer class=article-time><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--published>Jan 20, 2021</time></footer></div></header><section class=article-content><h1 id=autoencoder-简介>Autoencoder 简介</h1><p>自编码器（Autoencoder，AE），是一种利用反向传播（backpropagation，BP）算法<strong>使得输出值等于输入值</strong>的神经网络，它先将输入压缩成潜在空间表征，然后通过这种表征来重构输出。其中，空间表征可以看作是输入数据的高级抽象，通常是将高维度的数据抽象为低维度的数据。</p><p>自编码器由两部分组成：<br>编码器：这部分能将输入压缩成潜在空间表征，可以用编码函数 $h=f(x)$ 表示;<br>解码器：这部分能重构来自潜在空间表征的输入，可以用解码函数 $r=g(h)$ 表示。</p><p>因此，整个自编码器可以用函数 $g(f(x)) = r$ 来描述，其中输出 $r$ 与原始输入 $x$ 相近。</p><p>自动编码器的目标是最大程度地减少输入和输出之间的重构误差。这有助于自动编码器学习数据中存在的重要功能。当表征很好地重建其输入时，则表示这个表征很好地保留了输入中存在的许多信息。整个过程如下图。</p><p><img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210122142001.png alt=20210122142001></p><h1 id=stacked-autoencoder-简介>Stacked Autoencoder 简介</h1><p>Stacked Autoencoder 简写作 SAE。SAE 与 AE 的主要区别在于编码器与解码器的层数，栈式自编码器包含多层隐藏层。具体网络结构如下图所示，图中有两层编码层，两层解码层。</p><p><img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210122154135.png alt=20210122154135></p><h1 id=代码实现>代码实现</h1><blockquote><p>代码环境配置，请参考 <a class=link href=https://sudrizzz.github.io/posts/gan-for-hand-written-digits/ target=_blank rel=noopener>GAN 网络之手写数字生成</a> 第一小节——环境搭建。</p></blockquote><p>自编码器只是一种思想，在具体实现中，编码器和解码器可以由多种深度学习模型构成，例如全连接层、卷积层和 LSTM 等，以下使用 Keras 来实现栈式自编码器。</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=ln> 1</span><span class=kn>from</span> <span class=nn>keras.datasets</span> <span class=kn>import</span> <span class=n>mnist</span>
<span class=ln> 2</span><span class=kn>from</span> <span class=nn>keras.layers</span> <span class=kn>import</span> <span class=n>Input</span><span class=p>,</span> <span class=n>Dense</span>
<span class=ln> 3</span><span class=kn>from</span> <span class=nn>keras.models</span> <span class=kn>import</span> <span class=n>Model</span>
<span class=ln> 4</span><span class=kn>import</span> <span class=nn>numpy</span> <span class=kn>as</span> <span class=nn>np</span>
<span class=ln> 5</span><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=kn>as</span> <span class=nn>plt</span>
<span class=ln> 6</span>
<span class=ln> 7</span><span class=n>EPOCHS</span> <span class=o>=</span> <span class=mi>50</span>
<span class=ln> 8</span><span class=n>BATCH_SIZE</span> <span class=o>=</span> <span class=mi>256</span>
<span class=ln> 9</span>
<span class=ln>10</span>
<span class=ln>11</span><span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>x_test</span><span class=p>):</span>
<span class=ln>12</span>    <span class=n>input_img</span> <span class=o>=</span> <span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=mi>784</span><span class=p>,))</span>
<span class=ln>13</span>
<span class=ln>14</span>    <span class=c1># 三个编码层，将数据从 784 维向量编码为 128、64、32 维向量</span>
<span class=ln>15</span>    <span class=n>encoded</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)(</span><span class=n>input_img</span><span class=p>)</span>
<span class=ln>16</span>    <span class=n>encoded</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)(</span><span class=n>encoded</span><span class=p>)</span>
<span class=ln>17</span>    <span class=n>encoded</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)(</span><span class=n>encoded</span><span class=p>)</span>
<span class=ln>18</span>
<span class=ln>19</span>    <span class=c1># 三个解码层，将数据从 32 维向量解码成 64、128、784 维向量</span>
<span class=ln>20</span>    <span class=n>decoded</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)(</span><span class=n>encoded</span><span class=p>)</span>
<span class=ln>21</span>    <span class=n>decoded</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)(</span><span class=n>decoded</span><span class=p>)</span>
<span class=ln>22</span>    <span class=n>decoded</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=o>=</span><span class=mi>784</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>)(</span><span class=n>decoded</span><span class=p>)</span>
<span class=ln>23</span>    <span class=n>autoencoder</span> <span class=o>=</span> <span class=n>Model</span><span class=p>(</span><span class=n>input_img</span><span class=p>,</span> <span class=n>decoded</span><span class=p>)</span>
<span class=ln>24</span>    <span class=n>encoder</span> <span class=o>=</span> <span class=n>Model</span><span class=p>(</span><span class=n>input_img</span><span class=p>,</span> <span class=n>encoded</span><span class=p>)</span>
<span class=ln>25</span>
<span class=ln>26</span>    <span class=n>autoencoder</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
<span class=ln>27</span>    <span class=n>encoder</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
<span class=ln>28</span>
<span class=ln>29</span>    <span class=n>autoencoder</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>optimizer</span><span class=o>=</span><span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=n>loss</span><span class=o>=</span><span class=s1>&#39;binary_crossentropy&#39;</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>])</span>
<span class=ln>30</span>    <span class=n>autoencoder</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>x_train</span><span class=p>,</span>
<span class=ln>31</span>                    <span class=n>epochs</span><span class=o>=</span><span class=n>EPOCHS</span><span class=p>,</span>
<span class=ln>32</span>                    <span class=n>batch_size</span><span class=o>=</span><span class=n>BATCH_SIZE</span><span class=p>,</span>
<span class=ln>33</span>                    <span class=n>shuffle</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span>
<span class=ln>34</span>                    <span class=n>validation_data</span><span class=o>=</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>x_test</span><span class=p>))</span>
<span class=ln>35</span>    <span class=k>return</span> <span class=n>encoder</span><span class=p>,</span> <span class=n>autoencoder</span>
<span class=ln>36</span>
<span class=ln>37</span>
<span class=ln>38</span><span class=k>def</span> <span class=nf>plot</span><span class=p>(</span><span class=n>encoded_imgs</span><span class=p>,</span> <span class=n>decoded_imgs</span><span class=p>):</span>
<span class=ln>39</span>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>40</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
<span class=ln>40</span>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
<span class=ln>41</span>        <span class=c1># 展示原始输入图像</span>
<span class=ln>42</span>        <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
<span class=ln>43</span>        <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>x_test</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>28</span><span class=p>,</span> <span class=mi>28</span><span class=p>))</span>
<span class=ln>44</span>        <span class=n>plt</span><span class=o>.</span><span class=n>gray</span><span class=p>()</span>
<span class=ln>45</span>        <span class=n>ax</span><span class=o>.</span><span class=n>get_xaxis</span><span class=p>()</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=bp>False</span><span class=p>)</span>
<span class=ln>46</span>        <span class=n>ax</span><span class=o>.</span><span class=n>get_yaxis</span><span class=p>()</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=bp>False</span><span class=p>)</span>
<span class=ln>47</span>
<span class=ln>48</span>        <span class=c1># 展示编码后的图像</span>
<span class=ln>49</span>        <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>+</span> <span class=mi>20</span><span class=p>)</span>
<span class=ln>50</span>        <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>encoded_imgs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
<span class=ln>51</span>        <span class=n>plt</span><span class=o>.</span><span class=n>gray</span><span class=p>()</span>
<span class=ln>52</span>        <span class=n>ax</span><span class=o>.</span><span class=n>get_xaxis</span><span class=p>()</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=bp>False</span><span class=p>)</span>
<span class=ln>53</span>        <span class=n>ax</span><span class=o>.</span><span class=n>get_yaxis</span><span class=p>()</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=bp>False</span><span class=p>)</span>
<span class=ln>54</span>
<span class=ln>55</span>        <span class=c1># 展示解码后的输入图像</span>
<span class=ln>56</span>        <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>2</span> <span class=o>*</span> <span class=mi>20</span> <span class=o>+</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
<span class=ln>57</span>        <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>decoded_imgs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>28</span><span class=p>,</span> <span class=mi>28</span><span class=p>))</span>
<span class=ln>58</span>        <span class=n>plt</span><span class=o>.</span><span class=n>gray</span><span class=p>()</span>
<span class=ln>59</span>        <span class=n>ax</span><span class=o>.</span><span class=n>get_xaxis</span><span class=p>()</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=bp>False</span><span class=p>)</span>
<span class=ln>60</span>        <span class=n>ax</span><span class=o>.</span><span class=n>get_yaxis</span><span class=p>()</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=bp>False</span><span class=p>)</span>
<span class=ln>61</span>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
<span class=ln>62</span>
<span class=ln>63</span>
<span class=ln>64</span><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
<span class=ln>65</span>    <span class=c1># 加载数据，训练数据 60000 条，测试数据 10000 条，数据灰度值 [0, 255]</span>
<span class=ln>66</span>    <span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>_</span><span class=p>),</span> <span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>_</span><span class=p>)</span> <span class=o>=</span> <span class=n>mnist</span><span class=o>.</span><span class=n>load_data</span><span class=p>()</span>
<span class=ln>67</span>
<span class=ln>68</span>    <span class=c1># 正则化数据，将灰度值区间转换为 [0, 1]</span>
<span class=ln>69</span>    <span class=n>x_train</span> <span class=o>=</span> <span class=n>x_train</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span> <span class=o>/</span> <span class=mi>255</span>
<span class=ln>70</span>    <span class=n>x_test</span> <span class=o>=</span> <span class=n>x_test</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span> <span class=o>/</span> <span class=mi>255</span>
<span class=ln>71</span>
<span class=ln>72</span>    <span class=c1># 将数据集从二维 (28, 28) 矩阵转换为长度为维度是 784 的向量</span>
<span class=ln>73</span>    <span class=n>x_train</span> <span class=o>=</span> <span class=n>x_train</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>x_train</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>prod</span><span class=p>(</span><span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>:]))</span>
<span class=ln>74</span>    <span class=n>x_test</span> <span class=o>=</span> <span class=n>x_test</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>x_test</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>prod</span><span class=p>(</span><span class=n>x_test</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>:]))</span>
<span class=ln>75</span>    <span class=k>print</span><span class=p>(</span><span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
<span class=ln>76</span>    <span class=k>print</span><span class=p>(</span><span class=n>x_test</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
<span class=ln>77</span>
<span class=ln>78</span>    <span class=c1># 训练数据</span>
<span class=ln>79</span>    <span class=n>encoder</span><span class=p>,</span> <span class=n>autoencoder</span> <span class=o>=</span> <span class=n>train</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>x_test</span><span class=p>)</span>
<span class=ln>80</span>
<span class=ln>81</span>    <span class=c1># 获取编码后和解码后的图像</span>
<span class=ln>82</span>    <span class=n>encoded_imgs</span> <span class=o>=</span> <span class=n>encoder</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
<span class=ln>83</span>    <span class=n>decoded_imgs</span> <span class=o>=</span> <span class=n>autoencoder</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
<span class=ln>84</span>
<span class=ln>85</span>    <span class=c1># 绘制图像</span>
<span class=ln>86</span>    <span class=n>plot</span><span class=p>(</span><span class=n>encoded_imgs</span><span class=p>,</span> <span class=n>decoded_imgs</span><span class=p>)</span>
</code></pre></div><p>运行上述代码，可以从输出内容中得到以下信息：</p><ol><li>输入数据是 60000 张手写数字的灰度图像，灰度取值范围是 [0, 255]，我们将其灰度值按行依次存储到一个 1 * 784 的数组中；</li><li>输入数据形如 (0, 0, 0,&mldr;, 84, 185, 159,&mldr;, 170, 52,&mldr;, 0, 0)，我们可以将每张图片（每个向量）理解为一个 784 维空间的中向量；</li><li>通过正则化后，输入数据每个维度区间变为 [0, 1]；</li><li>编码层将输入的 784 维向量抽象为 128、64、32 维向量（dense，dense_1，dense_2）；</li></ol><pre><code>Model: &quot;functional_3&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 784)]             0
_________________________________________________________________
dense (Dense)                (None, 128)               100480
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080
=================================================================
Total params: 110,816
Trainable params: 110,816
Non-trainable params: 0
_________________________________________________________________
</code></pre><ol start=4><li>解码层将抽象后的 32 维向量还原维 64、128、784 维向量（dense_3，dense_4，dense_5）；</li></ol><pre><code>Model: &quot;functional_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 784)]             0
_________________________________________________________________
dense (Dense)                (None, 128)               100480
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080
_________________________________________________________________
dense_3 (Dense)              (None, 64)                2112
_________________________________________________________________
dense_4 (Dense)              (None, 128)               8320
_________________________________________________________________
dense_5 (Dense)              (None, 784)               101136
=================================================================
Total params: 222,384
Trainable params: 222,384
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>训练完成之后，可以在输出内容中看到详细的训练数据，在 50 次训练之后，loss 已经降低到了 0.08。得到的输出图像如下图所示。</p><pre><code>......

Epoch 48/50
235/235 [==============================] - 3s 12ms/step - loss: 0.0848 - accuracy: 0.0130 - val_loss: 0.0844 - val_accuracy: 0.0147
Epoch 49/50
235/235 [==============================] - 3s 12ms/step - loss: 0.0846 - accuracy: 0.0130 - val_loss: 0.0845 - val_accuracy: 0.0115
Epoch 50/50
235/235 [==============================] - 3s 12ms/step - loss: 0.0845 - accuracy: 0.0139 - val_loss: 0.0840 - val_accuracy: 0.0165
</code></pre><p><img src=https://cdn.jsdelivr.net/gh/sudrizzz/blog_images@main/20210122160643.png alt=20210122160643></p><h1 id=参考文献>参考文献</h1><ol><li><a class=link href=https://medium.com/@venkatakrishna.jonnalagadda/sparse-stacked-and-variational-autoencoder-efe5bfe73b64 target=_blank rel=noopener>Sparse, Stacked and Variational Autoencoder</a></li><li><a class=link href=https://medium.com/datadriveninvestor/deep-learning-autoencoders-db265359943e target=_blank rel=noopener>Deep Learning Autoencoders</a></li><li><a class=link href=https://medium.com/datadriveninvestor/deep-autoencoder-using-keras-b77cd3e8be95 target=_blank rel=noopener>Deep Autoencoder using Keras</a></li><li><a class=link href=https://zhuanlan.zhihu.com/p/34238979 target=_blank rel=noopener>自编码器是什么？有什么用？这里有一份入门指南（附代码）</a></li><li><a class=link href=https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95 target=_blank rel=noopener>反向传播算法 - 维基百科</a></li><li><a class=link href=https://github.com/Nana0606/autoencoder target=_blank rel=noopener>Autoencoder - Github</a></li></ol></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=StackLaTeX()></script><script>function StackLaTeX(){renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]});}</script></article><aside class=related-contents--wrapper><h2 class=section-title>Related contents</h2><div class=related-contents><div class="flex article-list--tile"><article><a href=/posts/sae-2/><div class=article-details><h2 class=article-title>SAE 入门（二）——基于 tiny_dnn 的手写数字重建</h2></div></a></article><article><a href=/posts/machine-learning-note-3/><div class=article-details><h2 class=article-title>《机器学习》笔记（第四章）</h2></div></a></article><article><a href=/posts/machine-learning-note-2/><div class=article-details><h2 class=article-title>《机器学习》笔记（第三章）</h2></div></a></article><article><a href=/posts/machine-learning-note-1/><div class=article-details><h2 class=article-title>《机器学习》笔记（第一、二章）</h2></div></a></article><article><a href=/posts/gan-for-hand-written-digits/><div class=article-details><h2 class=article-title>GAN 网络之手写数字生成</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2018 -
2021 Anthony's blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=2.0.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const customFont=document.createElement('link');customFont.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";customFont.type="text/css";customFont.rel="stylesheet";document.head.appendChild(customFont);}());</script></body></html>