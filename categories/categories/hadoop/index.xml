<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>hadoop on Anthony's Blog</title><link>https://sudrizzz.github.com/categories/hadoop/</link><description>Recent content in hadoop on Anthony's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 01 Oct 2020 15:20:11 +0800</lastBuildDate><atom:link href="https://sudrizzz.github.com/categories/hadoop/index.xml" rel="self" type="application/rss+xml"/><item><title>HDFS 小结</title><link>https://sudrizzz.github.com/posts/summary-of-hdfs/</link><pubDate>Thu, 01 Oct 2020 15:20:11 +0800</pubDate><guid>https://sudrizzz.github.com/posts/summary-of-hdfs/</guid><description>HDFS 组成部分 HDFS 是一个分布式文件存储系统 Client 提交读写请求（拆分 blocksize） NameNode 全局把控（存储数据位置） DataNode 存储数据（将数据存储进去，且以 Pipeline 的方式把数据写完） HDFS 数据交互 写入数据 使用 HDFS 提供的客户端 Client，向远程的 NameNode 发起 RPC 请求 NameNode 会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件创建一个记录，否则会让客户端抛出异常 当客户端开始写入文件的时候，客户端会将文件切分成多个 packets，并在内部以数据队列 data queue（数据队列） 的形式管理这些 packets，并向 NameNode 申请 blocks，获取用来存储 replicas 的合适的 DataNode 列表，列表的大小根据 NameNode 中 replication（副本份数）的设定而定 开始以 pipeline（管道）的形式将 packet 写入所有的 replicas 中。客户端把 packet 以流的方式写入第一个 DataNode，该 DataNode 把该 packet 存储之后，再将其传递给在此 pipeline 中的下一个 DataNode，直到最后一个 DataNode，这种写数据的方式呈流水线的形式 最后一个 DataNode 成功存储之后会返回一个 ack packet（确认队列），在 pipeline 里传递至客户端，在客户端的开发库内部维护着 &amp;ldquo;ack queue&amp;rdquo;，成功收到 DataNode 返回的 ack packet 后会从 &amp;ldquo;data queue&amp;rdquo; 移除相应的 packet 如果传输过程中，有某个 DataNode 出现了故障，那么当前的 pipeline 会被关闭，出现故障的 DataNode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 DataNode 中继续以 pipeline 的形式传输，同时 NameNode 会分配一个新的 DataNode，保持 replicas 设定的数量。 客户端完成数据的写入后，会对数据流调用 close() 方法，关闭数据流 只要写入了 dfs.</description></item><item><title>初识 Hadoop（一）</title><link>https://sudrizzz.github.com/posts/getting-to-know-hadoop/</link><pubDate>Thu, 24 Sep 2020 09:20:11 +0800</pubDate><guid>https://sudrizzz.github.com/posts/getting-to-know-hadoop/</guid><description>前言 本系列文章是基于《大数据技术基础》与 10 小时入门大数据 课程，如果有兴趣可以先阅读该书并观看视频教程。本系列文章中所用到的软件版本及其下载地址如下：
名称 版本 下载地址 CentOS 8.2.2004 https://mirrors.tuna.tsinghua.edu.cn/centos/8.2.2004/isos/x86_64/CentOS-8.2.2004-x86_64-minimal.iso JDK 14.0.2 https://www.oracle.com/java/technologies/javase/jdk14-archive-downloads.html Hadoop 2.10.1 https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.10.1/hadoop-2.10.1-src.tar.gz 环境准备 配置网络 此篇文章所使用的 CentOS 环境均是使用 VMware 15 虚拟的，具体安装教程请查看 使用 VMware 15 安装虚拟机和使用 CentOS 8，此处不再赘述。安装好一个节点之后，我们可以采用“虚拟机克隆”的方式，直接完成另外两个节点系统的安装。
虚拟机的网络配置采用 DHCP 自动分配模式，每台机器的 IP 地址可以通过命令 ip address 或 ifconfig 查看，其中 ifconfig 输出如下，第一组配置中 ens33 即为本机网络配置，inet 项对应的即为本机 ip（192.168.61.128）。
1ens33: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 2 inet 192.168.61.128 netmask 255.255.255.0 broadcast 192.</description></item></channel></rss>